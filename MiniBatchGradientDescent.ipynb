{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b780fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aa1ad49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Existing dataset for regression by sklearn.datasets\n",
    "X , y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1f0c3371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((442, 10), (442,))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "007f110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split( X , y ,test_size=0.2 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8a611045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini Batch Gradient Descent from the scratch\n",
    "class MBRegressor:\n",
    "    def __init__(self,batch_size,epochs = 100,learning_rate = 0.01):\n",
    "        self.b_size = batch_size\n",
    "        self.coef = None\n",
    "        self.intercept = None\n",
    "        self.epochs = epochs\n",
    "        self.l = learning_rate\n",
    "    \n",
    "    def fit(self,X_train,y_train):\n",
    "        #Instantiation of intercept and coeffecients\n",
    "        self.coef = np.ones(X_train.shape[1]) # Column size\n",
    "        self.intercept = 0 \n",
    "        \n",
    "        # Looping epochs time\n",
    "        for i in range(self.epochs):\n",
    "            for j in range(int(X_train.shape[0]/self.b_size)): #  we calculate the batch size by int(the no of rows / batch size).\n",
    "                \n",
    "                # Now calculating the intercept but here we have batch size \n",
    "                # So we will use np.sample to generate random batch size samples from the data. \n",
    "                \n",
    "                # First we will fetch the ids for the nummber of random values from the dataset\n",
    "                idx = random.sample(range(X_train.shape[0]),self.b_size) # generates row/b_size no of random ids from the domain\n",
    "\n",
    "                # Now calculating yhat for calculation of intercept\n",
    "                y_hat = np.dot(X_train[idx],self.coef) + self.intercept \n",
    "\n",
    "                # We need intercept derivaive acting as a loss function in calculation of new intercept value\n",
    "                intercept_deri = -2 * np.mean(y_train[idx] - y_hat)\n",
    "\n",
    "                # Now calculating new intercept value\n",
    "                self.intercept = self.intercept - (self.l * intercept_deri)\n",
    "\n",
    "                # Now lets calculate new coeffecient values\n",
    "                # First again like intercept we need coef_deri :\n",
    "                coef_deri = -2 * np.dot((y_train[idx] - y_hat),X_train[idx])\n",
    "\n",
    "                # Now calculating new coef value:\n",
    "                self.coef = self.coef - (self.l * coef_deri)\n",
    "\n",
    "\n",
    "        print(self.coef , self.intercept)\n",
    "\n",
    "    def predict(self,X_test):\n",
    "        return (np.dot(X_test,self.coef) + self.intercept )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94b3609",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MBRegressor(batch_size=int(X_train.shape[0]/50)) # we are just taking this batch size for testing ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fb580fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  47.5966421  -165.26811717  468.64897147  308.02613012  -48.97527356\n",
      " -102.70523842 -208.28402096  140.8817889   352.36816343  126.84051853] 155.441430905509\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3aaad03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "16c2f842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46096770581855073"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d3e04591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will use SGD regressor for this and implement it \n",
    "mbr = SGDRegressor( learning_rate='constant' , eta0=0.1 ) \n",
    "# We can tweak the eta and make other changes also by passing paramters here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6a8a5dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW there is no special method for MiniBatchRegression so we will use a loop and partial fit to make the model fit to data in each epoch\n",
    "\n",
    "batch_size = 25 #Explicitly set for this example\n",
    "\n",
    "for i in range(100): #epochs\n",
    "    idx = random.sample(range(X_train.shape[0]),batch_size) # Same as our scratch implementaion\n",
    "    mbr.partial_fit(X_train[idx],y_train[idx]) # Partially fits one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0fde9405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  48.66407653, -131.2370863 ,  440.48127934,  274.87093215,\n",
       "         -35.34979179,  -80.52081532, -197.33974199,  140.85576794,\n",
       "         325.43902735,  149.21428062]),\n",
       " array([155.69762581]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbr.coef_,mbr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e6ba29c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mbr = mbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a7ec2fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4579601843518969"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred_mbr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
