{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "bf496991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the necessary imports for the programme\n",
    "from sklearn.datasets import load_iris # We are gonna use the iris dataset for this demonstration.\n",
    "from sklearn.metrics import classification_report,confusion_matrix # Evaluation metrics for classification\n",
    "from sklearn.model_selection import cross_val_score # Cross val score to predict using different combinations of the folds.\n",
    "import pandas as pd # For dataframem manipulation\n",
    "import seaborn as sns # For plotting graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "07e8c6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_iris(return_X_y=True) # load the dataset\n",
    "# Basically we already have the variables and labels stored in different values , reducing wokload(preprocessing). \n",
    "# In iris dataset we are give iris flower properties (continous numeric) and we have to predict based on this properties\n",
    "# which flower belong to which class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "d37bb854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the models that can be used to classify the species.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "607277a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model selection for ensemble learning - Voting is upto us . \n",
    "# We can either use multiple different models or a same models with different paramaters tuned with it .\n",
    "lor1 = LogisticRegression(max_iter = 1000)\n",
    "clf1 = DecisionTreeClassifier(\n",
    "    criterion = 'gini'\n",
    ")\n",
    "clf2 = DecisionTreeClassifier(\n",
    "    criterion = 'gini',\n",
    "    max_depth = 5 ,\n",
    "    splitter = 'random'\n",
    ")\n",
    "gnb1 = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "69f416ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make a estimator list consiting of all the tuples which has the name of that model so that VotingClassifier \n",
    "# can uniquely identify it and this is followe by the object of that model instantiated earlier . \n",
    "'''\n",
    "            syntax : estimators(just a variable name) = \n",
    "            [\n",
    "                ('modelname1' , model1),\n",
    "                ('modelname2' , mode2), . . . \n",
    "                ('modelnameN' , modelN),\n",
    "]\n",
    "'''\n",
    "estimators = [\n",
    "    ('LogisticRegressor1' , lor1) , \n",
    "    ('DecisionTreeClassifier' , clf1) , \n",
    "    ('DecisionTreeClassifierUsingRandom' , clf2) ,\n",
    "    ('GaussianNaiveBayes' , gnb1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "af8476b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Voting Ensemble Classifier from the ensemble module\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "744b4e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "voteHard = VotingClassifier(\n",
    "    estimators = estimators ,  # Pass the variables in which we made the list of the modelnames and models (estimators)\n",
    "    voting = 'hard' # We are using hard voting which means only the predicted label is passed as the output for the ensembler and \n",
    "    # not the probability of all the other classes which were not predicted . \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "9968cbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-16.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-16.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-16 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-16 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-16 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-16 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-16 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-16 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-16 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-16 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-16 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;LogisticRegressor1&#x27;,\n",
       "                              LogisticRegression(max_iter=1000)),\n",
       "                             (&#x27;DecisionTreeClassifier&#x27;,\n",
       "                              DecisionTreeClassifier()),\n",
       "                             (&#x27;DecisionTreeClassifierUsingRandom&#x27;,\n",
       "                              DecisionTreeClassifier(max_depth=5,\n",
       "                                                     splitter=&#x27;random&#x27;)),\n",
       "                             (&#x27;GaussianNaiveBayes&#x27;, GaussianNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-66\" type=\"checkbox\" ><label for=\"sk-estimator-id-66\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>VotingClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html\">?<span>Documentation for VotingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html#:~:text=estimators,-list%20of%20%28str%2C%20estimator%29%20tuples\">\n",
       "            estimators\n",
       "            <span class=\"param-doc-description\">estimators: list of (str, estimator) tuples<br><br>Invoking the ``fit`` method on the ``VotingClassifier`` will fit clones<br>of those original estimators that will be stored in the class attribute<br>``self.estimators_``. An estimator can be set to ``'drop'`` using<br>:meth:`set_params`.<br><br>.. versionchanged:: 0.21<br>    ``'drop'`` is accepted. Using None was deprecated in 0.22 and<br>    support was removed in 0.24.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">[(&#x27;LogisticRegressor1&#x27;, ...), (&#x27;DecisionTreeClassifier&#x27;, ...), ...]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('voting',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html#:~:text=voting,-%7B%27hard%27%2C%20%27soft%27%7D%2C%20default%3D%27hard%27\">\n",
       "            voting\n",
       "            <span class=\"param-doc-description\">voting: {'hard', 'soft'}, default='hard'<br><br>If 'hard', uses predicted class labels for majority rule voting.<br>Else if 'soft', predicts the class label based on the argmax of<br>the sums of the predicted probabilities, which is recommended for<br>an ensemble of well-calibrated classifiers.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;hard&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html#:~:text=weights,-array-like%20of%20shape%20%28n_classifiers%2C%29%2C%20default%3DNone\">\n",
       "            weights\n",
       "            <span class=\"param-doc-description\">weights: array-like of shape (n_classifiers,), default=None<br><br>Sequence of weights (`float` or `int`) to weight the occurrences of<br>predicted class labels (`hard` voting) or class probabilities<br>before averaging (`soft` voting). Uses uniform weights if `None`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of jobs to run in parallel for ``fit``.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.<br><br>.. versionadded:: 0.18</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('flatten_transform',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html#:~:text=flatten_transform,-bool%2C%20default%3DTrue\">\n",
       "            flatten_transform\n",
       "            <span class=\"param-doc-description\">flatten_transform: bool, default=True<br><br>Affects shape of transform output only when voting='soft'<br>If voting='soft' and flatten_transform=True, transform method returns<br>matrix with shape (n_samples, n_classifiers * n_classes). If<br>flatten_transform=False, it returns<br>(n_classifiers, n_samples, n_classes).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html#:~:text=verbose,-bool%2C%20default%3DFalse\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: bool, default=False<br><br>If True, the time elapsed while fitting will be printed as it<br>is completed.<br><br>.. versionadded:: 0.23</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>LogisticRegressor1</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-67\" type=\"checkbox\" ><label for=\"sk-estimator-id-67\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"LogisticRegressor1__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=penalty,-%7B%27l1%27%2C%20%27l2%27%2C%20%27elasticnet%27%2C%20None%7D%2C%20default%3D%27l2%27\">\n",
       "            penalty\n",
       "            <span class=\"param-doc-description\">penalty: {'l1', 'l2', 'elasticnet', None}, default='l2'<br><br>Specify the norm of the penalty:<br><br>- `None`: no penalty is added;<br>- `'l2'`: add a L2 penalty term and it is the default choice;<br>- `'l1'`: add a L1 penalty term;<br>- `'elasticnet'`: both L1 and L2 penalty terms are added.<br><br>.. warning::<br>   Some penalties may not work with some solvers. See the parameter<br>   `solver` below, to know the compatibility between the penalty and<br>   solver.<br><br>.. versionadded:: 0.19<br>   l1 penalty with SAGA solver (allowing 'multinomial' + L1)<br><br>.. deprecated:: 1.8<br>   `penalty` was deprecated in version 1.8 and will be removed in 1.10.<br>   Use `l1_ratio` instead. `l1_ratio=0` for `penalty='l2'`, `l1_ratio=1` for<br>   `penalty='l1'` and `l1_ratio` set to any float between 0 and 1 for<br>   `'penalty='elasticnet'`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=C,-float%2C%20default%3D1.0\">\n",
       "            C\n",
       "            <span class=\"param-doc-description\">C: float, default=1.0<br><br>Inverse of regularization strength; must be a positive float.<br>Like in support vector machines, smaller values specify stronger<br>regularization. `C=np.inf` results in unpenalized logistic regression.<br>For a visual example on the effect of tuning the `C` parameter<br>with an L1 penalty, see:<br>:ref:`sphx_glr_auto_examples_linear_model_plot_logistic_path.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=l1_ratio,-float%2C%20default%3D0.0\">\n",
       "            l1_ratio\n",
       "            <span class=\"param-doc-description\">l1_ratio: float, default=0.0<br><br>The Elastic-Net mixing parameter, with `0 <= l1_ratio <= 1`. Setting<br>`l1_ratio=1` gives a pure L1-penalty, setting `l1_ratio=0` a pure L2-penalty.<br>Any value between 0 and 1 gives an Elastic-Net penalty of the form<br>`l1_ratio * L1 + (1 - l1_ratio) * L2`.<br><br>.. warning::<br>   Certain values of `l1_ratio`, i.e. some penalties, may not work with some<br>   solvers. See the parameter `solver` below, to know the compatibility between<br>   the penalty and solver.<br><br>.. versionchanged:: 1.8<br>    Default value changed from None to 0.0.<br><br>.. deprecated:: 1.8<br>    `None` is deprecated and will be removed in version 1.10. Always use<br>    `l1_ratio` to specify the penalty type.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=dual,-bool%2C%20default%3DFalse\">\n",
       "            dual\n",
       "            <span class=\"param-doc-description\">dual: bool, default=False<br><br>Dual (constrained) or primal (regularized, see also<br>:ref:`this equation <regularized-logistic-loss>`) formulation. Dual formulation<br>is only implemented for l2 penalty with liblinear solver. Prefer `dual=False`<br>when n_samples > n_features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=tol,-float%2C%20default%3D1e-4\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-4<br><br>Tolerance for stopping criteria.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Specifies if a constant (a.k.a. bias or intercept) should be<br>added to the decision function.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=intercept_scaling,-float%2C%20default%3D1\">\n",
       "            intercept_scaling\n",
       "            <span class=\"param-doc-description\">intercept_scaling: float, default=1<br><br>Useful only when the solver `liblinear` is used<br>and `self.fit_intercept` is set to `True`. In this case, `x` becomes<br>`[x, self.intercept_scaling]`,<br>i.e. a \"synthetic\" feature with constant value equal to<br>`intercept_scaling` is appended to the instance vector.<br>The intercept becomes<br>``intercept_scaling * synthetic_feature_weight``.<br><br>.. note::<br>    The synthetic feature weight is subject to L1 or L2<br>    regularization as all other features.<br>    To lessen the effect of regularization on synthetic feature weight<br>    (and therefore on the intercept) `intercept_scaling` has to be increased.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=class_weight,-dict%20or%20%27balanced%27%2C%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: dict or 'balanced', default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If not given, all classes are supposed to have weight one.<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.<br><br>.. versionadded:: 0.17<br>   *class_weight='balanced'*</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=random_state,-int%2C%20RandomState%20instance%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance, default=None<br><br>Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the<br>data. See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=solver,-%7B%27lbfgs%27%2C%20%27liblinear%27%2C%20%27newton-cg%27%2C%20%27newton-cholesky%27%2C%20%27sag%27%2C%20%27saga%27%7D%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3D%27lbfgs%27\">\n",
       "            solver\n",
       "            <span class=\"param-doc-description\">solver: {'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'},             default='lbfgs'<br><br>Algorithm to use in the optimization problem. Default is 'lbfgs'.<br>To choose a solver, you might want to consider the following aspects:<br><br>- 'lbfgs' is a good default solver because it works reasonably well for a wide<br>  class of problems.<br>- For :term:`multiclass` problems (`n_classes >= 3`), all solvers except<br>  'liblinear' minimize the full multinomial loss, 'liblinear' will raise an<br>  error.<br>- 'newton-cholesky' is a good choice for<br>  `n_samples` >> `n_features * n_classes`, especially with one-hot encoded<br>  categorical features with rare categories. Be aware that the memory usage<br>  of this solver has a quadratic dependency on `n_features * n_classes`<br>  because it explicitly computes the full Hessian matrix.<br>- For small datasets, 'liblinear' is a good choice, whereas 'sag'<br>  and 'saga' are faster for large ones;<br>- 'liblinear' can only handle binary classification by default. To apply a<br>  one-versus-rest scheme for the multiclass setting one can wrap it with the<br>  :class:`~sklearn.multiclass.OneVsRestClassifier`.<br><br>.. warning::<br>   The choice of the algorithm depends on the penalty chosen (`l1_ratio=0`<br>   for L2-penalty, `l1_ratio=1` for L1-penalty and `0 < l1_ratio < 1` for<br>   Elastic-Net) and on (multinomial) multiclass support:<br><br>   ================= ======================== ======================<br>   solver            l1_ratio                 multinomial multiclass<br>   ================= ======================== ======================<br>   'lbfgs'           l1_ratio=0               yes<br>   'liblinear'       l1_ratio=1 or l1_ratio=0 no<br>   'newton-cg'       l1_ratio=0               yes<br>   'newton-cholesky' l1_ratio=0               yes<br>   'sag'             l1_ratio=0               yes<br>   'saga'            0<=l1_ratio<=1           yes<br>   ================= ======================== ======================<br><br>.. note::<br>   'sag' and 'saga' fast convergence is only guaranteed on features<br>   with approximately the same scale. You can preprocess the data with<br>   a scaler from :mod:`sklearn.preprocessing`.<br><br>.. seealso::<br>   Refer to the :ref:`User Guide <Logistic_regression>` for more<br>   information regarding :class:`LogisticRegression` and more specifically the<br>   :ref:`Table <logistic_regression_solvers>`<br>   summarizing solver/penalty supports.<br><br>.. versionadded:: 0.17<br>   Stochastic Average Gradient (SAG) descent solver. Multinomial support in<br>   version 0.18.<br>.. versionadded:: 0.19<br>   SAGA solver.<br>.. versionchanged:: 0.22<br>   The default solver changed from 'liblinear' to 'lbfgs' in 0.22.<br>.. versionadded:: 1.2<br>   newton-cholesky solver. Multinomial support in version 1.6.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=max_iter,-int%2C%20default%3D100\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=100<br><br>Maximum number of iterations taken for the solvers to converge.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>For the liblinear and lbfgs solvers set verbose to any positive<br>number for verbosity.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to True, reuse the solution of the previous call to fit as<br>initialization, otherwise, just erase the previous solution.<br>Useless for liblinear solver. See :term:`the Glossary <warm_start>`.<br><br>.. versionadded:: 0.17<br>   *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Does not have any effect.<br><br>.. deprecated:: 1.8<br>   `n_jobs` is deprecated in version 1.8 and will be removed in 1.10.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>DecisionTreeClassifier</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-68\" type=\"checkbox\" ><label for=\"sk-estimator-id-68\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"DecisionTreeClassifier__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=criterion,-%7B%22gini%22%2C%20%22entropy%22%2C%20%22log_loss%22%7D%2C%20default%3D%22gini%22\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"<br><br>The function to measure the quality of a split. Supported criteria are<br>\"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the<br>Shannon information gain, see :ref:`tree_mathematical_formulation`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('splitter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=splitter,-%7B%22best%22%2C%20%22random%22%7D%2C%20default%3D%22best%22\">\n",
       "            splitter\n",
       "            <span class=\"param-doc-description\">splitter: {\"best\", \"random\"}, default=\"best\"<br><br>The strategy used to choose the split at each node. Supported<br>strategies are \"best\" to choose the best split and \"random\" to choose<br>the best random split.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;best&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_depth,-int%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int, default=None<br><br>The maximum depth of the tree. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, then consider `min_samples_split` as the minimum number.<br>- If float, then `min_samples_split` is a fraction and<br>  `ceil(min_samples_split * n_samples)` are the minimum<br>  number of samples for each split.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, then consider `min_samples_leaf` as the minimum number.<br>- If float, then `min_samples_leaf` is a fraction and<br>  `ceil(min_samples_leaf * n_samples)` are the minimum<br>  number of samples for each node.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_features,-int%2C%20float%20or%20%7B%22sqrt%22%2C%20%22log2%22%7D%2C%20default%3DNone\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: int, float or {\"sqrt\", \"log2\"}, default=None<br><br>The number of features to consider when looking for the best split:<br><br>- If int, then consider `max_features` features at each split.<br>- If float, then `max_features` is a fraction and<br>  `max(1, int(max_features * n_features_in_))` features are considered at<br>  each split.<br>- If \"sqrt\", then `max_features=sqrt(n_features)`.<br>- If \"log2\", then `max_features=log2(n_features)`.<br>- If None, then `max_features=n_features`.<br><br>.. note::<br><br>    The search for a split does not stop until at least one<br>    valid partition of the node samples is found, even if it requires to<br>    effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls the randomness of the estimator. The features are always<br>randomly permuted at each split, even if ``splitter`` is set to<br>``\"best\"``. When ``max_features < n_features``, the algorithm will<br>select ``max_features`` at random at each split before finding the best<br>split among them. But the best found split may vary across different<br>runs, even if ``max_features=n_features``. That is the case, if the<br>improvement of the criterion is identical for several splits and one<br>split has to be selected at random. To obtain a deterministic behaviour<br>during fitting, ``random_state`` has to be fixed to an integer.<br>See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow a tree with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>If None then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=class_weight,-dict%2C%20list%20of%20dict%20or%20%22balanced%22%2C%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: dict, list of dict or \"balanced\", default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If None, all classes are supposed to have weight one. For<br>multi-output problems, a list of dicts can be provided in the same<br>order as the columns of y.<br><br>Note that for multioutput (including multilabel) weights should be<br>defined for each class of every column in its own dict. For example,<br>for four-class multilabel classification weights should be<br>[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of<br>[{1:1}, {2:5}, {3:1}, {4:1}].<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``<br><br>For multi-output, the weights of each column of y will be multiplied.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>:ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features), default=None<br><br>Indicates the monotonicity constraint to enforce on each feature.<br>  - 1: monotonic increase<br>  - 0: no constraint<br>  - -1: monotonic decrease<br><br>If monotonic_cst is None, no constraints are applied.<br><br>Monotonicity constraints are not supported for:<br>  - multiclass classifications (i.e. when `n_classes > 2`),<br>  - multioutput classifications (i.e. when `n_outputs_ > 1`),<br>  - classifications trained on data with missing values.<br><br>The constraints hold over the probability of the positive class.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>DecisionTreeClassifierUsingRandom</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-69\" type=\"checkbox\" ><label for=\"sk-estimator-id-69\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"DecisionTreeClassifierUsingRandom__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=criterion,-%7B%22gini%22%2C%20%22entropy%22%2C%20%22log_loss%22%7D%2C%20default%3D%22gini%22\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"<br><br>The function to measure the quality of a split. Supported criteria are<br>\"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the<br>Shannon information gain, see :ref:`tree_mathematical_formulation`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('splitter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=splitter,-%7B%22best%22%2C%20%22random%22%7D%2C%20default%3D%22best%22\">\n",
       "            splitter\n",
       "            <span class=\"param-doc-description\">splitter: {\"best\", \"random\"}, default=\"best\"<br><br>The strategy used to choose the split at each node. Supported<br>strategies are \"best\" to choose the best split and \"random\" to choose<br>the best random split.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;random&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_depth,-int%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int, default=None<br><br>The maximum depth of the tree. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, then consider `min_samples_split` as the minimum number.<br>- If float, then `min_samples_split` is a fraction and<br>  `ceil(min_samples_split * n_samples)` are the minimum<br>  number of samples for each split.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, then consider `min_samples_leaf` as the minimum number.<br>- If float, then `min_samples_leaf` is a fraction and<br>  `ceil(min_samples_leaf * n_samples)` are the minimum<br>  number of samples for each node.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_features,-int%2C%20float%20or%20%7B%22sqrt%22%2C%20%22log2%22%7D%2C%20default%3DNone\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: int, float or {\"sqrt\", \"log2\"}, default=None<br><br>The number of features to consider when looking for the best split:<br><br>- If int, then consider `max_features` features at each split.<br>- If float, then `max_features` is a fraction and<br>  `max(1, int(max_features * n_features_in_))` features are considered at<br>  each split.<br>- If \"sqrt\", then `max_features=sqrt(n_features)`.<br>- If \"log2\", then `max_features=log2(n_features)`.<br>- If None, then `max_features=n_features`.<br><br>.. note::<br><br>    The search for a split does not stop until at least one<br>    valid partition of the node samples is found, even if it requires to<br>    effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls the randomness of the estimator. The features are always<br>randomly permuted at each split, even if ``splitter`` is set to<br>``\"best\"``. When ``max_features < n_features``, the algorithm will<br>select ``max_features`` at random at each split before finding the best<br>split among them. But the best found split may vary across different<br>runs, even if ``max_features=n_features``. That is the case, if the<br>improvement of the criterion is identical for several splits and one<br>split has to be selected at random. To obtain a deterministic behaviour<br>during fitting, ``random_state`` has to be fixed to an integer.<br>See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow a tree with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>If None then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=class_weight,-dict%2C%20list%20of%20dict%20or%20%22balanced%22%2C%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: dict, list of dict or \"balanced\", default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If None, all classes are supposed to have weight one. For<br>multi-output problems, a list of dicts can be provided in the same<br>order as the columns of y.<br><br>Note that for multioutput (including multilabel) weights should be<br>defined for each class of every column in its own dict. For example,<br>for four-class multilabel classification weights should be<br>[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of<br>[{1:1}, {2:5}, {3:1}, {4:1}].<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``<br><br>For multi-output, the weights of each column of y will be multiplied.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>:ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features), default=None<br><br>Indicates the monotonicity constraint to enforce on each feature.<br>  - 1: monotonic increase<br>  - 0: no constraint<br>  - -1: monotonic decrease<br><br>If monotonic_cst is None, no constraints are applied.<br><br>Monotonicity constraints are not supported for:<br>  - multiclass classifications (i.e. when `n_classes > 2`),<br>  - multioutput classifications (i.e. when `n_outputs_ > 1`),<br>  - classifications trained on data with missing values.<br><br>The constraints hold over the probability of the positive class.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>GaussianNaiveBayes</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-70\" type=\"checkbox\" ><label for=\"sk-estimator-id-70\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GaussianNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.naive_bayes.GaussianNB.html\">?<span>Documentation for GaussianNB</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"GaussianNaiveBayes__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('priors',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.naive_bayes.GaussianNB.html#:~:text=priors,-array-like%20of%20shape%20%28n_classes%2C%29%2C%20default%3DNone\">\n",
       "            priors\n",
       "            <span class=\"param-doc-description\">priors: array-like of shape (n_classes,), default=None<br><br>Prior probabilities of the classes. If specified, the priors are not<br>adjusted according to the data.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('var_smoothing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.naive_bayes.GaussianNB.html#:~:text=var_smoothing,-float%2C%20default%3D1e-9\">\n",
       "            var_smoothing\n",
       "            <span class=\"param-doc-description\">var_smoothing: float, default=1e-9<br><br>Portion of the largest variance of all features that is added to<br>variances for calculation stability.<br><br>.. versionadded:: 0.20</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1e-09</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-16');</script></body>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('LogisticRegressor1',\n",
       "                              LogisticRegression(max_iter=1000)),\n",
       "                             ('DecisionTreeClassifier',\n",
       "                              DecisionTreeClassifier()),\n",
       "                             ('DecisionTreeClassifierUsingRandom',\n",
       "                              DecisionTreeClassifier(max_depth=5,\n",
       "                                                     splitter='random')),\n",
       "                             ('GaussianNaiveBayes', GaussianNB())])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voteHard.fit(X,y) # Fit the X and y values \n",
    "# To be honest this should be X_train and Y_train but for simplicity we are gonna pass X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "49d2feaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = voteHard.predict(X) # Predict species based on X features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "f48eef9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.93333333, 1.        , 0.93333333, 0.93333333,\n",
       "       0.93333333, 0.93333333, 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(voteHard,X,y,cv=10,scoring='accuracy') # Calculate the cross val score to evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b531728b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9666666666666666)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(voteHard,X,y,cv=10,scoring='accuracy').mean() # Calculate the mean of  cross val score to evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "13d334e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.98      1.00      0.99        50\n",
      "           2       1.00      0.98      0.99        50\n",
      "\n",
      "    accuracy                           0.99       150\n",
      "   macro avg       0.99      0.99      0.99       150\n",
      "weighted avg       0.99      0.99      0.99       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y,pred1)) # Examine the different classfication metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "42e48f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf1 = pd.DataFrame(confusion_matrix(y,pred1)) # Convert to dataframe for better visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "8640d62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "2",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "3df96a7d-7a03-495e-aa27-a46e03d991c6",
       "rows": [
        [
         "0",
         "50",
         "0",
         "0"
        ],
        [
         "1",
         "0",
         "50",
         "0"
        ],
        [
         "2",
         "0",
         "1",
         "49"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2\n",
       "0  50   0   0\n",
       "1   0  50   0\n",
       "2   0   1  49"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "fd32e631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAGiCAYAAADp4c+XAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAI2BJREFUeJzt3Qt4VNX57/HfTCABA0lMgARElItcFFEbESIIiijFiiCIl1oRSo+imBZyrJpeRDz+jS0WkHJrLQWtBi1atHiqHIwCf/4GBCwqqPFaQTEBAiQSycVkzrO3jyOzE5SRSfbOXt+Pz3pI1p7MrMmMeed991prB0KhUEgAAMAYQbcHAAAAmhbBHwAAwxD8AQAwDMEfAADDEPwBADAMwR8AAMMQ/AEAMAzBHwAAwxD8AQAwDMEfAADDEPwBAPCIe+65R4FAIKL17t07fLyyslJTp05VWlqa2rRpo3HjxqmkpCTqxyH4AwDgIWeccYY+++yzcNuwYUP42PTp07Vq1SqtWLFC69at0+7duzV27NioH6NFjMcMAACOQ4sWLZSRkVGvv6ysTEuWLFF+fr6GDRtm9y1dulR9+vTRxo0bNXDgwGN+DDJ/AAAaUVVVlcrLyyOa1Xc07733njp16qRu3brp+uuv186dO+3+rVu3qqamRsOHDw/f1jol0KVLFxUWFjbPzH9KIMntIcBDFlfscnsIALzshORmE5MyZuRo5syZEX0zZsywz+87DRgwQMuWLVOvXr3skr/1cxdccIG2b9+u4uJixcfHKyUlJeJn0tPT7WPNMvgDAOAVwRjeV25urnJyciL6EhISGrztyJEjw1/369fP/jBwyimn6O9//7tat24dszFR9gcAoBFZgT4pKSmiHS34O1lZfs+ePfX+++/b8wCqq6t18ODBiNtYs/0bmiPwbQj+AAA4BAOBmLXjcejQIX3wwQfq2LGjMjMz1bJlSxUUFISPFxUV2XMCsrKyorpfyv4AAHgkM7799ts1atQou9RvLeOz5gbExcXpuuuuU3JysiZPnmyfQkhNTbUrCNnZ2Xbgj2amv4XgDwCAQ/D4Evbv7ZNPPrEDfWlpqdq3b6/Bgwfby/isry1z5sxRMBi0N/exVgyMGDFCCxcujPpxAqFQKCQPYLY/jsRsfwBuzvafFhe7+59bWyavIfMHAMCwCXEEfwAAHI53op7X+f3DDQAAcCDzBwDAsMyY4A8AgEdm+zcVv3+4AQAADmT+AAAYlhkT/AEAcAgw2x8AAPgJmT8AAA6U/QEAMEzQ57P9yfwBADAs8/f78wMAAA5k/gAAGLa3P8EfAADDyuJ+f34AAMCBzB8AAAdm+wMAYJig/M3vzw8AADhQ9gcAwCEoZvsDAGCUoL9jP2V/AABMQ9kfAADDJsQR/AEAMKzsT/AHAMCwCX9+r2wAAAAHMn8AABwo+wMAYJig/M3vzw8AADhQ9gcAwIGyPwAAhgky2x8AAPgJZX8AABwo+wMAYJiA/I3Z/gAAGIayPwAADpT9AQAwTNDnhX8yfwAADMv8OecPAIBhyPwBADAsMyb4AwDg4POqv+8/3AAAAAcyfwAAHIIBf+f+BH8AABz8Hfop+wMAYBwyfwAADMv8Cf4AABgW/JntDwCAYcj8AQBwCPh8tj+ZfxO7fEauFofKI9o9b28JH2+RkKBr5/9BD+77j+Z+vls3PfU3te3QvqmHCQ94/MkVGnbZaJ05YLDG3zBJb2zf4faQ4CLeD00rEMPmRQR/F3y6/S3dkdEj3GYNvjR8bPycPPUb9UM9PH6CZg+9TCmdOmrKPx53Y5hw0b9Wr1HeH+Zq6s0/08r8R9W752mafOvPVbp/P6+LgXg/uBMcgzFqXuTVcfla3ZdfqrxkT7hVlH71B71VUpIGTZ6gp3J+paKX12vna9v0yKRb1H3QQHUd0N/tYaMJLX0sX1ePHaNxo0epR/dumvnru9SqVSs9/cwqXgcD8X6A6+f89+3bp7/+9a8qLCxUcXGx3ZeRkaHzzz9fEydOVPv2lKi/S4fTuuuBT4tUU1mpjwo3a2XuPTqw6xOdknm2WsTH6+0X14ZvW1L0nko/3qluWefpo02bo3250AxV19Rox9vv6Oaf3hjuCwaDOn9Af/37jTddHRuaHu8HdwS8Wq93I/PfvHmzevbsqXnz5ik5OVlDhgyxm/W11de7d29t2fLN+eujqaqqUnl5eUSrVUgm+GjTFj0y8Rb98YdjtfyWHKV1PUW3//cLSmjTRkkZ6aqpqtLhsrKIn/m8ZK+SMjq4NmY0rQMHDqq2tlZpqakR/WlpqdpXWsrLYRjeD+4IxPC/Zp/5Z2dna/z48Vq8eHG9mZChUEhTpkyxb2NVBb5NXl6eZs6cGdGXqXidqwT53Y4X1oS//vTNHfaHgfs/3q7Mq69UzeFKV8cGADBDVJn/66+/runTpze4BMLqs45t27btO+8nNzdXZWVlEe0cxctEVpZf8u4H6tCjm8qLS9QyIUGtk5MjbtM2vb3Ki/e4NkY0rRNPTFFcXFy9yX2lpfvVLi2Nl8MwvB/cEWC2/zesc/uvvvrqUX9Z1rH09PTv/KUmJCQoKSkposV5tDTS2BISE9W+e1eVfVaij7du05fV1ep98dDw8fSePZR2Shd9WHj03zv8Jb5lS53Rp7cKj5jjUVdXp8JXt+icfme6OjY0Pd4P7gj4PPhHVfa//fbbddNNN2nr1q26+OKLw4G+pKREBQUFevjhh/Xggw821lh9Ydys+/TGque1/+NdSu6UoVEzf6W62lptXr5CleXl+p8lj+qq2ferYv8BVZZ/rmv+OEsfvLKJyX6GmfSTH+vOu2eq7+l91K/vGXok/wkdPnxYY0df7vbQ4ALeD4i1qIL/1KlT1a5dO82ZM0cLFy60JyVZrBJlZmamli1bpquvvjrmg/STlM4nafLyvyoxLVWH9u7T+xs26ncDL9ahfV9N5FoxPVehupBufvoxtUiI11urC7T81hy3h40mdtmIS7T/wAHNW/Rn7S0tVZ9ePfWXBQ9R9jcU74emF/Rqyh4jgZA1U+97qKmpsZf9WawPBC1btjyugUwJJB3Xz8NfFlfscnsIALzshMi5UbH2fLtOMbuvkft2yzd7+1vBvmPHjrEdDQAAaHRc2AcAAAefV/0J/gAAOLHDHwAAhgl4YKnfAw88YO+hM23atHBfZWWlPfk+LS1Nbdq00bhx4+wVd9Hiwj4AAHiMtZ3+n/70J/Xr1y+i39pMb9WqVVqxYoXWrVun3bt3a+zYsVHfP8EfAACHoAIxa9E6dOiQrr/+envvnBNPPDHcb+2Gu2TJEs2ePVvDhg2zl9gvXbpUr7zyijZu3BjVYxD8AQBoxLJ/Qxezs/qOxirr/+hHP9Lw4cMj+q0N9qxl9kf2WxfU69Kly3deU8eJ4A8AQCOyLmZnXf32yGb1NeSJJ57Qa6+91uDx4uJixcfHKyUlJaLf2m3XOhYNlvoBANCIs/2ti9nl5OTUu8aN065du/SLX/xCa9asUatWrdSYCP4AADTiOn8r0DcU7J2ssv6ePXv0gx/8INxnbaO/fv16zZ8/X6tXr1Z1dbUOHjwYkf1bs/2tC+9Fg+APAIAHWBfMe/PNNyP6Jk2aZJ/Xv/POO3XyySfbu+taF9KzlvhZioqKtHPnTmVlZUX1WAR/AAAcAi7s8de2bVv17ds3oi8xMdFe0/91/+TJk+1TCKmpqUpKSlJ2drYd+AcOHBjVYxH8AQBoJlf1s66qGwwG7czfWjEwYsQI+yq7TXZVv1jjqn44Elf1A+DmVf3Wp3eO2X0NKflEXkPmDwCAg0cT/5gh+AMA4EDwBwDAMAGfh392+AMAwDCU/QEAaMQd/ryI4A8AgGFlcb8/PwAA4EDmDwCAg8+r/gR/AACcAj4/6U/ZHwAAw1D2BwDAwd95P8EfAADjgj9lfwAADEPZHwAAwyb8EfwBAHAI+jv2E/wBAHAK+Dz6c84fAADDUPYHAMDB56f8Cf4AAJgW/Cn7AwBgGMr+AAA4sNQPAADDBCj7AwAAP6HsDwCAA2V/AAAME6DsDwAA/ISyPwAADkGfp/4EfwAAHHwe+wn+AACYNuGPHf4AADAMZX8AABwCPk+NCf4AADhQ9gcAAL5C5g8AgIPP5/sR/AEAcKLsDwAAfIWyPwAADpT9AQAwTNDn0d/nKxkBAIATZX8AABx8nvgT/AEAMG22P5k/AAAOPo/93gn+iyt2uT0EeMiUxJPdHgI8hL8PgE+DPwAAXhEg8wcAwCyBoL+jP0v9AAAwDGV/AAAcKPsDAGCYoM+jP2V/AAAMQ9kfAAAHnyf+BH8AAEzb4Y+yPwAAhqHsDwCAg88Tf4I/AACmlf3J/AEAcPB57OecPwAApiHzBwDAgbI/AACGCfh8LZzPnx4AAHCi7A8AgANlfwAATBP093R/yv4AABiGsj8AAIYt9CfzBwCggXP+sWrRWLRokfr166ekpCS7ZWVl6fnnnw8fr6ys1NSpU5WWlqY2bdpo3LhxKikpUbQI/gAANHTOP1YtCp07d9YDDzygrVu3asuWLRo2bJhGjx6tHTt22MenT5+uVatWacWKFVq3bp12796tsWPHKlqBUCgUkhd8Ueb2COAhUxJPdnsI8JDFFbvcHgK85oTkRr378uE/iNl9Jb342nH9fGpqqmbNmqWrrrpK7du3V35+vv215Z133lGfPn1UWFiogQMHHvN9cs4fAIBGPOdfVVVltyMlJCTY7dvU1tbaGX5FRYVd/reqATU1NRo+fHj4Nr1791aXLl2iDv6U/QEAcAgEAzFreXl5Sk5OjmhW39G8+eab9vl868PBlClTtHLlSp1++ukqLi5WfHy8UlJSIm6fnp5uH4sGmT8AAI0oNzdXOTk5EX3flvX36tVL27ZtU1lZmZ566indeOON9vn9WCL4AwDQiGX/YynxH8nK7nv06GF/nZmZqc2bN+uhhx7SNddco+rqah08eDAi+7dm+2dkZEQ1Jsr+AAA0Ytn/eNXV1dlzBqwPAi1btlRBQUH4WFFRkXbu3GnPCYgGmT8AAB46RTBy5Eh7Et/nn39uz+xfu3atVq9ebc8VmDx5sn0KwVoBYO0DkJ2dbQf+aCb7WQj+AAB4ZIe/PXv2aMKECfrss8/sYG9t+GMF/ksuucQ+PmfOHAWDQXtzH6saMGLECC1cuDDqx2GdPzyJdf44Euv80dTr/A+Nii6T/jZtVm2U13DOHwAAw1D2BwDAIdo9+Zsbgj8AAE4xmKXvZQR/AACcfJ75c84fAADDkPkDAOAQ8HlqTPAHAMCJsj8AAPATMn8AABxisSe/lxH8AQBwouwPAAD8hMwfAAAnyv4AAJglQNkfAAD4CWV/AACcKPsDAGCYAEv9AAAwSsDnwd/nuxcDAAAnzvkDAODEOX8AAMwSoOwPAAD8hLI/AABOlP0BADBMgNn+AADAR1jq5xGPP7lCwy4brTMHDNb4Gybpje073B4SmsDlM3K1OFQe0e55e0v4eIuEBF07/w96cN9/NPfz3brpqb+pbYf2vDYG4m9E0woEAzFrXkTw94B/rV6jvD/M1dSbf6aV+Y+qd8/TNPnWn6t0/363h4Ym8On2t3RHRo9wmzX40vCx8XPy1G/UD/Xw+AmaPfQypXTqqCn/eJzXxTD8jXCp7B+IUfMggr8HLH0sX1ePHaNxo0epR/dumvnru9SqVSs9/cwqt4eGJlD35ZcqL9kTbhWlX33oa5WUpEGTJ+ipnF+p6OX12vnaNj0y6RZ1HzRQXQf057UxCH8jEGsEf5dV19Rox9vv6Pwj/pgHg0H7+3+/8aarY0PT6HBadz3waZH+zwev66eP/UUnntzZ7j8l82y1iI/X2y+uDd+2pOg9lX68U92yzuPlMQR/I1wSDMSueZArS/2qqqrsdqSE2iolJCTINAcOHFRtba3SUlMj+tPSUvXhfz52bVxoGh9t2qJHJt5iB/Xkjhn60Yy7dPt/v6B7+w5UUka6aqqqdLisLOJnPi/Zq6SMDrxEhuBvhDsCHi3Xezbz37Vrl376059+623y8vKUnJwc0fIenB3roQCet+OFNXrtqWf06Zs79Nb/K9D8y67SCSnJyrz6SreHBpgt6O/MP+bBf//+/XrkkUe+9Ta5ubkqKyuLaLm358hEJ56Yori4uHqT+0pL96tdWppr44I7rCy/5N0P1KFHN5UXl6hlQoJaJydH3KZtenuVF+/hJTIEfyPgibL/P//5z289/uGHH37nfVjl/Xol/i9CMlF8y5Y6o09vFW7arOEXXWj31dXVqfDVLfrJNePdHh6aWEJiotp376pNf3tCH2/dpi+rq9X74qH69z+++v8uvWcPpZ3SRR8WvsprYwj+Rrgk4M2M3bXgP2bMGPtcSCgUMvZcSaxN+smPdefdM9X39D7q1/cMPZL/hA4fPqyxoy93e2hoZONm3ac3Vj2v/R/vUnKnDI2a+SvV1dZq8/IVqiwv1/8seVRXzb5fFfsPqLL8c13zx1n64JVN+mjTZl4bg/A3wgUBf8exqIN/x44dtXDhQo0ePbrB49u2bVNmZmYsxmaMy0Zcov0HDmjeoj9rb2mp+vTqqb8seIiyvwFSOp+kycv/qsS0VB3au0/vb9io3w28WIf2ldrHV0zPVagupJuffkwtEuL11uoCLb/VzFNkJuNvBGItEPq2FL4BV1xxhc4++2zde++9DR5//fXXdc4559il66h8ETmjGWabkniy20OAhyyu2OX2EOA1J0TOhYm1L3/RcIL7fbR46Fk1+8z/l7/8pSoqKo56vEePHnr55ZePd1wAALgn6O9tcKIO/hdccMG3Hk9MTNTQoUOPZ0wAAMBvm/wAAOBpASb8AQBgloC/g7+/T2oAAIB6KPsDAGBY5k/wBwDAidn+AAAYJuDvzJ9z/gAAGIayPwAAhmX+BH8AAAwL/pT9AQAwDJk/AABOzPYHAMAwAcr+AADARyj7AwBgWOZP8AcAwLDgz2x/AAAMQ+YPAIBDgNn+AAAYJuDvsj+ZPwAAhgV/zvkDAGAYMn8AAAzL/An+AAA4+XzCn7+fHQAAqIfMHwAAJ8r+AAAYJuDvc/6U/QEAMAzBHwCAhjL/WLUo5OXlqX///mrbtq06dOigMWPGqKioKOI2lZWVmjp1qtLS0tSmTRuNGzdOJSUlUT0OwR8AgIZm+8eqRWHdunV2YN+4caPWrFmjmpoaXXrppaqoqAjfZvr06Vq1apVWrFhh33737t0aO3ZsVI/DhD8AABpRVVWV3Y6UkJBgN6cXXngh4vtly5bZFYCtW7dqyJAhKisr05IlS5Sfn69hw4bZt1m6dKn69Oljf2AYOHDgMY2JzB8AgEYs+1ul/OTk5Ihm9R0LK9hbUlNT7X+tDwFWNWD48OHh2/Tu3VtdunRRYWGhjhWZPwAAjTjbPzc3Vzk5ORF9DWX9TnV1dZo2bZoGDRqkvn372n3FxcWKj49XSkpKxG3T09PtY8eK4A8AQCPu8He0Ev93sc79b9++XRs2bFCsUfYHAMBjbrvtNj333HN6+eWX1blz53B/RkaGqqurdfDgwYjbW7P9rWPHiuAPAIBHlvqFQiE78K9cuVIvvfSSunbtGnE8MzNTLVu2VEFBQbjPWgq4c+dOZWVlHfPjUPYHAMAjO/xZpX5rJv+zzz5rr/X/+jy+NUmwdevW9r+TJ0+25xBYkwCTkpKUnZ1tB/5jnelvIfgDAOARixYtsv+98MILI/qt5XwTJ060v54zZ46CwaC9uY+1hHDEiBFauHBhVI9D8AcAwCOZv1X2/y6tWrXSggUL7PZ9EfwBAGjE2f5e5O9nBwAA6iHzBwDAsEv6EvwBADAs+FP2BwDAMGT+AAA4BfydGxP8AQBwCvq77E/wBwDAsMzf388OAADUQ+YPAIBhs/0J/gAAOLHDHwAA8BMyfwAAnCj7AwBgmIC/58P7+9kBAIB6KPsDAOBE2R8AAMME/V0YJ/OHJy0u/9DtIcBDctp2cXsI8JjZtWVuD6FZI/gDAOBE2R8AAMMEKPsDAGCWoL+39/X3RxsAAFAP5/wBAHCi7A8AgGEClP0BAICPUPYHAMCJsj8AAIYJUvYHAAA+QtkfAADDJvwR/AEAMOycv7+fHQAAqIfMHwAAwyb8EfwBADCs7E/wBwDAsAl//v5oAwAA6iHzBwDAibI/AACGCVL2BwAAPkLZHwAAJ8r+AAAYJkDZHwAA+AhlfwAAnIL+XglP8AcAwImyPwAA8BMyfwAAnJjtDwCAYQL+nu1P5g8AgGET/vz97AAAQD1k/gAAOFH2BwDAMAF/F8b9/ewAAEA9lP0BAHCi7A8AgGEC/i6M+/vZAQCAeij7AwDgFGSTHwAAzBLwd2Hc388OAADUQ9kfAAAnZvsDAGCYgL8L42T+AAA4BHye+fv7ow0AAKiHzB8AACfK/gAAGCbg78K4v58dAADNyPr16zVq1Ch16tTJnnfwzDPPRBwPhUK6++671bFjR7Vu3VrDhw/Xe++9F/XjEPwBAGhoh79YtShUVFTorLPO0oIFCxo8/vvf/17z5s3T4sWLtWnTJiUmJmrEiBGqrKyM6nE45w8AQCOW/auqqux2pISEBLs5jRw50m4NsbL+uXPn6je/+Y1Gjx5t9z366KNKT0+3KwTXXnvtMY+JzB8AgEaUl5en5OTkiGb1Reujjz5ScXGxXer/mnVfAwYMUGFhYVT3ReYPAIBTDNf55+bmKicnJ6Kvoaz/u1iB32Jl+keyvv/62LEi+AMA0Ihl/6OV+N1E2R8AgGYgIyPD/rekpCSi3/r+62PHiuAPAEBDZf9YtRjp2rWrHeQLCgrCfeXl5fas/6ysrKjui7I/AAAe2eTn0KFDev/99yMm+W3btk2pqanq0qWLpk2bpvvuu0+nnXaa/WHgt7/9rb0nwJgxY6J6HII/AABOUa7Pj5UtW7booosuCn//9UTBG2+8UcuWLdMdd9xh7wVw00036eDBgxo8eLBeeOEFtWrVKqrHoezvEY8/uULDLhutMwcM1vgbJumN7TvcHhJcsvm1bZoy/Q4N/uEV6nXuIL24dj2vhaGG3TFds2vLNGb2N8vC0rp11aSnH9O9xR/o/gO7NOGJZWrTob2r40TsXHjhhfZ6fmezAr/F2vXv3nvvtWf3Wxv7vPjii+rZs2fUj0Pw94B/rV6jvD/M1dSbf6aV+Y+qd8/TNPnWn6t0/363hwYXfHH4sHqd1kMz7vzf/P4NdvK5P1DWTZO0+/U3w33xJ5ygm19YqVBIWjR8lP54wQjFxbfUz5590veXoHWl7B+IUfMgb47KMEsfy9fVY8do3OhR6tG9m2b++i67hPP0M6vcHhpcMHRQlqbfepMuuWgov39DxScm6vq/Pay/3/xzfXHgYLj/1EEDlXpqFy2fdIs+2/6W3ZZPvEWdzz1HPYbxfvH7hL9YIvi7rLqmRjvefkfnD+gf7gsGg/b3/37jm0/8AMwxbv6Devtfq/VewdqI/hYJ8XYJ+MsjtoqtqaxUqK5O3QYNdGGkaK4I/i47cOCgamtrlZaaGtGflpaqfaWlro0LgDvOvmacOp9zlv7vr2bWO/bxxs2qrqjQqAdmqmXr1vZpgCtm3ae4Fi2U1DG6dd74DpT9Ix0+fFgbNmzQW2+9Ve93ZU0+sC4y8F2sCxxYaxOPbM6LHgCAaVI6n6Qr5zygx274XxHZ/dcq9pXqkWsm6vTLRyqvfLf+68AutU5J1q6t21RXV+fKmH0rQNk/7N1331WfPn00ZMgQnXnmmRo6dKg+++yz8PGysjJNmjTp+13k4MHZMtGJJ6YoLi6u3uS+0tL9apeW5tq4ADS9zplnq216B+VsWa9ZVaV263HhBRqcPcX+OhAM6t01L+n+nmdrRkZ3/bZDN+XfeLOST+qo/R/+h5cMjbPO/84771Tfvn3tdYjW+kJrs4FBgwZp7dq19uYDx3WRg9rorkXsF/EtW+qMPr1VuGmzhl90od1nfYIvfHWLfnLNeLeHB6AJvVewTr/vF3nu/tolC7Wn6F299Pu59rn9r1WUfpUw9LhoiL3Ub/uqf/FaxVLA32fFowr+r7zyir2msF27dnZbtWqVbr31Vl1wwQV6+eWXlZiY+P0vcvBFSKaa9JMf6867Z6rv6X3Ur+8ZeiT/Cfv0ytjRl7s9NLig4osvtHPXJ+HvP/l0t94uelfJyUnqFOX+3Wheqg4dUvGOtyP6rHP8X5TuD/f3n3i99rxdpEN7S3VqVn+NmfM7rZ+7QHvf/WZXOMRAkOAfZgWkFi2++bxgrStdtGiRbrvtNvsUQH5+Pu+57+GyEZdo/4EDmrfoz9pbWqo+vXrqLwseouxvqO1vvaMJU7LD3+fN+aP975WXj9QD9/zGxZHBCzr0PE0/+q8ZOiH1RO3/z069eP+DWjd3gdvDQjMTCFnrRo7Reeedp+zsbN1www31jlkfAB5//HF78p41ez1qX5RF/zPwr9oat0cAD8lJ6e72EOAx1s6HjSlUtDFm9xXo5b1lmFHVNa688kotX768wWPz58/XddddZ69BBQCgWQv4e4e/qDL/RkXmjyOR+eMIZP5o8sz/vc0xu6/Aad9s4uYV3vxIAgAAGg2X9AUAwMmj5fpYIfgDAODk0QvyxIq/P9oAAIB6yPwBAHBikx8AAAwToOwPAAB8hLI/AABOzPYHAMAwAcr+AADARyj7AwBQj78zf4I/AACGlf0J/gAAGBb82eEPAADDkPkDAFCPvzN/gj8AAE6U/QEAgJ+Q+QMAYFbVn+APAIBp0Z/Z/gAAGIayPwAAhk34I/gDAGBY8KfsDwCAYcj8AQCox9+ZP8EfAADDyv4EfwAA6vF38OecPwAAhiHzBwDAibI/AACGCVD2BwAAPkLZHwCAevyd+RP8AQBwCFD2BwAAfkLmDwCAk88zf4I/AAD1+Dv4s8kPAACGIfMHAMCJsj8AAIYJ+LvsT+YPAEA9/g7+nPMHAMAwZP4AADhR9gcAwDAB+RplfwAADEPZHwAAw1J/gj8AAIad86fsDwCAYcj8AQAwLPMn+AMAUI+/gz9lfwAADEPmDwCAE2V/AAAME6DsDwCAYQIxbNFZsGCBTj31VLVq1UoDBgzQq6++GvNnxzl/AAA84sknn1ROTo5mzJih1157TWeddZZGjBihPXv2xPRxAqFQKCQv+KLM7RHAS2pr3B4BPCQnpbvbQ4DHzK4tazYxqSqulaqqqiL6EhIS7OZkZfr9+/fX/Pnz7e/r6up08sknKzs7W3fddVfMxiQr+MMbKisrQzNmzLD/BXg/gL8P/jBjxgwryY5oVp9TVVVVKC4uLrRy5cqI/gkTJoSuuOKKmI7JO5k/VF5eruTkZJWVlSkpKYnfiOF4P4D3gz9UVVUdU+a/e/dunXTSSXrllVeUlZUV7r/jjju0bt06bdq0KWZjYqkfAACN6Gglfjcx4Q8AAA9o166d4uLiVFJSEtFvfZ+RkRHTxyL4AwDgAfHx8crMzFRBQUG4z5rwZ31/5GmAWKDs7yFWWcha3uG18hDcwfsBvB/Mk5OToxtvvFHnnnuuzjvvPM2dO1cVFRWaNGlSTB+HCX8AAHiItcxv1qxZKi4u1tlnn6158+bZSwBjieAPAIBhOOcPAIBhCP4AABiG4A8AgGEI/gAAGIbg7xFNcQlHNA/r16/XqFGj1KlTJwUCAT3zzDNuDwkuysvLsy/00rZtW3Xo0EFjxoxRUVERrwmOC8HfoEs4onmw1vRa7wHrAyFg7ek+depUbdy4UWvWrFFNTY0uvfRS+30CfF8s9fOAJruEI5odK/NfuXKlne0Blr1799oVAOtDwZAhQ/il4Hsh83dZdXW1tm7dquHDh4f7gsGg/X1hYaGrYwPgPdZVPy2pqaluDwXNGMHfZfv27VNtba3S09Mj+q3vrd2dAOBrVlVw2rRpGjRokPr27csvBt8be/sDQDNhnfvfvn27NmzY4PZQ0MwR/A26hCOA5uu2227Tc889Z68G6dy5s9vDQTNH2d+gSzgCaH5CoZAd+K2Jny+99JK6du3q9pDgA2T+Bl3CEc3DoUOH9P7774e//+ijj7Rt2zZ7gleXLl1cHRvcKfXn5+fr2Weftdf6fz0XKDk5Wa1bt+YlwffCUj+DLuGI5mHt2rW66KKL6vVbHxCXLVvmypjg7nLPhixdulQTJ05s8vHAHwj+AAAYhnP+AAAYhuAPAIBhCP4AABiG4A8AgGEI/gAAGIbgDwCAYQj+AAAYhuAPAIBhCP4AABiG4A8AgGEI/gAAyCz/H+CLrDo9ZVLmAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the confusion matrix using heatmap\n",
    "sns.heatmap(\n",
    "    data = conf1,\n",
    "    cmap = 'Reds',\n",
    "    annot = True # For values to be displayed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "1040e239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets do the same process but with soft Voting Ensemble\n",
    "voteSoft = VotingClassifier(\n",
    "    estimators = estimators ,  # Pass the variables in which we made the list of the modelnames and models (estimators)\n",
    "    voting = 'soft'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "f4e2d1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-17.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-17.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-17 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-17 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-17 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-17 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-17 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-17 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-17 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-17 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-17 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;LogisticRegressor1&#x27;,\n",
       "                              LogisticRegression(max_iter=1000)),\n",
       "                             (&#x27;DecisionTreeClassifier&#x27;,\n",
       "                              DecisionTreeClassifier()),\n",
       "                             (&#x27;DecisionTreeClassifierUsingRandom&#x27;,\n",
       "                              DecisionTreeClassifier(max_depth=5,\n",
       "                                                     splitter=&#x27;random&#x27;)),\n",
       "                             (&#x27;GaussianNaiveBayes&#x27;, GaussianNB())],\n",
       "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-71\" type=\"checkbox\" ><label for=\"sk-estimator-id-71\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>VotingClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html\">?<span>Documentation for VotingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html#:~:text=estimators,-list%20of%20%28str%2C%20estimator%29%20tuples\">\n",
       "            estimators\n",
       "            <span class=\"param-doc-description\">estimators: list of (str, estimator) tuples<br><br>Invoking the ``fit`` method on the ``VotingClassifier`` will fit clones<br>of those original estimators that will be stored in the class attribute<br>``self.estimators_``. An estimator can be set to ``'drop'`` using<br>:meth:`set_params`.<br><br>.. versionchanged:: 0.21<br>    ``'drop'`` is accepted. Using None was deprecated in 0.22 and<br>    support was removed in 0.24.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">[(&#x27;LogisticRegressor1&#x27;, ...), (&#x27;DecisionTreeClassifier&#x27;, ...), ...]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('voting',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html#:~:text=voting,-%7B%27hard%27%2C%20%27soft%27%7D%2C%20default%3D%27hard%27\">\n",
       "            voting\n",
       "            <span class=\"param-doc-description\">voting: {'hard', 'soft'}, default='hard'<br><br>If 'hard', uses predicted class labels for majority rule voting.<br>Else if 'soft', predicts the class label based on the argmax of<br>the sums of the predicted probabilities, which is recommended for<br>an ensemble of well-calibrated classifiers.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;soft&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html#:~:text=weights,-array-like%20of%20shape%20%28n_classifiers%2C%29%2C%20default%3DNone\">\n",
       "            weights\n",
       "            <span class=\"param-doc-description\">weights: array-like of shape (n_classifiers,), default=None<br><br>Sequence of weights (`float` or `int`) to weight the occurrences of<br>predicted class labels (`hard` voting) or class probabilities<br>before averaging (`soft` voting). Uses uniform weights if `None`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of jobs to run in parallel for ``fit``.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.<br><br>.. versionadded:: 0.18</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('flatten_transform',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html#:~:text=flatten_transform,-bool%2C%20default%3DTrue\">\n",
       "            flatten_transform\n",
       "            <span class=\"param-doc-description\">flatten_transform: bool, default=True<br><br>Affects shape of transform output only when voting='soft'<br>If voting='soft' and flatten_transform=True, transform method returns<br>matrix with shape (n_samples, n_classifiers * n_classes). If<br>flatten_transform=False, it returns<br>(n_classifiers, n_samples, n_classes).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html#:~:text=verbose,-bool%2C%20default%3DFalse\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: bool, default=False<br><br>If True, the time elapsed while fitting will be printed as it<br>is completed.<br><br>.. versionadded:: 0.23</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>LogisticRegressor1</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-72\" type=\"checkbox\" ><label for=\"sk-estimator-id-72\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"LogisticRegressor1__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=penalty,-%7B%27l1%27%2C%20%27l2%27%2C%20%27elasticnet%27%2C%20None%7D%2C%20default%3D%27l2%27\">\n",
       "            penalty\n",
       "            <span class=\"param-doc-description\">penalty: {'l1', 'l2', 'elasticnet', None}, default='l2'<br><br>Specify the norm of the penalty:<br><br>- `None`: no penalty is added;<br>- `'l2'`: add a L2 penalty term and it is the default choice;<br>- `'l1'`: add a L1 penalty term;<br>- `'elasticnet'`: both L1 and L2 penalty terms are added.<br><br>.. warning::<br>   Some penalties may not work with some solvers. See the parameter<br>   `solver` below, to know the compatibility between the penalty and<br>   solver.<br><br>.. versionadded:: 0.19<br>   l1 penalty with SAGA solver (allowing 'multinomial' + L1)<br><br>.. deprecated:: 1.8<br>   `penalty` was deprecated in version 1.8 and will be removed in 1.10.<br>   Use `l1_ratio` instead. `l1_ratio=0` for `penalty='l2'`, `l1_ratio=1` for<br>   `penalty='l1'` and `l1_ratio` set to any float between 0 and 1 for<br>   `'penalty='elasticnet'`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=C,-float%2C%20default%3D1.0\">\n",
       "            C\n",
       "            <span class=\"param-doc-description\">C: float, default=1.0<br><br>Inverse of regularization strength; must be a positive float.<br>Like in support vector machines, smaller values specify stronger<br>regularization. `C=np.inf` results in unpenalized logistic regression.<br>For a visual example on the effect of tuning the `C` parameter<br>with an L1 penalty, see:<br>:ref:`sphx_glr_auto_examples_linear_model_plot_logistic_path.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=l1_ratio,-float%2C%20default%3D0.0\">\n",
       "            l1_ratio\n",
       "            <span class=\"param-doc-description\">l1_ratio: float, default=0.0<br><br>The Elastic-Net mixing parameter, with `0 <= l1_ratio <= 1`. Setting<br>`l1_ratio=1` gives a pure L1-penalty, setting `l1_ratio=0` a pure L2-penalty.<br>Any value between 0 and 1 gives an Elastic-Net penalty of the form<br>`l1_ratio * L1 + (1 - l1_ratio) * L2`.<br><br>.. warning::<br>   Certain values of `l1_ratio`, i.e. some penalties, may not work with some<br>   solvers. See the parameter `solver` below, to know the compatibility between<br>   the penalty and solver.<br><br>.. versionchanged:: 1.8<br>    Default value changed from None to 0.0.<br><br>.. deprecated:: 1.8<br>    `None` is deprecated and will be removed in version 1.10. Always use<br>    `l1_ratio` to specify the penalty type.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=dual,-bool%2C%20default%3DFalse\">\n",
       "            dual\n",
       "            <span class=\"param-doc-description\">dual: bool, default=False<br><br>Dual (constrained) or primal (regularized, see also<br>:ref:`this equation <regularized-logistic-loss>`) formulation. Dual formulation<br>is only implemented for l2 penalty with liblinear solver. Prefer `dual=False`<br>when n_samples > n_features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=tol,-float%2C%20default%3D1e-4\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-4<br><br>Tolerance for stopping criteria.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Specifies if a constant (a.k.a. bias or intercept) should be<br>added to the decision function.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=intercept_scaling,-float%2C%20default%3D1\">\n",
       "            intercept_scaling\n",
       "            <span class=\"param-doc-description\">intercept_scaling: float, default=1<br><br>Useful only when the solver `liblinear` is used<br>and `self.fit_intercept` is set to `True`. In this case, `x` becomes<br>`[x, self.intercept_scaling]`,<br>i.e. a \"synthetic\" feature with constant value equal to<br>`intercept_scaling` is appended to the instance vector.<br>The intercept becomes<br>``intercept_scaling * synthetic_feature_weight``.<br><br>.. note::<br>    The synthetic feature weight is subject to L1 or L2<br>    regularization as all other features.<br>    To lessen the effect of regularization on synthetic feature weight<br>    (and therefore on the intercept) `intercept_scaling` has to be increased.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=class_weight,-dict%20or%20%27balanced%27%2C%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: dict or 'balanced', default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If not given, all classes are supposed to have weight one.<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.<br><br>.. versionadded:: 0.17<br>   *class_weight='balanced'*</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=random_state,-int%2C%20RandomState%20instance%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance, default=None<br><br>Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the<br>data. See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=solver,-%7B%27lbfgs%27%2C%20%27liblinear%27%2C%20%27newton-cg%27%2C%20%27newton-cholesky%27%2C%20%27sag%27%2C%20%27saga%27%7D%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3D%27lbfgs%27\">\n",
       "            solver\n",
       "            <span class=\"param-doc-description\">solver: {'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'},             default='lbfgs'<br><br>Algorithm to use in the optimization problem. Default is 'lbfgs'.<br>To choose a solver, you might want to consider the following aspects:<br><br>- 'lbfgs' is a good default solver because it works reasonably well for a wide<br>  class of problems.<br>- For :term:`multiclass` problems (`n_classes >= 3`), all solvers except<br>  'liblinear' minimize the full multinomial loss, 'liblinear' will raise an<br>  error.<br>- 'newton-cholesky' is a good choice for<br>  `n_samples` >> `n_features * n_classes`, especially with one-hot encoded<br>  categorical features with rare categories. Be aware that the memory usage<br>  of this solver has a quadratic dependency on `n_features * n_classes`<br>  because it explicitly computes the full Hessian matrix.<br>- For small datasets, 'liblinear' is a good choice, whereas 'sag'<br>  and 'saga' are faster for large ones;<br>- 'liblinear' can only handle binary classification by default. To apply a<br>  one-versus-rest scheme for the multiclass setting one can wrap it with the<br>  :class:`~sklearn.multiclass.OneVsRestClassifier`.<br><br>.. warning::<br>   The choice of the algorithm depends on the penalty chosen (`l1_ratio=0`<br>   for L2-penalty, `l1_ratio=1` for L1-penalty and `0 < l1_ratio < 1` for<br>   Elastic-Net) and on (multinomial) multiclass support:<br><br>   ================= ======================== ======================<br>   solver            l1_ratio                 multinomial multiclass<br>   ================= ======================== ======================<br>   'lbfgs'           l1_ratio=0               yes<br>   'liblinear'       l1_ratio=1 or l1_ratio=0 no<br>   'newton-cg'       l1_ratio=0               yes<br>   'newton-cholesky' l1_ratio=0               yes<br>   'sag'             l1_ratio=0               yes<br>   'saga'            0<=l1_ratio<=1           yes<br>   ================= ======================== ======================<br><br>.. note::<br>   'sag' and 'saga' fast convergence is only guaranteed on features<br>   with approximately the same scale. You can preprocess the data with<br>   a scaler from :mod:`sklearn.preprocessing`.<br><br>.. seealso::<br>   Refer to the :ref:`User Guide <Logistic_regression>` for more<br>   information regarding :class:`LogisticRegression` and more specifically the<br>   :ref:`Table <logistic_regression_solvers>`<br>   summarizing solver/penalty supports.<br><br>.. versionadded:: 0.17<br>   Stochastic Average Gradient (SAG) descent solver. Multinomial support in<br>   version 0.18.<br>.. versionadded:: 0.19<br>   SAGA solver.<br>.. versionchanged:: 0.22<br>   The default solver changed from 'liblinear' to 'lbfgs' in 0.22.<br>.. versionadded:: 1.2<br>   newton-cholesky solver. Multinomial support in version 1.6.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=max_iter,-int%2C%20default%3D100\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=100<br><br>Maximum number of iterations taken for the solvers to converge.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>For the liblinear and lbfgs solvers set verbose to any positive<br>number for verbosity.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to True, reuse the solution of the previous call to fit as<br>initialization, otherwise, just erase the previous solution.<br>Useless for liblinear solver. See :term:`the Glossary <warm_start>`.<br><br>.. versionadded:: 0.17<br>   *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Does not have any effect.<br><br>.. deprecated:: 1.8<br>   `n_jobs` is deprecated in version 1.8 and will be removed in 1.10.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>DecisionTreeClassifier</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-73\" type=\"checkbox\" ><label for=\"sk-estimator-id-73\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"DecisionTreeClassifier__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=criterion,-%7B%22gini%22%2C%20%22entropy%22%2C%20%22log_loss%22%7D%2C%20default%3D%22gini%22\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"<br><br>The function to measure the quality of a split. Supported criteria are<br>\"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the<br>Shannon information gain, see :ref:`tree_mathematical_formulation`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('splitter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=splitter,-%7B%22best%22%2C%20%22random%22%7D%2C%20default%3D%22best%22\">\n",
       "            splitter\n",
       "            <span class=\"param-doc-description\">splitter: {\"best\", \"random\"}, default=\"best\"<br><br>The strategy used to choose the split at each node. Supported<br>strategies are \"best\" to choose the best split and \"random\" to choose<br>the best random split.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;best&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_depth,-int%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int, default=None<br><br>The maximum depth of the tree. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, then consider `min_samples_split` as the minimum number.<br>- If float, then `min_samples_split` is a fraction and<br>  `ceil(min_samples_split * n_samples)` are the minimum<br>  number of samples for each split.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, then consider `min_samples_leaf` as the minimum number.<br>- If float, then `min_samples_leaf` is a fraction and<br>  `ceil(min_samples_leaf * n_samples)` are the minimum<br>  number of samples for each node.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_features,-int%2C%20float%20or%20%7B%22sqrt%22%2C%20%22log2%22%7D%2C%20default%3DNone\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: int, float or {\"sqrt\", \"log2\"}, default=None<br><br>The number of features to consider when looking for the best split:<br><br>- If int, then consider `max_features` features at each split.<br>- If float, then `max_features` is a fraction and<br>  `max(1, int(max_features * n_features_in_))` features are considered at<br>  each split.<br>- If \"sqrt\", then `max_features=sqrt(n_features)`.<br>- If \"log2\", then `max_features=log2(n_features)`.<br>- If None, then `max_features=n_features`.<br><br>.. note::<br><br>    The search for a split does not stop until at least one<br>    valid partition of the node samples is found, even if it requires to<br>    effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls the randomness of the estimator. The features are always<br>randomly permuted at each split, even if ``splitter`` is set to<br>``\"best\"``. When ``max_features < n_features``, the algorithm will<br>select ``max_features`` at random at each split before finding the best<br>split among them. But the best found split may vary across different<br>runs, even if ``max_features=n_features``. That is the case, if the<br>improvement of the criterion is identical for several splits and one<br>split has to be selected at random. To obtain a deterministic behaviour<br>during fitting, ``random_state`` has to be fixed to an integer.<br>See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow a tree with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>If None then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=class_weight,-dict%2C%20list%20of%20dict%20or%20%22balanced%22%2C%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: dict, list of dict or \"balanced\", default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If None, all classes are supposed to have weight one. For<br>multi-output problems, a list of dicts can be provided in the same<br>order as the columns of y.<br><br>Note that for multioutput (including multilabel) weights should be<br>defined for each class of every column in its own dict. For example,<br>for four-class multilabel classification weights should be<br>[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of<br>[{1:1}, {2:5}, {3:1}, {4:1}].<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``<br><br>For multi-output, the weights of each column of y will be multiplied.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>:ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features), default=None<br><br>Indicates the monotonicity constraint to enforce on each feature.<br>  - 1: monotonic increase<br>  - 0: no constraint<br>  - -1: monotonic decrease<br><br>If monotonic_cst is None, no constraints are applied.<br><br>Monotonicity constraints are not supported for:<br>  - multiclass classifications (i.e. when `n_classes > 2`),<br>  - multioutput classifications (i.e. when `n_outputs_ > 1`),<br>  - classifications trained on data with missing values.<br><br>The constraints hold over the probability of the positive class.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>DecisionTreeClassifierUsingRandom</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-74\" type=\"checkbox\" ><label for=\"sk-estimator-id-74\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"DecisionTreeClassifierUsingRandom__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=criterion,-%7B%22gini%22%2C%20%22entropy%22%2C%20%22log_loss%22%7D%2C%20default%3D%22gini%22\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"<br><br>The function to measure the quality of a split. Supported criteria are<br>\"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the<br>Shannon information gain, see :ref:`tree_mathematical_formulation`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('splitter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=splitter,-%7B%22best%22%2C%20%22random%22%7D%2C%20default%3D%22best%22\">\n",
       "            splitter\n",
       "            <span class=\"param-doc-description\">splitter: {\"best\", \"random\"}, default=\"best\"<br><br>The strategy used to choose the split at each node. Supported<br>strategies are \"best\" to choose the best split and \"random\" to choose<br>the best random split.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;random&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_depth,-int%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int, default=None<br><br>The maximum depth of the tree. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, then consider `min_samples_split` as the minimum number.<br>- If float, then `min_samples_split` is a fraction and<br>  `ceil(min_samples_split * n_samples)` are the minimum<br>  number of samples for each split.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, then consider `min_samples_leaf` as the minimum number.<br>- If float, then `min_samples_leaf` is a fraction and<br>  `ceil(min_samples_leaf * n_samples)` are the minimum<br>  number of samples for each node.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_features,-int%2C%20float%20or%20%7B%22sqrt%22%2C%20%22log2%22%7D%2C%20default%3DNone\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: int, float or {\"sqrt\", \"log2\"}, default=None<br><br>The number of features to consider when looking for the best split:<br><br>- If int, then consider `max_features` features at each split.<br>- If float, then `max_features` is a fraction and<br>  `max(1, int(max_features * n_features_in_))` features are considered at<br>  each split.<br>- If \"sqrt\", then `max_features=sqrt(n_features)`.<br>- If \"log2\", then `max_features=log2(n_features)`.<br>- If None, then `max_features=n_features`.<br><br>.. note::<br><br>    The search for a split does not stop until at least one<br>    valid partition of the node samples is found, even if it requires to<br>    effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls the randomness of the estimator. The features are always<br>randomly permuted at each split, even if ``splitter`` is set to<br>``\"best\"``. When ``max_features < n_features``, the algorithm will<br>select ``max_features`` at random at each split before finding the best<br>split among them. But the best found split may vary across different<br>runs, even if ``max_features=n_features``. That is the case, if the<br>improvement of the criterion is identical for several splits and one<br>split has to be selected at random. To obtain a deterministic behaviour<br>during fitting, ``random_state`` has to be fixed to an integer.<br>See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow a tree with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>If None then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=class_weight,-dict%2C%20list%20of%20dict%20or%20%22balanced%22%2C%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: dict, list of dict or \"balanced\", default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If None, all classes are supposed to have weight one. For<br>multi-output problems, a list of dicts can be provided in the same<br>order as the columns of y.<br><br>Note that for multioutput (including multilabel) weights should be<br>defined for each class of every column in its own dict. For example,<br>for four-class multilabel classification weights should be<br>[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of<br>[{1:1}, {2:5}, {3:1}, {4:1}].<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``<br><br>For multi-output, the weights of each column of y will be multiplied.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>:ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features), default=None<br><br>Indicates the monotonicity constraint to enforce on each feature.<br>  - 1: monotonic increase<br>  - 0: no constraint<br>  - -1: monotonic decrease<br><br>If monotonic_cst is None, no constraints are applied.<br><br>Monotonicity constraints are not supported for:<br>  - multiclass classifications (i.e. when `n_classes > 2`),<br>  - multioutput classifications (i.e. when `n_outputs_ > 1`),<br>  - classifications trained on data with missing values.<br><br>The constraints hold over the probability of the positive class.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>GaussianNaiveBayes</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-75\" type=\"checkbox\" ><label for=\"sk-estimator-id-75\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GaussianNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.naive_bayes.GaussianNB.html\">?<span>Documentation for GaussianNB</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"GaussianNaiveBayes__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('priors',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.naive_bayes.GaussianNB.html#:~:text=priors,-array-like%20of%20shape%20%28n_classes%2C%29%2C%20default%3DNone\">\n",
       "            priors\n",
       "            <span class=\"param-doc-description\">priors: array-like of shape (n_classes,), default=None<br><br>Prior probabilities of the classes. If specified, the priors are not<br>adjusted according to the data.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('var_smoothing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.naive_bayes.GaussianNB.html#:~:text=var_smoothing,-float%2C%20default%3D1e-9\">\n",
       "            var_smoothing\n",
       "            <span class=\"param-doc-description\">var_smoothing: float, default=1e-9<br><br>Portion of the largest variance of all features that is added to<br>variances for calculation stability.<br><br>.. versionadded:: 0.20</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1e-09</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-17');</script></body>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('LogisticRegressor1',\n",
       "                              LogisticRegression(max_iter=1000)),\n",
       "                             ('DecisionTreeClassifier',\n",
       "                              DecisionTreeClassifier()),\n",
       "                             ('DecisionTreeClassifierUsingRandom',\n",
       "                              DecisionTreeClassifier(max_depth=5,\n",
       "                                                     splitter='random')),\n",
       "                             ('GaussianNaiveBayes', GaussianNB())],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voteSoft.fit(X,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "2fdd0bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = voteSoft.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "7f6d5e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now compare the Hard and Soft evaluation metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "74c22068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.93333333, 1.        , 0.93333333, 0.93333333,\n",
       "       0.93333333, 0.86666667, 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(voteSoft,X,y,cv=10,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "a764625d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9533333333333334)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(voteSoft,X,y,cv=10,scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "3ebc2e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       1.00      0.98      0.99        50\n",
      "           2       0.98      1.00      0.99        50\n",
      "\n",
      "    accuracy                           0.99       150\n",
      "   macro avg       0.99      0.99      0.99       150\n",
      "weighted avg       0.99      0.99      0.99       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y,pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "e61607f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf2 = pd.DataFrame(confusion_matrix(y,pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "ea197695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "2",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "81fc89b9-a8bc-4840-aaf7-dbfc11562973",
       "rows": [
        [
         "0",
         "50",
         "0",
         "0"
        ],
        [
         "1",
         "0",
         "49",
         "1"
        ],
        [
         "2",
         "0",
         "0",
         "50"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2\n",
       "0  50   0   0\n",
       "1   0  49   1\n",
       "2   0   0  50"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "3368286f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(\n",
    "    data = conf2,\n",
    "    cmap = 'Blues',\n",
    "    annot = True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "4e48e339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results are almost the same for soft and hard Voting so we will try some changes ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "ac3ac3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Voting(X,y,method):\n",
    "\n",
    "    lor = LogisticRegression(max_iter = 1000)\n",
    "    clf = DecisionTreeClassifier(\n",
    "        criterion = 'gini'\n",
    "    )\n",
    "    clf1 = DecisionTreeClassifier(\n",
    "        criterion = 'gini',\n",
    "        max_depth = 5 ,\n",
    "        splitter = 'random'\n",
    "    )\n",
    "    gnb = GaussianNB()\n",
    "\n",
    "\n",
    "    estimators = [\n",
    "        ('LogisticRegressor1' , lor) , \n",
    "        ('DecisionTreeClassifier' , clf) , \n",
    "        ('DecisionTreeClassifierUsingRandom' , clf1) ,\n",
    "        ('GaussianNaiveBayes' , gnb)\n",
    "    ]\n",
    "\n",
    "\n",
    "    voteX = VotingClassifier(\n",
    "    estimators = estimators ,  # Pass the variables in which we made the list of the modelnames and models (estimators)\n",
    "    voting = method\n",
    "    )\n",
    "\n",
    "    voteX.fit(X,y)\n",
    "\n",
    "    predX = voteX.predict(X)\n",
    "\n",
    "    print(f'Cross Val Score Mean for Voting : {method} : \\n {cross_val_score(voteX,X,y,cv=10,scoring='accuracy').mean()}')\n",
    "    print(f'Classification report for Voting : {method} : \\n {classification_report(y,predX)}')\n",
    "\n",
    "    confX = pd.DataFrame(confusion_matrix(y,predX))\n",
    "    print(f'Confusion Matrix for Voting : {method} : ')\n",
    "    sns.heatmap(\n",
    "        data = confX,\n",
    "        cmap = 'Blues',\n",
    "        annot = True \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "a2d20f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Score Mean for Voting : hard : \n",
      " 0.7733333333333334\n",
      "Classification report for Voting : hard : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.73      0.76      0.75        50\n",
      "           2       0.75      0.72      0.73        50\n",
      "\n",
      "    accuracy                           0.83       150\n",
      "   macro avg       0.83      0.83      0.83       150\n",
      "weighted avg       0.83      0.83      0.83       150\n",
      "\n",
      "Confusion Matrix for Voting : hard : \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Voting( \n",
    "        X[:,:2] , # Doing this cause I wanted to introduce some hurdles and find how well can ensembling work on\n",
    "        # models using Soft and Hard Votings.\n",
    "        y , \n",
    "        'hard'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "efb5e1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Score Mean for Voting : soft : \n",
      " 0.76\n",
      "Classification report for Voting : soft : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.84      0.82      0.83        50\n",
      "           2       0.82      0.84      0.83        50\n",
      "\n",
      "    accuracy                           0.89       150\n",
      "   macro avg       0.89      0.89      0.89       150\n",
      "weighted avg       0.89      0.89      0.89       150\n",
      "\n",
      "Confusion Matrix for Voting : soft : \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAGiCAYAAADp4c+XAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAI+NJREFUeJzt3Qt4VNW5//HfTCAXgQQSIOEWoaLcAqgUSERQAxrRgly8YKlciooVUMhRMR4t1dbGWiqUAwEfRbAqRVFRsYoX5PKnBEQUBFSUSg8qJMglwURyMcl59j5/c5hNRAYn2ZO9vp8+q2TWHjKLmXl89/uutdf2VVVVVQkAABjD7/YAAABA3SL4AwBgGII/AACGIfgDAGAYgj8AAIYh+AMAYBiCPwAAhiH4AwBgGII/AACGIfgDAGAYgj8AAGHid7/7nXw+X0Dr3Llz9fGSkhJNmjRJCQkJaty4sUaOHKn8/PygX4fgDwBAGOnWrZv2799f3davX199bNq0aVqxYoWWLVumtWvXat++fRoxYkTQr9EgxGMGAAA/QYMGDZSUlHRCf2FhoRYuXKglS5YoPT3d7lu0aJG6dOmijRs3KjU19ZRfg8wfAIBaVFpaqqNHjwY0q++HfPbZZ2rdurV+9rOfafTo0dq7d6/dv2XLFpWXl2vQoEHVz7WmBJKTk5Wbm1s/M/+Y8ya7PQSEkSOb57o9BABhLLpB/YlJ069qrvvvvz+gb8aMGfb8vlPfvn21ePFiderUyS75W3+vf//+2rFjh/Ly8hQZGammTZsG/J3ExET7WL0M/gAAhA1f6ArjWVlZyszMDOiLioqq8bmDBw+u/rlHjx72ycCZZ56p5557TjExMSEbE2V/AABqkRXoY2NjA9oPBX8nK8s/55xztHv3bnsdQFlZmQoKCgKeY632r2mNwMkQ/AEAcPL5Qtd+gqKiIv3rX/9Sq1at1KtXLzVs2FCrVq2qPr5r1y57TUBaWlpQv5eyPwAAtVj2D8Ydd9yhIUOG2KV+6zI+a21ARESErr/+esXFxWnChAn2FEJ8fLxdQZgyZYod+INZ6W8h+AMA4PQTM/bT9eWXX9qB/tChQ2rRooUuvPBC+zI+62fLrFmz5Pf77c19rCsGMjIylJOTE/Tr+KqqqqoUBljtj+Ox2h+Aq6v9ewcu0Pspjm1+ROGGzB8AgDAp+9cVgj8AAGFS9q8r3j61AQAAJyDzBwDAibI/AACG8VH2BwAAHkLZHwAAJ8r+AAAYxkfZHwAAeAhlfwAAnCj7AwBgGJ+3y/5k/gAAGJb5e/tfBwAATkDmDwCAYZk/wR8AACe/t+f8vX1qAwAATkDmDwCAE2V/AAAM46PsDwAAPISyPwAATpT9AQAwjI+yPwAA8BDK/gAAOFH2BwDAMD5vl/3J/AEAMCzz9/a/DgAAnIDMHwAAJ8r+AAAYxuftwri3/3UAAOAElP0BAHCi7A8AgGF83i6Me/tfBwAATkDZHwAAwzJ/gj8AAIbN+Xv71AYAAJyAzB8AACfK/gAAGMbn7bI/mT8AAIZl/t7+1wEAgBOQ+QMA4ETZHwAAs/g8Hvwp+wMAYBjK/gAAGJb5E/wBAHDyduyn7A8AgGnI/AEAcKDsDwCAYXwen/NntT8AAIah7A8AgAOZP0LqPydeoWMfzA1oW1+8t/p4VGQDzbr7Wn25+k/6+p9/0d9n3qiW8U34FAy0dMkzGnxpunqf112jR12j7R9+6PaQ4CK+D3Uf/H0hauGIsr8Ldu7ep/aDsqrbwF/Pqj728B0jdeWAFI2+a6Euu3G2WrWI09K/3OjGMOGila+/ppkPZ2virZO0dNlyderUWb+ZOEGHDh3iczEQ3wcX+ELYwhDB3wXfVVQq/9A31e1QQbHdH9s4WuOGpWn6Iy9q7eZP9cHHX+jmGU8r7dyz1Kd7ezeGCpc89eQijbj6Wg0bPlJndeyoe2fcr+joaL304gt8Jgbi+wDX5/wPHjyoJ554Qrm5ucrLy7P7kpKSdMEFF2jcuHFq0aJFyAfpNR2TW+jzNx9USWm5Nn24R7/9r1f0Rd4RndclWZENG+idjbuqn/vpv/O1d/9h9e3RQe9u/7er40bdKC8r08cf7dSEmyZW9/n9fqWmXqAPt33Ax2AYvg/u8IVpud6VzH/z5s0655xzNGfOHMXFxWnAgAF2s362+jp37qz33nvvR39PaWmpjh49GtCqKitkgs07/q2bf/u0hk6ap9v++Kzat0nQ209MU+MzopSUEKvSsnIVFh0L+DsHDh1VYkKsa2NG3TpScEQVFRVKSEgI6LceWyffMAvfB3f4PD7nH1TmP2XKFF1zzTVasGDBCf+gqqoq3XLLLfZzrKrAyWRnZ+v+++8P6ItI7K2GrfrI697850fVP+/4bJ82b/+3dr32gEZedr5KSspdHRsAwAxBZf7btm3TtGnTajyTsfqsY1u3bv3R35OVlaXCwsKA1iCxl0xkZfm79x7QWe1aKO/QUUVFNlRc45iA57RMiFX+oaOujRF1q1nTZoqIiDhhcZ/1uHnz5nwchuH74A6fxzP/oIK/Nbf/7rvv/uBx61hiYuKP/p6oqCjFxsYGNJ8/QiZqFBOpDm2bK+9goT74eK/Kyr/TJX07VR8/+8yWSm4Vb68NgBkaRkaqS9du2rTx/ypolZWV2rQpVz16nufq2FD3+D64w+fx4B9U2f+OO+7QzTffrC1btmjgwIHVgT4/P1+rVq3SY489ppkzZ9bWWD0he9pw/WPddu3dd1itW8bp3luuVEVlpZ5buUVHi0q0+KVc/ek/RuhwYbG+KS7RI9Ov0cZtn7PYzzA3jB2v++6Zrm7dUpTSvYeefupJHTt2TMOGj3B7aHAB3weEWlDBf9KkSXbZcdasWcrJybEXJVmsEmWvXr20ePFiXXvttSEfpJe0SWyqv2WPV3zcGTp4pEgbtn6ui8b8xf7ZctfMF1RZWWVv7mNt+PP2ho91e/azbg8bdezywVfoyOHDypk7RwcPfq1Onbso59HHlUDZ30h8H1zgk6f5qqyVeqehvLy8euWxdULQsGHDnzSQmPMm/6S/D285snmu20MAEMaia3lz+ubjlobsdx1cPErh5rTfPivYt2rVKrSjAQAAtY4b+wAA4BCuC/VCheAPAIBhwZ+9/QEACMMb+zz00EP2ScjUqVOr+0pKSuzF99aOn40bN9bIkSPtK+6CRfAHACDMWNvpP/roo+rRo0dAv7WZ3ooVK7Rs2TKtXbtW+/bt04gRwV8CTPAHACCMNvkpKirS6NGj7b1zmjVrVt1v7Ya7cOFCPfLII0pPT7cvsV+0aJE2bNigjRs3BvUaBH8AAGox+Nd0Mzur74dYZf0rr7xSgwYNCui3NtizLrM/vt+6oV5ycvKP3lPHieAPAEAtsm5mZ9399vhm9dVk6dKlev/992s8npeXp8jISDVt2jSg39pt1zoWDFb7AwBQi6v9rZvZZWZmnnCPG6cvvvhCt99+u9566y1FR0erNhH8AQCoxeBvBfqagr2TVdY/cOCAzj///Oo+axv9devWae7cuXrjjTdUVlamgoKCgOzfWu1v3XgvGAR/AADCgHXDvO3btwf0jR8/3p7Xnz59utq1a2fvrmvdSM+6xM+ya9cu7d27V2lpaUG9FsEfAAAnF/b4adKkiVJSUgL6GjVqZF/T/33/hAkT7CmE+Ph4xcbGasqUKXbgT01NDeq1CP4AANSTHf6su+r6/X4787euGMjIyLDvsltnd/ULNe7qh+NxVz8Abt7Vr81vlofsd301f7jCDZk/AAD1JPMPFYI/AAAOBH8AAEzjk6exwx8AAIah7A8AgANlfwAADOPz+II/yv4AABiGsj8AAIZl/gR/AAAMC/6U/QEAMAyZPwAATt5O/An+AAA4UfYHAACeQtkfAADDMn+CPwAADh6P/QR/AABMy/y51A8AAMNQ9gcAwMHjiT/BHwAAJ8r+AADAUyj7AwDgQNkfAADD+P3envRntT8AAIah7A8AgANlfwAADOPzePSn7A8AgGEo+wMA4ODxxJ/gDwCAaWV/Mn8AAAwL/sz5AwBgGDJ/AAAcPJ74E/wBAHCi7A8AADyFsj8AAA6U/QEAMIzP49Gf1f4AABiGsj8AAA4eT/wJ/gAAOFH2BwAAnkLZHwAAB8r+AAAYxufx6E/mDwCAg8djf/gE/yOb57o9BISRtjcudXsICCNrHvyF20NAmElp09jtIdRrYRP8AQAIFz6Pp/4EfwAAHDwe+9nhDwAA05D5AwDgQNkfAADD+Cj7AwAAL6HsDwCAA2V/AAAM4/N43d/v9gAAAEDdouwPAICDxxN/gj8AAKaV/cn8AQBw8HjsZ84fAADTkPkDAOBA2R8AAMP4KPsDAAAvoewPAICD3+OpP8EfAAAHj8d+VvsDAGAaMn8AAAxb7c/e/gAAOPh9oWvBmD9/vnr06KHY2Fi7paWl6fXXX68+XlJSokmTJikhIUGNGzfWyJEjlZ+fH9yLEPwBAKg58w9VC0bbtm310EMPacuWLXrvvfeUnp6uq666Sjt37rSPT5s2TStWrNCyZcu0du1a7du3TyNGjFCwKPsDABAmhgwZEvD4wQcftKsBGzdutE8MFi5cqCVLltgnBZZFixapS5cu9vHU1NRTfh2CPwAADqGc8i8tLbXb8aKioux2MhUVFXaGX1xcbJf/rWpAeXm5Bg0aVP2czp07Kzk5Wbm5uUEFf+b8AQBw8IXwf9nZ2YqLiwtoVt8P2b59uz2fb50c3HLLLVq+fLm6du2qvLw8RUZGqmnTpgHPT0xMtI8Fg8wfAIBalJWVpczMzIC+k2X9nTp10tatW1VYWKjnn39eY8eOtef3Q4ngDwCAQ7Cr9E/mVEr8x7Oy+44dO9o/9+rVS5s3b9Zf//pXXXfddSorK1NBQUFA9m+t9k9KSgpqTJT9AQAIk9X+NamsrLTXDFgnAg0bNtSqVauqj+3atUt79+611wQEg8wfAIAwmiIYPHiwvYjvm2++sVf2r1mzRm+88Ya9VmDChAn2FEJ8fLy9D8CUKVPswB/MYj8LwR8AAAe3Nvg7cOCAxowZo/3799vB3trwxwr8l156qX181qxZ8vv99uY+VjUgIyNDOTk5Qb8OwR8AgDC5q591Hf/JREdHa968eXb7KZjzBwDAMGT+AAA4ePy+PgR/AABMu6sfmT8AAA4ej/3M+QMAYBoyfwAAwmS1f10h+AMA4ODt0E/ZHwAA45D5AwDgwGp/AAAM4/d43Z8d/gAAMAxlfwAAHCj7AwBgGB9lfwAA4CWU/QEAcKDsDwCAYfweL/uT+QMAYFjmz6V+AAAYhswfAAAHb+f9BH8AAIy7qx9lfwAADEPZHwAAB48n/gR/AACcWO0PAAA8hTn/MLF0yTMafGm6ep/XXaNHXaPtH37o9pDggtuu7KKDi0fpD788r7pvzEVn6eW707Vn/kj7WOwZDflsDHPs22I9MXemJo66UtdffoHumTxeuz/Z6fawPF/294WohSOCfxhY+fprmvlwtibeOklLly1Xp06d9ZuJE3To0CG3h4Y6dF6HeI29+Czt2HskoD8mKkKrtu/XrFc/4vMwVM7M32vblk26Lev3emThs+r581Tdf+dvdOjrA24PzdOr/f0hauGI4B8GnnpykUZcfa2GDR+pszp21L0z7ld0dLReevEFt4eGOtIoqoEWTEzVtEWbVfhtecCxR9/8VHP+8bG2/IuTQROVlpZo47p3NGbiberW83y1atNO142bqKTW7fTGK8+7PTzUUwR/l5WXlenjj3YqNe2C6j6/36/U1Av04bYPXB0b6s6fbuilt7bt17qP8nnbEaCyokKVlRVqGBkV0B8ZFaVPdmzl3aolPo+X/V251K+0tNRux6uKiFJUVOCX2wRHCo6ooqJCCQkJAf3W4z17PndtXKg7w/smq8eZzXTpA2/ytuMEMWc0UqeuPfT8U4+rbXIHxTWL1/p33tCnH223s3/UDl+4Ru1wzfy/+OIL/frXvz7pc7KzsxUXFxfQ/vyn7FAPBQh7rePP0IO/PF+3PJqr0vJKt4eDMHVb1gOqqqrSTdderlEZaXrtxaW6MD1DPq/fes7l4OgPUTMi8z98+LCefPJJPfHEEz/4nKysLGVmZp6Q+ZuoWdNmioiIOGFxn/W4efPmro0LdaNn+2ZqGRetd+7PqO5rEOFX2jktdOPAs9X6xmWqrKri4zBcUpt2+v3sx1Ry7JiOfVukZgkt9JcH7lZiqzZuDw31VNDB/5VXXjnp8c8///FStVXed5b4S76TkRpGRqpL127atDFX6QMH2X2VlZXatClXo67/ldvDQy37fx/l68L/fD2g778m9NFned/Yi/wI/DhedEyM3Yq+Oaqtm3N1w8TbeYNqic/jZf+gg/+wYcPsN8UqQZn6poXaDWPH6757pqtbtxSldO+hp596UseOHdOw4SPcHhpqWVHJd/rkq8KAvm/LKnS4qLS636oMWK1Dy8b2465tm6qopFxfHvpWBcVlfEYG+GDzBqlKat3uTOV99YX+9uhf1Sa5vdIvH+L20DzL7/EwFnTwb9WqlXJycnTVVVfVeHzr1q3q1atXKMZmjMsHX6Ejhw8rZ+4cHTz4tTp17qKcRx9XAmV/SBp3SUfdNSyl+r149Z6B9p+TH9+kpev38B4Z4NviIj3z2FwdOnhAjZvEKrX/QP1ywq1q0IANn3B6fFUnS+FrMHToUJ177rl64IEHajy+bds2nXfeeXbpOhimlv1Rs7Y3LuWtQbU1D/6CdwMBUtr8byWstmS+8knIftcjQzur3mf+d955p4qLi3/weMeOHbV69eqfOi4AAFzj8/j0ddDBv3///ic93qhRI1100UU/ZUwAAMBrm/wAABDO/N5O/An+AAA4ebzqH7abDwEAgFpC2R8AAIdwvRVvqBD8AQAwrCxO8AcAwMHjib/nT24AAIADmT8AAA7M+QMAYBgfZX8AAOAllP0BAHBghz8AAAzj93jdn9X+AAAYhrI/AAAOHk/8Cf4AAJg250/ZHwAAw1D2BwDAwSdvp/4EfwAADCv7E/wBADAs+DPnDwCAYcj8AQBw8Hn8Wj+CPwAADpT9AQCAp5D5AwDg4PGqP8EfAAAnbuwDAAA8hUv9AACoYcFfqFowsrOz1bt3bzVp0kQtW7bUsGHDtGvXroDnlJSUaNKkSUpISFDjxo01cuRI5efnB/U6BH8AAGqY8w9VC8batWvtwL5x40a99dZbKi8v12WXXabi4uLq50ybNk0rVqzQsmXL7Ofv27dPI0aMCOp1WPAHAEAtKi0ttdvxoqKi7Oa0cuXKgMeLFy+2KwBbtmzRgAEDVFhYqIULF2rJkiVKT0+3n7No0SJ16dLFPmFITU09pTGR+QMA4OCXL2TNKuXHxcUFNKvvVFjB3hIfH2//aZ0EWNWAQYMGVT+nc+fOSk5OVm5urk4VmT8AALV4qV9WVpYyMzMD+mrK+p0qKys1depU9evXTykpKXZfXl6eIiMj1bRp04DnJiYm2sdOFcEfAIBa3OHvh0r8P8aa+9+xY4fWr1+vUKPsDwBAmJk8ebJeffVVrV69Wm3btq3uT0pKUllZmQoKCgKeb632t46dKoI/AAA1bPITqhaMqqoqO/AvX75c77zzjjp06BBwvFevXmrYsKFWrVpV3WddCrh3716lpaWd8utQ9gcAIEy297VK/dZK/pdfftm+1v/7eXxrkWBMTIz954QJE+w1BNYiwNjYWE2ZMsUO/Ke60t9C8AcAIEzMnz/f/vPiiy8O6Lcu5xs3bpz986xZs+T3++3NfaxLCDMyMpSTkxPU6xD8AQAIk739rbL/j4mOjta8efPsdroI/gAAGHZXPxb8AQBgGDJ/AAAMy4wJ/gAAOPg8Xvf3+skNAABwIPMHAMDB23k/wR8AgLC51K+ukPkDAODg7dDPnD8AAMYh8wcAwMHjVX+CPwAATlzqBwAAPIWyPwAAhm2CQ/AHAMCBsj8AAPAUMn8AABw8vtif4A8AgGllfzJ/hKV/PjTU7SEgjPTJfMHtISDMFC65we0h1GsEfwAAHFjtDwCAYXyU/QEAMItP3ub1ygYAAHBgzh8AAAePV/0J/gAAOPk9Xvin7A8AgGEo+wMA4EDZHwAAw/go+wMAAC+h7A8AgANlfwAADOOn7A8AALyEsj8AAA6U/QEAMIzP23v8kPkDAODEpX4AAMBTmPMHAMDBT9kfAACz+LjUDwAAeAllfwAAHFjtDwCAYXyU/QEAgJdQ9gcAwIHV/gAAGMZH2R8AAHgJZX8AABxY7Q8AgGF88jYyfwAAHPweT/39bg8AAADULTJ/AAAcvJ33E/wBADAu+lP2BwDAMJT9AQAwbJMfgj8AAA4eX+xP2R8AANOQ+QMA4ODxxJ/gDwCAadGf1f4AABiGsj8AAA6s9gcAwDA+j5f9yfwBAHDweOxnzh8AANOQ+QMAYFjqT/AHAMCwBX9c6gcAQJhYt26dhgwZotatW8vn8+mll14KOF5VVaXf/va3atWqlWJiYjRo0CB99tlnQb8OwR8AgBpW+4eqBaO4uFg9e/bUvHnzajz+8MMPa86cOVqwYIE2bdqkRo0aKSMjQyUlJUG9DmV/AAAcQln0Ly0ttdvxoqKi7OY0ePBgu9XEyvpnz56te++9V1dddZXd97e//U2JiYl2hWDUqFGnPCYyfwAAalF2drbi4uICmtUXrD179igvL88u9X/P+l19+/ZVbm5uUL+LzB8AgFpM/bOyspSZmRnQV1PW/2OswG+xMv3jWY+/P3aqCP4AANTiav8fKvG7ibI/AAD1QFJSkv1nfn5+QL/1+Ptjp4rgDwBAmKz2P5kOHTrYQX7VqlXVfUePHrVX/aelpQX1uyj7AwDg4NYWP0VFRdq9e3fAIr+tW7cqPj5eycnJmjp1qv7whz/o7LPPtk8G7rvvPntPgGHDhgX1OgR/AADCJPq/9957uuSSS6off79QcOzYsVq8eLHuuusuey+Am2++WQUFBbrwwgu1cuVKRUdHB/U6virrwsEwUPKdjLZ0yTN6ctFCHTz4tc7p1Fl333OfuvfoIVP998FvZaqKigr9ffECrXnzNRUcPqT45i2UfvkQXTfmJnvHLxP1yXxBJpo2pJt+d/35ynn9Y2U99Z6aNYpU1tU9ld69ldo2b6SDR0v1j/e+0IPLturosXKZpHDJDbX6+3d8VRSy35XSprHCDZl/GFj5+mua+XC27p1xv7p376lnnnpSv5k4QS+/ulIJCQluDw917IUli/X6y89ratYDSm5/lnbv2qk5D/1OjRo11pCrf8nnYYjzf5ag8QPP0fb/Plzdl9TsDLVqFqN7l7yvXV8WqF3zxpo1oa/dN+av61wdr9f42Nsfte2pJxdpxNXXatjwkTqrY0f7JMAq4bz0opnZjuk+2blNfftdpN5p/ZXYqrX6XXypzu2dqk8/2en20FBHGkU10GOTLtRtj+eqoLisuv/jLwt0w+x1Wvn+l9pzoEjrPsrT75/7QJef31YRfjOrQiYt+AslVvu7rLysTB9/tFOpaRdU9/n9fqWmXqAPt33g6tjgjs7deurD99/VV1/8t/14z+5d+mj7VvXq24+PxBAzx/fRGx98pTU7fnzjltiYSH1zrFwVlWExg4t6grK/y44UHLHneJ3lfevxnj2fuzYuuOfq0eN17Nsi3XrDcPn9EaqsrNCvbpykiy+9go/FACPT2qtn+3hdct9rP/rc+CZRunN4dy1+J/i7uuHkwjRhdy/4Hzt2TFu2bLEvO+jatWvAMeuuQs8995zGjBkT9E0OqiLCbwckwA3rV7+ptW+9rv+474/2nL+V+T8+d6a98G/g5UP5UDysTfwZemjMzzXsj2+rtLzypM9tEtNQy+5M166vCpX9wrY6G6MxfPK0oMr+n376qbp06aIBAwaoe/fuuuiii7R///7q44WFhRo/fvxp3eTgz38K/iYHXtCsaTNFRETo0KFDAf3W4+bNm7s2Lrhn8fzZGjl6vAYMvFztzzpbl2T8QkOvGa3nn1nEx+Jx5/4sQS3jYrTuj1fq0FOj7da/a5Juyehs/+z//xPIjaMb6IXp6SoqKdfoWWv0XQUlf9Ri5j99+nSlpKTY1yFa1xdamw3069dPa9assTcf+Ck3ObAyfxM1jIxUl67dtGljrtIH/u+dmiorK7VpU65GXf8rt4cHF5SWlpxwSZ+1DqSq8uSZIOq/tTv2K/WuFQF9ORPT9Om+o5q9Yqcqq6rsjP/FuweqtLxCo2au/tEKAU6Pz+Opf1DBf8OGDXr77bftjNRqK1as0K233qr+/ftr9erVatSo0Wnf5MDk6/xvGDte990zXd26pSilew89/dST9vTKsOEj3B4aXND7ggFa9vRCtUhsZZf9P//sE7383NMadEVwO3ih/ikq+c5e0X+84tLvdLio1O63Av/yuwcqJqqBbp633n5sNYt1zb91coDQ8Hk79gcX/K2A1KDB//0VKzuZP3++Jk+ebE8BLFmypDbG6HmXD75CRw4fVs7cOfYmP506d1HOo48rgbK/kW6+fbqeWZijBbP+qMIjR+y5/suHXq3rxt7s9tDgMmshYO+zW9g/b509POBY99te1N6DxS6NDPVNUDv89enTR1OmTNENN5y4s5J1AvDMM8/YNxmwVq8Hy+TMHycyeYc/nMjUHf7g3g5/n+aF7r9B5ySdoXq94G/48OH6+9//XuOxuXPn6vrrr1eY7BYMAMDp84WwhSH29kdYIvPH8cj8UdeZ/2f5x0L2u85OjFG4YYc/AAAMww5/AAA4sNofAADD+ORtlP0BADAMZX8AAAxL/Qn+AAAYtr0vZX8AAAxD5g8AgAOr/QEAMIxP3kbZHwAAw1D2BwDAsNSf4A8AgGGr/Qn+AAAYtuCPOX8AAAxD5g8AgIPHE3+CPwAATpT9AQCAp1D2BwDAsMI/wR8AAAfK/gAAwFPI/AEAMKroT/AHAOAElP0BAICnUPYHAMCBvf0BADCNT55G5g8AgFmxnxv7AABgGjJ/AAAMW+1P8AcAwLAFf363BwAAAOoWmT8AAE7eTvwJ/gAAGBb7KfsDAGAayv4AADiw2h8AAMP4PF74Z7U/AACGoewPAIBhZX8yfwAADEPmDwCAA5k/AADwFDJ/AAAMW+1P8AcAwIGyPwAA8BQyfwAAHLxd9Cf4AwBgXPTnOn8AAAxD2R8AAAdW+wMAYBgfZX8AAOAllP0BAHDweOJP8AcAwLToz2p/AABqWPAXqv8Fa968eWrfvr2io6PVt29fvfvuuwo1gj8AAGHi2WefVWZmpmbMmKH3339fPXv2VEZGhg4cOBDS1yH4AwBQw2r/ULXS0lIdPXo0oFl9NXnkkUd00003afz48eratasWLFigM844Q0888YRCqgpho6SkpGrGjBn2nwDfB/DfB2+YMWNGlRVuj29Wn1NpaWlVRERE1fLlywP6x4wZUzV06NCQjsln/V9oTydwuqyzwbi4OBUWFio2NpY30nB8H8D3wRtKS0tPyPSjoqLsdrx9+/apTZs22rBhg9LS0qr777rrLq1du1abNm0K2Zi41A8AgFpUU6B3G3P+AACEgebNmysiIkL5+fkB/dbjpKSkkL4WwR8AgDAQGRmpXr16adWqVdV9lZWV9uPjpwFCgbJ/GLHKQtblHeFWHoI7+D6A74N5MjMzNXbsWP385z9Xnz59NHv2bBUXF9ur/0OJBX8AAISRuXPn6s9//rPy8vJ07rnnas6cOfZmP6FE8AcAwDDM+QMAYBiCPwAAhiH4AwBgGII/AACGIfiHibq4hSPqh3Xr1mnIkCFq3bq1fD6fXnrpJbeHBBdlZ2erd+/eatKkiVq2bKlhw4Zp165dfCb4SQj+Bt3CEfWDdU2v9R2wTggBa0/3SZMmaePGjXrrrbdUXl6uyy67zP6eAKeLS/3CgJXpW2f21rWd3+/o1K5dO02ZMkV3332328ODi6zMf/ny5Xa2B1i+/vpruwJgnRQMGDCANwWnhczfZWVlZdqyZYsGDRpU3ef3++3Hubm5ro4NQPix7vppiY+Pd3soqMcI/i47ePCgKioqlJiYGNBvPbZ2dwKA71lVwalTp6pfv35KSUnhjcFpY29/AKgnrLn/HTt2aP369W4PBfUcwd+gWzgCqL8mT56sV1991b4apG3btm4PB/UcZX+DbuEIoP6pqqqyA7+18POdd95Rhw4d3B4SPIDM36BbOKJ+KCoq0u7du6sf79mzR1u3brUXeCUnJ7s6NrhT6l+yZIlefvll+1r/79cCxcXFKSYmho8Ep4VL/Qy6hSPqhzVr1uiSSy45od86QVy8eLErY4K7l3vWZNGiRRo3blydjwfeQPAHAMAwzPkDAGAYgj8AAIYh+AMAYBiCPwAAhiH4AwBgGII/AACGIfgDAGAYgj8AAIYh+AMAYBiCPwAAhiH4AwAgs/wPkXhlj3ysKSoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Voting( \n",
    "        X[:,:2] , \n",
    "        y , \n",
    "        'soft'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "7a98d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As you can see now that we take only two columns we can clearly see that hard voting is better ensembling technique for it ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "c4dd27b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I will take the last two columns and check again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "e208ac58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Score Mean for Voting : hard : \n",
      " 0.96\n",
      "Classification report for Voting : hard : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.94      0.98      0.96        50\n",
      "           2       0.98      0.94      0.96        50\n",
      "\n",
      "    accuracy                           0.97       150\n",
      "   macro avg       0.97      0.97      0.97       150\n",
      "weighted avg       0.97      0.97      0.97       150\n",
      "\n",
      "Confusion Matrix for Voting : hard : \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Voting( \n",
    "        X[:,2:] , # Doing this cause I wanted to introduce some hurdles and find how well can ensembling work on\n",
    "        # models using Soft and Hard Votings.\n",
    "        y , \n",
    "        'hard'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "65966410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Score Mean for Voting : soft : \n",
      " 0.9666666666666666\n",
      "Classification report for Voting : soft : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.96      0.98      0.97        50\n",
      "           2       0.98      0.96      0.97        50\n",
      "\n",
      "    accuracy                           0.98       150\n",
      "   macro avg       0.98      0.98      0.98       150\n",
      "weighted avg       0.98      0.98      0.98       150\n",
      "\n",
      "Confusion Matrix for Voting : soft : \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAGiCAYAAADp4c+XAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAI+lJREFUeJzt3Qt4FOXZ//HfbiAHCQkkQDgZRRESOQhGhIBgxSilFoHg8W8VKZ6Bt5BSEV+VYtWooCjFqK0YPCFKFSy+iq9yLBoQUBTQIogWLSQQIEEiOZjkvWb+Fyk7icrqJrOZ5/vhmib7zLL7sLv23vuee57xVVdXVwsAABjD7/YEAABAwyL4AwBgGII/AACGIfgDAGAYgj8AAIYh+AMAYBiCPwAAhiH4AwBgGII/AACGIfgDAGAYgj8AAGHij3/8o3w+X8CWkpJSs7+0tFTjxo1TYmKiYmNjNWrUKBUUFAT9PAR/AADCSLdu3bRnz56abc2aNTX7Jk2apCVLlmjhwoVatWqVdu/erczMzKCfo0mI5wwAAH6GJk2aqG3btrXGi4uLNXfuXM2fP1+DBw+2x3Jzc5Wamqq1a9eqX79+x/0cZP4AANSjsrIyHTp0KGCzxr7P9u3b1b59e51yyim66qqrtGvXLnt848aNqqioUEZGRs19rUMCycnJysvLa5yZf0zv8W5PAWHk4Po5bk8BQBiLbtJ4YtKU4a00ffr0gLFp06bZx/ed+vbtq3nz5qlr1652yd/6ewMHDtSWLVuUn5+vyMhItWjRIuDvJCUl2fsaZfAHACBs+EJXGJ86daqysrICxqKiouq879ChQ2t+79mzp/1l4KSTTtLLL7+smJiYkM2Jsj8AAPXICvRxcXEB2/cFfycry+/SpYt27Nhh9wGUl5erqKgo4D5Wt39dPQI/hOAPAICTzxe67Wc4fPiwPv/8c7Vr105paWlq2rSpli1bVrN/27Ztdk9Aenp6UI9L2R8AgHos+wdj8uTJGjZsmF3qt07js3oDIiIidOWVVyo+Pl5jx461DyEkJCTYFYQJEybYgT+YTn8LwR8AAKefmbH/VF9//bUd6Pfv36/WrVvrnHPOsU/js363zJo1S36/317cxzpjYMiQIcrJyQn6eXzV1dXVCgN0++NYdPsDcLXbv09gg97PcWT9wwo3ZP4AAIRJ2b+hEPwBAAiTsn9D8fZXGwAAUAuZPwAATpT9AQAwjI+yPwAA8BDK/gAAOFH2BwDAMD7K/gAAwEMo+wMA4ETZHwAAw/i8XfYn8wcAwLDM39v/OgAAUAuZPwAAhmX+BH8AAJz83j7m7+2vNgAAoBYyfwAAnCj7AwBgGB9lfwAA4CGU/QEAcKLsDwCAYXyU/QEAgIdQ9gcAwImyPwAAhvF5u+xP5g8AgGGZv7f/dQAAoBYyfwAAnCj7AwBgGJ+3C+Pe/tcBAIBaKPsDAOBE2R8AAMP4vF0Y9/a/DgAA1ELZHwAAwzJ/gj8AAIYd8/f2VxsAAFALmT8AAE6U/QEAMIzP22V/Mn8AAAzL/L39rwMAALWQ+QMA4ETZHwAAs/g8Hvwp+wMAYBjK/gAAGJb5E/wBAHDyduyn7A8AgGnI/AEAcKDsDwCAYXweP+ZPtz8AAIah7A8AgAOZP0Lqv2/8lY58OCdg2/TqHTX7oyKbaNZtl+nrFQ9o37sP6cWZ16lNQnPeBQMtmP+Chl4wWH1699BVV1yqzR9/7PaU4CI+Dw0f/H0h2sIRZX8XbN2xWydnTK3Zzv/trJp9D04epYsGdddVt87Vhdc9onat47XgoevcmCZctPTNNzTzwWzdeMs4LVi4SF27pujmG8dq//79vC8G4vPgAl8ItzBE8HfBd5VVKtj/Tc22v6jEHo+Ljda1I9I15eFXtWr9Z/rw0690w7Tnld7rVJ3d42Q3pgqXPPdMrjIvuUwjRo7SqZ07645p0xUdHa3Fr77Ce2IgPg9w/Zh/YWGhnn76aeXl5Sk/P98ea9u2rfr3769rr71WrVu3DvkkvaZzcmvt/N97VVpWoXUff6G7/vx3fZV/UL1TkxXZtImWr91Wc9/PvizQrj0H1LdnJ72/+UtX542GUVFerk8/2aqx199YM+b3+9WvX399/NGHvA2G4fPgDl+YlutdyfzXr1+vLl26aPbs2YqPj9egQYPszfrdGktJSdGGDRt+9HHKysp06NChgK26qlImWL/lS91w1/O6eNxj+q/7XtLJHRL1ztOTFHtClNomxqmsvELFh48E/J29+w8pKTHOtTmjYR0sOqjKykolJiYGjFu3rS/fMAufB3f4PH7MP6jMf8KECbr00kv1xBNP1PoHVVdX66abbrLvY1UFfkh2dramT58eMBaR1EdN250tr/vfdz+p+X3L9t1av/lLbXvjbo268EyVlla4OjcAgBmCyvw/+ugjTZo0qc5vMtaYtW/Tpk0/+jhTp05VcXFxwNYkKU0msrL8Hbv26tQTWyt//yFFRTZVfGxMwH3aJMapYP8h1+aIhtWyRUtFRETUau6zbrdq1Yq3wzB8Htzh83jmH1Twt47tv//++9+739qXlJT0o48TFRWluLi4gM3nj5CJmsVEqlPHVsovLNaHn+5SecV3Oq9v15r9p53URsntEuzeAJihaWSkUk/vpnVr/1NBq6qq0rp1eep5Rm9X54aGx+fBHT6PB/+gyv6TJ0/WDTfcoI0bN+r888+vCfQFBQVatmyZ/vrXv2rmzJn1NVdPyJ40Uv+zerN27T6g9m3idcdNF6myqkovL92oQ4dLNW9xnh74faYOFJfom5JSPTzlUq39aCfNfoa5evQY3Xn7FHXr1l3de/TU8889oyNHjmjEyEy3pwYX8HlAqAUV/MeNG2eXHWfNmqWcnBy7KclilSjT0tI0b948XXbZZSGfpJd0SGqhZ7PHKCH+BBUePKz3Nu3Uudc8ZP9uuXXmK6qqqrYX97EW/HnnvU/1u+yX3J42Gtgvh/5KBw8cUM6c2Sos3KeuKanKefIpJVL2NxKfBxf45Gm+aqtT7yeoqKio6Ty2vhA0bdr0Z00kpvf4n/X34S0H189xewoAwlh0PS9O3+raBSF7rMJ5Vyjc/OSXzwr27dq1C+1sAABAvePCPgAAOIRro16oEPwBADAs+LO2PwAAYXhhn/vvv9/+EjJx4sSasdLSUrv53lrxMzY2VqNGjbLPuAsWwR8AgDBjLaf/5JNPqmfPngHj1mJ6S5Ys0cKFC7Vq1Srt3r1bmZnBnwJM8AcAIIwW+Tl8+LCuuuoqe+2cli1b1oxbq+HOnTtXDz/8sAYPHmyfYp+bm6v33ntPa9euDeo5CP4AANRj8K/rYnbW2PexyvoXXXSRMjIyAsatBfas0+yPHbcuqJecnPyj19RxIvgDAFCPrIvZWVe/PXazxuqyYMECffDBB3Xuz8/PV2RkpFq0aBEwbq22a+0LBt3+AADUY7e/dTG7rKysWte4cfrqq6/0u9/9Tm+//baio6NVnwj+AADUY/C3An1dwd7JKuvv3btXZ555Zs2YtYz+6tWrNWfOHL311lsqLy9XUVFRQPZvdftbF94LBsEfAIAwYF0wb/PmzQFjY8aMsY/rT5kyRSeeeKK9uq51IT3rFD/Ltm3btGvXLqWnpwf1XAR/AACcXFjjp3nz5urevXvAWLNmzexz+o+Ojx071j6EkJCQoLi4OE2YMMEO/P369QvquQj+AAA0khX+rKvq+v1+O/O3zhgYMmSIfZXdBruqX6hxVT8ci6v6AXDzqn4dbl4Ussf69+MjFW7I/AEAaCSZf6gQ/AEAcCD4AwBgGp88jRX+AAAwDGV/AAAcKPsDAGAYn8cb/ij7AwBgGMr+AAAYlvkT/AEAMCz4U/YHAMAwZP4AADh5O/En+AMA4ETZHwAAeAplfwAADMv8Cf4AADh4PPYT/AEAMC3z51Q/AAAMQ9kfAAAHjyf+BH8AAJwo+wMAAE+h7A8AgANlfwAADOP3e/ugP93+AAAYhrI/AAAOlP0BADCMz+PRn7I/AACGoewPAICDxxN/gj8AAKaV/cn8AQAwLPhzzB8AAMOQ+QMA4ODxxJ/gDwCAE2V/AADgKZT9AQBwoOwPAIBhfB6P/nT7AwBgGMr+AAA4eDzxJ/gDAOBE2R8AAHgKZX8AABwo+wMAYBifx6M/mT8AAA4ej/3hE/wPrp/j9hQQRlr2n+z2FBBG9v1jhttTQLhp4vHobErwBwAgXPg8nvoT/AEAcPB47GeFPwAATEPmDwCAA2V/AAAM46PsDwAAvISyPwAADpT9AQAwjM/jdX+/2xMAAAANi7I/AAAOHk/8Cf4AAJhW9ifzBwDAweOxn2P+AACYhswfAAAHyv4AABjGR9kfAAB4CWV/AAAc/B5P/Qn+AAA4eDz20+0PAIBpyPwBADCs25+1/QEAcPD7QrcF4/HHH1fPnj0VFxdnb+np6XrzzTdr9peWlmrcuHFKTExUbGysRo0apYKCguCehOAPAEDdmX+otmB07NhR999/vzZu3KgNGzZo8ODBGj58uLZu3WrvnzRpkpYsWaKFCxdq1apV2r17tzIzMxUsyv4AAISJYcOGBdy+99577WrA2rVr7S8Gc+fO1fz58+0vBZbc3Fylpqba+/v163fcz0PwBwDAIZSH/MvKyuztWFFRUfb2QyorK+0Mv6SkxC7/W9WAiooKZWRk1NwnJSVFycnJysvLCyr4c8wfAAAHXwj/ZGdnKz4+PmCzxr7P5s2b7eP51peDm266SYsWLdLpp5+u/Px8RUZGqkWLFgH3T0pKsvcFg8wfAIB6NHXqVGVlZQWM/VDW37VrV23atEnFxcX629/+ptGjR9vH90OJ4A8AgEOwXfo/5HhK/MeysvvOnTvbv6elpWn9+vV69NFHdfnll6u8vFxFRUUB2b/V7d+2bdug5kTZHwCAMOn2r0tVVZXdM2B9EWjatKmWLVtWs2/btm3atWuX3RMQDDJ/AADC6BDB0KFD7Sa+b775xu7sX7lypd566y27V2Ds2LH2IYSEhAR7HYAJEybYgT+YZj8LwR8AAAe3Fvjbu3evrrnmGu3Zs8cO9taCP1bgv+CCC+z9s2bNkt/vtxf3saoBQ4YMUU5OTtDP46uurq5WGCj9zu0ZIJy07D/Z7SkgjOz7xwy3p4AwExtVv9E5c+7GkD3Wq2PTFG445g8AgGEo+wMA4ODx6/oQ/AEAMO2qfmT+AAA4eDz2c8wfAADTkPkDAODg93jqT/AHAMDB26Gfsj8AAMYh8wcAwIFufwAADOP3eN2fFf4AADAMZX8AABwo+wMAYBgfZX8AAOAllP0BAHCg7A8AgGH8Hi/7k/kDAGBY5s+pfgAAGIbMHwAAB2/n/QR/AACMu6ofZX8AAAxD2R8AAAePJ/4EfwAAnOj2BwAAnsIx/zCxYP4LGnrBYPXp3UNXXXGpNn/8sdtTggsmX3Oejrw/UzMmXVwz1qlDol56cLR2vfVHFSy/R8/fd7XaJMTy/hjkgw3rNXH8TRpy/kCl9UzRiuXvuD0lI8r+vhBt4YjgHwaWvvmGZj6YrRtvGacFCxepa9cU3XzjWO3fv9/tqaEBpaWeqLGZ6fp4++6asROiI/X6n69XdbU09JYnNPj6OYpsGqFXHvqt58uS+I8jR46oS9cUTbn9Ll6WBuz294doC0cE/zDw3DO5yrzkMo0YOUqndu6sO6ZNV3R0tBa/+orbU0MDaRYTqdw//T/dcu9CFR06UjOefsbJOqldgq6/e4G2fp5vb9f9cYHOTO2oX5zVmffHEAMGDtItEyZq8PkXuD0VeATB32UV5eX69JOt6pfev2bM7/erX7/++vijD12dGxrOI7dmaum7n2rF+u0B41FNm6i6ulpl5d/VjJWWV6iqqlr9e3XiLQLqiY+yf+iVlZXp0KFDAZs1ZqKDRQdVWVmpxMTEgHHrdmFhoWvzQsO59IJe6tW1g+587I1a+97f8i+VlJbr3vEXKSaqqX0Y4P7fDVOTJhFqm9ictwmoJz6fL2SbEZn/V199pd/+9rc/eJ/s7GzFx8cHbDMeyA71VICw17FNvGZkDdeYu+YHZPdHFRaV6Kqpz+lXA09X4ap7VbD8T4qPjdEHn36tKqsRAEC9BUd/iDYjFvk5cOCAnnnmGT399NPfe5+pU6cqKysrYKw6IkomatmipSIiImo191m3W7Vq5dq80DB6p3ZUUmJz5T07sWbMyurP6d1JN106QPHn3KZl6z5Tt8z7lRh/gr6rrFLx4VJ98eZd+vLtA7xNABom+P/973//wf07d+780ceIioqyt2OV1k56jNA0MlKpp3fTurV5Gnx+hj1WVVWldevydMWVv3F7eqhnK9bvUNoVMwPG/nLX5dr25V499OwK+9j+UfuLv7V/nntWZ7VpGavXV2/l/QHqiS9My/WuBf8RI0bYL4rVhGTqixZqV48eoztvn6Ju3bqre4+eev65Z+xTe0aMzHR7aqhnh78t0yc78wPGSo6U60BxSc341b/uo21fFmjfwRL17XGSZv5+uP784j+0fdc+3h9DfPttib7atavm9u5/f61t//xUcfHxateuvatz8yq/x8NY0MG/Xbt2ysnJ0fDhw+vcv2nTJqWlpYVibsb45dBf6eCBA8qZM1uFhfvUNSVVOU8+pUTK/pDU5aTWunvcUCXEnaB/7TmoB3OXafb81bw2Bvlk6xbdOHZ0ze2HZ9xv//z1xSM0/Z7//zsQDF/1D6Xwdbj44ovVq1cv3X333XXu/+ijj9S7d2+7dB0MU8v+qFvL/pN5aVBj3z9m8GogQGxU/abmWX//Z8ge6+GLU9ToM/8//OEPKikp+d79nTt31ooVK37uvAAAcI3P44evgw7+AwcO/MH9zZo107nnnvtz5gQAABrTqX4AADR2fm8n/gR/AACcPF71D9vFhwAAQD2h7A8AgEO4Xoo3VAj+AAAYVhYn+AMA4ODxxN/zX24AAIADmT8AAA4c8wcAwDA+yv4AAMBLKPsDAODACn8AABjG7/G6P93+AAAYhrI/AAAOHk/8Cf4AAJh2zJ+yPwAAhqHsDwCAg0/eTv0J/gAAGFb2J/gDAGBY8OeYPwAAhiHzBwDAwefxc/0I/gAAOFD2BwAAnkLmDwCAg8er/gR/AACcuLAPAADwFE71AwCgjoa/UG3ByM7OVp8+fdS8eXO1adNGI0aM0LZt2wLuU1paqnHjxikxMVGxsbEaNWqUCgoKgnoegj8AAHUc8w/VFoxVq1bZgX3t2rV6++23VVFRoQsvvFAlJSU195k0aZKWLFmihQsX2vffvXu3MjMzg3oeGv4AAKhHZWVl9nasqKgoe3NaunRpwO158+bZFYCNGzdq0KBBKi4u1ty5czV//nwNHjzYvk9ubq5SU1PtLwz9+vU7rjmR+QMA4OCXL2SbVcqPj48P2Kyx42EFe0tCQoL90/oSYFUDMjIyau6TkpKi5ORk5eXl6XiR+QMAUI+n+k2dOlVZWVkBY3Vl/U5VVVWaOHGiBgwYoO7du9tj+fn5ioyMVIsWLQLum5SUZO87XgR/AADqcYW/7yvx/xjr2P+WLVu0Zs0ahRplfwAAwsz48eP1+uuva8WKFerYsWPNeNu2bVVeXq6ioqKA+1vd/ta+40XwBwCgjkV+QrUFo7q62g78ixYt0vLly9WpU6eA/WlpaWratKmWLVtWM2adCrhr1y6lp6cf9/NQ9gcAIEyW97VK/VYn/2uvvWaf63/0OL7VJBgTE2P/HDt2rN1DYDUBxsXFacKECXbgP95OfwvBHwCAMPH444/bP3/xi18EjFun81177bX277NmzZLf77cX97FOIRwyZIhycnKCeh6CPwAAYbK2v1X2/zHR0dF67LHH7O2nIvgDAGDYVf1o+AMAwDBk/gAAGJYZE/wBAHDwebzu7/UvNwAAwIHMHwAAB2/n/QR/AADC5lS/hkLmDwCAg7dDP8f8AQAwDpk/AAAOHq/6E/wBAHDiVD8AAOAplP0BADBsERyCPwAADpT9AQCAp5D5AwDg4PFmf4I/AACmlf3J/BGW9qx6wO0pIIy0HnyH21NAmDny7r1uT6FRI/gDAOBAtz8AAIbxUfYHAMAsPnmb1ysbAADAgWP+AAA4eLzqT/AHAMDJ7/HCP2V/AAAMQ9kfAAAHyv4AABjGR9kfAAB4CWV/AAAcKPsDAGAYP2V/AADgJZT9AQBwoOwPAIBhfN5e44fMHwAAJ071AwAAnsIxfwAAHPyU/QEAMIuPU/0AAICXUPYHAMCBbn8AAAzjo+wPAAC8hLI/AAAOdPsDAGAYH2V/AADgJZT9AQBwoNsfAADD+ORtZP4AADj4PZ76+92eAAAAaFhk/gAAOHg77yf4AwBgXPSn7A8AgGEo+wMAYNgiPwR/AAAcPN7sT9kfAADTkPkDAODg8cSf4A8AgGnRn25/AAAMQ9kfAAAHuv0BADCMz+NlfzJ/AAAcPB77OeYPAIBpyPwBADAs9Sf4AwBgWMMfp/oBABAmVq9erWHDhql9+/by+XxavHhxwP7q6mrdddddateunWJiYpSRkaHt27cH/TwEfwAA6uj2D9UWjJKSEp1xxhl67LHH6tz/4IMPavbs2XriiSe0bt06NWvWTEOGDFFpaWlQz0PZHwAAh1AW/cvKyuztWFFRUfbmNHToUHuri5X1P/LII7rjjjs0fPhwe+zZZ59VUlKSXSG44oorjntOZP4AANSj7OxsxcfHB2zWWLC++OIL5efn26X+o6zH6tu3r/Ly8oJ6LDJ/AADqMfWfOnWqsrKyAsbqyvp/jBX4LVamfyzr9tF9x4vgDwBAPXb7f1+J302U/QEAaATatm1r/ywoKAgYt24f3Xe8CP4AAIRJt/8P6dSpkx3kly1bVjN26NAhu+s/PT09qMei7A8AgINbS/wcPnxYO3bsCGjy27RpkxISEpScnKyJEyfqnnvu0WmnnWZ/GbjzzjvtNQFGjBgR1PMQ/AEACJPov2HDBp133nk1t482Co4ePVrz5s3Trbfeaq8FcMMNN6ioqEjnnHOOli5dqujo6KCex1dtnTgYBkq/k9EWzH9Bz+TOVWHhPnXpmqLbbr9TPXr2lKlKKyplqnlz/6KVy97Rv77cqaioaPU4o5fGT/y9Tjq5k0zVLuMumWjybwbpTzcP0ZyX39UfHn3DHktKiNV9436pwX06q/kJUfpsV6EefHalFq/cKpMceffeen38Lf8+HLLH6t4hVuGGY/5hYOmbb2jmg9m68ZZxWrBwkbp2TdHNN47V/v373Z4aXPDhxg265PIrNffZFzX7iaf03Xff6b9uvk5HjnzL+2GQtJQOGju8jz7evidg/Kk7L1GX5Na6dMrzOuua2Xpt1VY9f/cVOuO0dq7N1avd/r4Q/QlHBP8w8Nwzucq85DKNGDlKp3burDumTbdLOItffcXtqcEFj+b8Rb8ePlKndD7NrgLddfd9yt+zR//85BPeD0M0i4lU7rTLdMsDi1X0zZGAff26Jyvnb3na8OnX+nL3QT3wzEoVHS5V75QOrs3Xi3xh2PAXSgR/l1WUl+vTT7aqX3r/mjG/369+/frr448+dHVuCA+HD39j/4yLj3d7Kmggj/x+mJbmbdOKDZ/X2rd2yy5dcn4PtWweY1/45dLzeyg6solWf7CT9wfHjYY/lx0sOqjKykolJiYGjFu3v/iC/5hNV1VVpVkz7lfPXmfq1M6nuT0dNAArmPfq0l7nXPd4nft/c+cCPXf3Fdq99A5VfFepb0srdPntL2jnvw/w/oSQz+OvZtCZ/5EjR7RmzRp9UkcJ0rqqkHWRgR9jXeDAOjfx2M150QMA0ozsP2nnju2654GZvBwG6NgmXjMm/lpjpr+ssvK6u6CnXZ+hFrHRGvpfczVgbI5mL3jXPubf7ZTAJV8RgujvC9HW2IP/Z599ptTUVA0aNEg9evTQueeeqz17/tOMUlxcrDFjxvykixzMeCD4ixx4QcsWLRUREVGruc+63apVK9fmBffNyL5Ha1avUs5T85SUFNzqXWicendtb3fz5z09Tt+sutveBp15im65JN3+vVOHBN18SbpuzH5VKzfu1OYd+bovd7k++Oe/deOofm5PH14t+0+ZMkXdu3e3z0O0zi+0FhsYMGCAVq5caS8+8HMuclAdEV7rHjeUppGRSj29m9atzdPg8zNqSr3r1uXpiit/4/b04ALr7NuZ99+rVcvfsQN/+w4deR8MsWLj50r7zaMBY3/571Ha9q99euj51Tohqqk9VlUVeIZ2ZVW1/OHaWdZI+cI1ZXcj+L/33nt655137IzU2pYsWaJbbrlFAwcO1IoVK9SsWbOffJEDk8/zv3r0GN15+xR169Zd3Xv01PPPPWMfXhkxMtPtqcEFM+77k956838045E59n9T+wv32ePNYpsHvZAHGpfD35brky/2BoyVHCnXgUPf2uNNIvza8VWh5tw6XFPnLNX+Q9/q4oGpOr/Pqcq89TnX5u1FPm/H/uCCvxWQmjT5z1+xOk0ff/xxjR8/3j4EMH/+/PqYo+f9cuivdPDAAeXMmW0v8tM1JVU5Tz6lRMr+Rnpl4QL7583XjQ4Yv3P6vfYpgDDXd5VVGjH5Wd1z84X624NXKzYmUp9/vV/X3fOK3sr7zO3poREJaoW/s88+WxMmTNDVV19da5/1BeCFF16wm/es7vVgmZz5ozaTV/hDbaau8Af3Vvj7LD90i2p1aXuCGnXD38iRI/Xiiy/WuW/OnDm68sor7eOVAAA0aj5vd/uztj/CEpk/jkXmj4bO/LcXBK6s+HOclhSjcMMKfwAAGIYV/gAAcKDbHwAAw/jkbZT9AQAwDGV/AAAMS/0J/gAAGLa8L2V/AAAMQ+YPAIAD3f4AABjGJ2+j7A8AgGEo+wMAYFjqT/AHAMCwbn+CPwAAhjX8ccwfAADDkPkDAODg8cSf4A8AgBNlfwAA4CmU/QEAMKzwT/AHAMCBsj8AAPAUMn8AAIwq+hP8AQCohbI/AADwFMr+AAA4sLY/AACm8cnTyPwBADAr9nNhHwAATEPmDwCAYd3+BH8AAAxr+PO7PQEAANCwyPwBAHDyduJP8AcAwLDYT9kfAADTUPYHAMCBbn8AAAzj83jhn25/AAAMQ9kfAADDyv5k/gAAGIbMHwAABzJ/AADgKWT+AAAY1u1P8AcAwIGyPwAA8BQyfwAAHLxd9Cf4AwBgXPTnPH8AAAxD2R8AAAe6/QEAMIyPsj8AAPASyv4AADh4PPEn+AMAYFr0p9sfAIA6Gv5C9SdYjz32mE4++WRFR0erb9++ev/99xVqBH8AAMLESy+9pKysLE2bNk0ffPCBzjjjDA0ZMkR79+4N6fMQ/AEAqKPbP1RbWVmZDh06FLBZY3V5+OGHdf3112vMmDE6/fTT9cQTT+iEE07Q008/rZCqRtgoLS2tnjZtmv0T4PMA/v/BG6ZNm1ZthdtjN2vMqaysrDoiIqJ60aJFAePXXHNN9cUXXxzSOfms/wnt1wn8VNa3wfj4eBUXFysuLo4X0nB8HsDnwRvKyspqZfpRUVH2dqzdu3erQ4cOeu+995Senl4zfuutt2rVqlVat25dyObEqX4AANSjugK92zjmDwBAGGjVqpUiIiJUUFAQMG7dbtu2bUifi+APAEAYiIyMVFpampYtW1YzVlVVZd8+9jBAKFD2DyNWWcg6vSPcykNwB58H8HkwT1ZWlkaPHq2zzjpLZ599th555BGVlJTY3f+hRMMfAABhZM6cOZoxY4by8/PVq1cvzZ49217sJ5QI/gAAGIZj/gAAGIbgDwCAYQj+AAAYhuAPAIBhCP5hoiEu4YjGYfXq1Ro2bJjat28vn8+nxYsXuz0luCg7O1t9+vRR8+bN1aZNG40YMULbtm3jPcHPQvA36BKOaBysc3qtz4D1hRCw1nQfN26c1q5dq7ffflsVFRW68MIL7c8J8FNxql8YsDJ965u9dW7n0RWdTjzxRE2YMEG33Xab29ODi6zMf9GiRXa2B1j27dtnVwCsLwWDBg3iRcFPQubvsvLycm3cuFEZGRk1Y36/376dl5fn6twAhB/rqp+WhIQEt6eCRozg77LCwkJVVlYqKSkpYNy6ba3uBABHWVXBiRMnasCAAerevTsvDH4y1vYHgEbCOva/ZcsWrVmzxu2poJEj+Bt0CUcAjdf48eP1+uuv22eDdOzY0e3poJGj7G/QJRwBND7V1dV24LcaP5cvX65OnTq5PSV4AJm/QZdwRONw+PBh7dixo+b2F198oU2bNtkNXsnJya7ODe6U+ufPn6/XXnvNPtf/aC9QfHy8YmJieEvwk3Cqn0GXcETjsHLlSp133nm1xq0viPPmzXNlTnD3dM+65Obm6tprr23w+cAbCP4AABiGY/4AABiG4A8AgGEI/gAAGIbgDwCAYQj+AAAYhuAPAIBhCP4AABiG4A8AgGEI/gAAGIbgDwCAYQj+AADILP8HUyqHSPMdLEIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Voting( \n",
    "        X[:,2:] , # Doing this cause I wanted to introduce some hurdles and find how well can ensembling work on\n",
    "        # models using Soft and Hard Votings.\n",
    "        y , \n",
    "        'soft'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "38ca9ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now soft method is performing good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "7e325786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now what does this mean ? \n",
    "#           Basically these are hyperparameters we use to tune and get better results. \n",
    "#           Not just this but also the parameters passed to each model can also be hypertuned . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "963db1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will implement regression models and VotingRegressor on regression dataset and see how the model gradually improves . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "e8a20b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be using students' dataset to predict performance index based on other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "ce811f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('L2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "84528796",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Extracurricular Activities'] = df['Extracurricular Activities'].map({\n",
    "    'Yes' : 1 ,\n",
    "    'No' : 0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "428ff356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Hours Studied",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Previous Scores",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Extracurricular Activities",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Sleep Hours",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Sample Question Papers Practiced",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Performance Index",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "e0dacfae-6f2b-4999-9f3f-cd0f590381b4",
       "rows": [
        [
         "0",
         "7",
         "99",
         "1",
         "9",
         "1",
         "91.0"
        ],
        [
         "1",
         "4",
         "82",
         "0",
         "4",
         "2",
         "65.0"
        ],
        [
         "2",
         "8",
         "51",
         "1",
         "7",
         "2",
         "45.0"
        ],
        [
         "3",
         "5",
         "52",
         "1",
         "5",
         "2",
         "36.0"
        ],
        [
         "4",
         "7",
         "75",
         "0",
         "8",
         "5",
         "66.0"
        ],
        [
         "5",
         "3",
         "78",
         "0",
         "9",
         "6",
         "61.0"
        ],
        [
         "6",
         "7",
         "73",
         "1",
         "5",
         "6",
         "63.0"
        ],
        [
         "7",
         "8",
         "45",
         "1",
         "4",
         "6",
         "42.0"
        ],
        [
         "8",
         "5",
         "77",
         "0",
         "8",
         "2",
         "61.0"
        ],
        [
         "9",
         "4",
         "89",
         "0",
         "4",
         "0",
         "69.0"
        ],
        [
         "10",
         "8",
         "91",
         "0",
         "4",
         "5",
         "84.0"
        ],
        [
         "11",
         "8",
         "79",
         "0",
         "6",
         "2",
         "73.0"
        ],
        [
         "12",
         "3",
         "47",
         "0",
         "9",
         "2",
         "27.0"
        ],
        [
         "13",
         "6",
         "47",
         "0",
         "4",
         "2",
         "33.0"
        ],
        [
         "14",
         "5",
         "79",
         "0",
         "7",
         "8",
         "68.0"
        ],
        [
         "15",
         "2",
         "72",
         "0",
         "4",
         "3",
         "43.0"
        ],
        [
         "16",
         "8",
         "73",
         "1",
         "8",
         "4",
         "67.0"
        ],
        [
         "17",
         "6",
         "83",
         "1",
         "7",
         "2",
         "70.0"
        ],
        [
         "18",
         "2",
         "54",
         "1",
         "4",
         "9",
         "30.0"
        ],
        [
         "19",
         "5",
         "75",
         "0",
         "7",
         "0",
         "63.0"
        ],
        [
         "20",
         "1",
         "99",
         "1",
         "4",
         "3",
         "71.0"
        ],
        [
         "21",
         "6",
         "96",
         "0",
         "9",
         "0",
         "85.0"
        ],
        [
         "22",
         "9",
         "74",
         "1",
         "7",
         "6",
         "73.0"
        ],
        [
         "23",
         "1",
         "85",
         "0",
         "5",
         "6",
         "57.0"
        ],
        [
         "24",
         "3",
         "61",
         "0",
         "6",
         "3",
         "35.0"
        ],
        [
         "25",
         "7",
         "62",
         "1",
         "7",
         "4",
         "49.0"
        ],
        [
         "26",
         "4",
         "79",
         "0",
         "8",
         "9",
         "66.0"
        ],
        [
         "27",
         "9",
         "84",
         "1",
         "6",
         "6",
         "83.0"
        ],
        [
         "28",
         "3",
         "94",
         "1",
         "6",
         "5",
         "74.0"
        ],
        [
         "29",
         "5",
         "90",
         "1",
         "4",
         "3",
         "74.0"
        ],
        [
         "30",
         "3",
         "61",
         "1",
         "7",
         "3",
         "39.0"
        ],
        [
         "31",
         "7",
         "44",
         "1",
         "9",
         "1",
         "36.0"
        ],
        [
         "32",
         "5",
         "70",
         "1",
         "6",
         "9",
         "58.0"
        ],
        [
         "33",
         "9",
         "52",
         "1",
         "8",
         "1",
         "47.0"
        ],
        [
         "34",
         "7",
         "67",
         "1",
         "9",
         "3",
         "60.0"
        ],
        [
         "35",
         "2",
         "97",
         "1",
         "9",
         "4",
         "74.0"
        ],
        [
         "36",
         "4",
         "59",
         "0",
         "8",
         "3",
         "42.0"
        ],
        [
         "37",
         "9",
         "72",
         "0",
         "8",
         "2",
         "68.0"
        ],
        [
         "38",
         "2",
         "55",
         "1",
         "4",
         "1",
         "32.0"
        ],
        [
         "39",
         "9",
         "68",
         "0",
         "5",
         "3",
         "64.0"
        ],
        [
         "40",
         "5",
         "62",
         "0",
         "7",
         "4",
         "45.0"
        ],
        [
         "41",
         "2",
         "63",
         "1",
         "6",
         "0",
         "39.0"
        ],
        [
         "42",
         "4",
         "73",
         "1",
         "7",
         "0",
         "58.0"
        ],
        [
         "43",
         "7",
         "46",
         "0",
         "9",
         "5",
         "36.0"
        ],
        [
         "44",
         "8",
         "77",
         "1",
         "6",
         "4",
         "71.0"
        ],
        [
         "45",
         "3",
         "76",
         "1",
         "4",
         "3",
         "54.0"
        ],
        [
         "46",
         "1",
         "43",
         "1",
         "7",
         "0",
         "17.0"
        ],
        [
         "47",
         "4",
         "73",
         "0",
         "4",
         "6",
         "54.0"
        ],
        [
         "48",
         "2",
         "81",
         "1",
         "4",
         "3",
         "58.0"
        ],
        [
         "49",
         "8",
         "61",
         "0",
         "7",
         "2",
         "53.0"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 10000
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hours Studied</th>\n",
       "      <th>Previous Scores</th>\n",
       "      <th>Extracurricular Activities</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Sample Question Papers Practiced</th>\n",
       "      <th>Performance Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>6</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>7</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Hours Studied  Previous Scores  Extracurricular Activities  Sleep Hours  \\\n",
       "0                 7               99                           1            9   \n",
       "1                 4               82                           0            4   \n",
       "2                 8               51                           1            7   \n",
       "3                 5               52                           1            5   \n",
       "4                 7               75                           0            8   \n",
       "...             ...              ...                         ...          ...   \n",
       "9995              1               49                           1            4   \n",
       "9996              7               64                           1            8   \n",
       "9997              6               83                           1            8   \n",
       "9998              9               97                           1            7   \n",
       "9999              7               74                           0            8   \n",
       "\n",
       "      Sample Question Papers Practiced  Performance Index  \n",
       "0                                    1               91.0  \n",
       "1                                    2               65.0  \n",
       "2                                    2               45.0  \n",
       "3                                    2               36.0  \n",
       "4                                    5               66.0  \n",
       "...                                ...                ...  \n",
       "9995                                 2               23.0  \n",
       "9996                                 5               58.0  \n",
       "9997                                 5               74.0  \n",
       "9998                                 0               95.0  \n",
       "9999                                 1               64.0  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "ed457237",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lr = df.drop(columns=['Performance Index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "bfdd2121",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lr = df['Performance Index'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "5d20a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "47d0b442",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1 = LinearRegression()\n",
    "sgd1 = SGDRegressor()\n",
    "clg1 = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "9a8a2f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('LinearRegression', lr1),\n",
    "    ('StochasticGradientDescent' , sgd1),\n",
    "    ('DecisionTreeRegressor' , clg1) , \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "043e4f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "03fae97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "voteReg = VotingRegressor(\n",
    "    estimators = estimators\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "284c07fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-19.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-19.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-19 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-19 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-19 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-19 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-19 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-19 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-19 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-19 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-19 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-19 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-19 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingRegressor(estimators=[(&#x27;LinearRegression&#x27;, LinearRegression()),\n",
       "                            (&#x27;StochasticGradientDescent&#x27;, SGDRegressor()),\n",
       "                            (&#x27;DecisionTreeRegressor&#x27;, DecisionTreeRegressor())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-80\" type=\"checkbox\" ><label for=\"sk-estimator-id-80\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>VotingRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingRegressor.html\">?<span>Documentation for VotingRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingRegressor.html#:~:text=estimators,-list%20of%20%28str%2C%20estimator%29%20tuples\">\n",
       "            estimators\n",
       "            <span class=\"param-doc-description\">estimators: list of (str, estimator) tuples<br><br>Invoking the ``fit`` method on the ``VotingRegressor`` will fit clones<br>of those original estimators that will be stored in the class attribute<br>``self.estimators_``. An estimator can be set to ``'drop'`` using<br>:meth:`set_params`.<br><br>.. versionchanged:: 0.21<br>    ``'drop'`` is accepted. Using None was deprecated in 0.22 and<br>    support was removed in 0.24.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">[(&#x27;LinearRegression&#x27;, ...), (&#x27;StochasticGradientDescent&#x27;, ...), ...]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingRegressor.html#:~:text=weights,-array-like%20of%20shape%20%28n_regressors%2C%29%2C%20default%3DNone\">\n",
       "            weights\n",
       "            <span class=\"param-doc-description\">weights: array-like of shape (n_regressors,), default=None<br><br>Sequence of weights (`float` or `int`) to weight the occurrences of<br>predicted values before averaging. Uses uniform weights if `None`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingRegressor.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of jobs to run in parallel for ``fit``.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingRegressor.html#:~:text=verbose,-bool%2C%20default%3DFalse\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: bool, default=False<br><br>If True, the time elapsed while fitting will be printed as it<br>is completed.<br><br>.. versionadded:: 0.23</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>LinearRegression</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-81\" type=\"checkbox\" ><label for=\"sk-estimator-id-81\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"LinearRegression__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Whether to calculate the intercept for this model. If set<br>to False, no intercept will be used in calculations<br>(i.e. data is expected to be centered).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html#:~:text=copy_X,-bool%2C%20default%3DTrue\">\n",
       "            copy_X\n",
       "            <span class=\"param-doc-description\">copy_X: bool, default=True<br><br>If True, X will be copied; else, it may be overwritten.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html#:~:text=tol,-float%2C%20default%3D1e-6\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-6<br><br>The precision of the solution (`coef_`) is determined by `tol` which<br>specifies a different convergence criterion for the `lsqr` solver.<br>`tol` is set as `atol` and `btol` of :func:`scipy.sparse.linalg.lsqr` when<br>fitting on sparse training data. This parameter has no effect when fitting<br>on dense data.<br><br>.. versionadded:: 1.7</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1e-06</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of jobs to use for the computation. This will only provide<br>speedup in case of sufficiently large problems, that is if firstly<br>`n_targets > 1` and secondly `X` is sparse or if `positive` is set<br>to `True`. ``None`` means 1 unless in a<br>:obj:`joblib.parallel_backend` context. ``-1`` means using all<br>processors. See :term:`Glossary <n_jobs>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LinearRegression.html#:~:text=positive,-bool%2C%20default%3DFalse\">\n",
       "            positive\n",
       "            <span class=\"param-doc-description\">positive: bool, default=False<br><br>When set to ``True``, forces the coefficients to be positive. This<br>option is only supported for dense arrays.<br><br>For a comparison between a linear regression model with positive constraints<br>on the regression coefficients and a linear regression without such constraints,<br>see :ref:`sphx_glr_auto_examples_linear_model_plot_nnls.py`.<br><br>.. versionadded:: 0.24</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>StochasticGradientDescent</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-82\" type=\"checkbox\" ><label for=\"sk-estimator-id-82\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SGDRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDRegressor.html\">?<span>Documentation for SGDRegressor</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"StochasticGradientDescent__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('loss',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDRegressor.html#:~:text=loss,-str%2C%20default%3D%27squared_error%27\">\n",
       "            loss\n",
       "            <span class=\"param-doc-description\">loss: str, default='squared_error'<br><br>The loss function to be used. The possible values are 'squared_error',<br>'huber', 'epsilon_insensitive', or 'squared_epsilon_insensitive'<br><br>The 'squared_error' refers to the ordinary least squares fit.<br>'huber' modifies 'squared_error' to focus less on getting outliers<br>correct by switching from squared to linear loss past a distance of<br>epsilon. 'epsilon_insensitive' ignores errors less than epsilon and is<br>linear past that; this is the loss function used in SVR.<br>'squared_epsilon_insensitive' is the same but becomes squared loss past<br>a tolerance of epsilon.<br><br>More details about the losses formulas can be found in the<br>:ref:`User Guide <sgd_mathematical_formulation>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;squared_error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDRegressor.html#:~:text=penalty,-%7B%27l2%27%2C%20%27l1%27%2C%20%27elasticnet%27%2C%20None%7D%2C%20default%3D%27l2%27\">\n",
       "            penalty\n",
       "            <span class=\"param-doc-description\">penalty: {'l2', 'l1', 'elasticnet', None}, default='l2'<br><br>The penalty (aka regularization term) to be used. Defaults to 'l2'<br>which is the standard regularizer for linear SVM models. 'l1' and<br>'elasticnet' might bring sparsity to the model (feature selection)<br>not achievable with 'l2'. No penalty is added when set to `None`.<br><br>You can see a visualisation of the penalties in<br>:ref:`sphx_glr_auto_examples_linear_model_plot_sgd_penalties.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDRegressor.html#:~:text=alpha,-float%2C%20default%3D0.0001\">\n",
       "            alpha\n",
       "            <span class=\"param-doc-description\">alpha: float, default=0.0001<br><br>Constant that multiplies the regularization term. The higher the<br>value, the stronger the regularization. Also used to compute the<br>learning rate when `learning_rate` is set to 'optimal'.<br>Values must be in the range `[0.0, inf)`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDRegressor.html#:~:text=l1_ratio,-float%2C%20default%3D0.15\">\n",
       "            l1_ratio\n",
       "            <span class=\"param-doc-description\">l1_ratio: float, default=0.15<br><br>The Elastic Net mixing parameter, with 0 <= l1_ratio <= 1.<br>l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1.<br>Only used if `penalty` is 'elasticnet'.<br>Values must be in the range `[0.0, 1.0]` or can be `None` if<br>`penalty` is not `elasticnet`.<br><br>.. versionchanged:: 1.7<br>    `l1_ratio` can be `None` when `penalty` is not \"elasticnet\".</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.15</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDRegressor.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Whether the intercept should be estimated or not. If False, the<br>data is assumed to be already centered.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDRegressor.html#:~:text=max_iter,-int%2C%20default%3D1000\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=1000<br><br>The maximum number of passes over the training data (aka epochs).<br>It only impacts the behavior in the ``fit`` method, and not the<br>:meth:`partial_fit` method.<br>Values must be in the range `[1, inf)`.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDRegressor.html#:~:text=tol,-float%20or%20None%2C%20default%3D1e-3\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float or None, default=1e-3<br><br>The stopping criterion. If it is not None, training will stop<br>when (loss > best_loss - tol) for ``n_iter_no_change`` consecutive<br>epochs.<br>Convergence is checked against the training loss or the<br>validation loss depending on the `early_stopping` parameter.<br>Values must be in the range `[0.0, inf)`.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('shuffle',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDRegressor.html#:~:text=shuffle,-bool%2C%20default%3DTrue\">\n",
       "            shuffle\n",
       "            <span class=\"param-doc-description\">shuffle: bool, default=True<br><br>Whether or not the training data should be shuffled after each epoch.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDRegressor.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>The verbosity level.<br>Values must be in the range `[0, inf)`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('epsilon',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDRegressor.html#:~:text=epsilon,-float%2C%20default%3D0.1\">\n",
       "            epsilon\n",
       "            <span class=\"param-doc-description\">epsilon: float, default=0.1<br><br>Epsilon in the epsilon-insensitive loss functions; only if `loss` is<br>'huber', 'epsilon_insensitive', or 'squared_epsilon_insensitive'.<br>For 'huber', determines the threshold at which it becomes less<br>important to get the prediction exactly right.<br>For epsilon-insensitive, any differences between the current prediction<br>and the correct label are ignored if they are less than this threshold.<br>Values must be in the range `[0.0, inf)`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDRegressor.html#:~:text=random_state,-int%2C%20RandomState%20instance%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance, default=None<br><br>Used for shuffling the data, when ``shuffle`` is set to ``True``.<br>Pass an int for reproducible output across multiple function calls.<br>See :term:`Glossary <random_state>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDRegressor.html#:~:text=learning_rate,-str%2C%20default%3D%27invscaling%27\">\n",
       "            learning_rate\n",
       "            <span class=\"param-doc-description\">learning_rate: str, default='invscaling'<br><br>The learning rate schedule:<br><br>- 'constant': `eta = eta0`<br>- 'optimal': `eta = 1.0 / (alpha * (t + t0))`<br>  where t0 is chosen by a heuristic proposed by Leon Bottou.<br>- 'invscaling': `eta = eta0 / pow(t, power_t)`<br>- 'adaptive': eta = eta0, as long as the training keeps decreasing.<br>  Each time n_iter_no_change consecutive epochs fail to decrease the<br>  training loss by tol or fail to increase validation score by tol if<br>  early_stopping is True, the current learning rate is divided by 5.<br>- 'pa1': passive-aggressive algorithm 1, see [1]_. Only with<br>  `loss='epsilon_insensitive'`.<br>  Update is `w += eta y x` with `eta = min(eta0, loss/||x||**2)`.<br>- 'pa2': passive-aggressive algorithm 2, see [1]_. Only with<br>  `loss='epsilon_insensitive'`.<br>  Update is `w += eta y x` with `eta = hinge_loss / (||x||**2 + 1/(2 eta0))`.<br><br>.. versionadded:: 0.20<br>    Added 'adaptive' option.<br><br>.. versionadded:: 1.8<br>   Added options 'pa1' and 'pa2'</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;invscaling&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eta0',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDRegressor.html#:~:text=eta0,-float%2C%20default%3D0.01\">\n",
       "            eta0\n",
       "            <span class=\"param-doc-description\">eta0: float, default=0.01<br><br>The initial learning rate for the 'constant', 'invscaling' or<br>'adaptive' schedules. The default value is 0.01.<br>Values must be in the range `(0.0, inf)`.<br><br>For PA-1 (`learning_rate=pa1`) and PA-II (`pa2`), it specifies the<br>aggressiveness parameter for the passive-agressive algorithm, see [1] where it<br>is called C:<br><br>- For PA-I it is the maximum step size.<br>- For PA-II it regularizes the step size (the smaller `eta0` the more it<br>  regularizes).<br><br>As a general rule-of-thumb for PA, `eta0` should be small when the data is<br>noisy.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.01</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('power_t',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDRegressor.html#:~:text=power_t,-float%2C%20default%3D0.25\">\n",
       "            power_t\n",
       "            <span class=\"param-doc-description\">power_t: float, default=0.25<br><br>The exponent for inverse scaling learning rate.<br>Values must be in the range `[0.0, inf)`.<br><br>.. deprecated:: 1.8<br>    Negative values for `power_t` are deprecated in version 1.8 and will raise<br>    an error in 1.10. Use values in the range [0.0, inf) instead.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.25</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDRegressor.html#:~:text=early_stopping,-bool%2C%20default%3DFalse\">\n",
       "            early_stopping\n",
       "            <span class=\"param-doc-description\">early_stopping: bool, default=False<br><br>Whether to use early stopping to terminate training when validation<br>score is not improving. If set to True, it will automatically set aside<br>a fraction of training data as validation and terminate<br>training when validation score returned by the `score` method is not<br>improving by at least `tol` for `n_iter_no_change` consecutive<br>epochs.<br><br>See :ref:`sphx_glr_auto_examples_linear_model_plot_sgd_early_stopping.py` for an<br>example of the effects of early stopping.<br><br>.. versionadded:: 0.20<br>    Added 'early_stopping' option</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validation_fraction',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDRegressor.html#:~:text=validation_fraction,-float%2C%20default%3D0.1\">\n",
       "            validation_fraction\n",
       "            <span class=\"param-doc-description\">validation_fraction: float, default=0.1<br><br>The proportion of training data to set aside as validation set for<br>early stopping. Must be between 0 and 1.<br>Only used if `early_stopping` is True.<br>Values must be in the range `(0.0, 1.0)`.<br><br>.. versionadded:: 0.20<br>    Added 'validation_fraction' option</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_iter_no_change',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDRegressor.html#:~:text=n_iter_no_change,-int%2C%20default%3D5\">\n",
       "            n_iter_no_change\n",
       "            <span class=\"param-doc-description\">n_iter_no_change: int, default=5<br><br>Number of iterations with no improvement to wait before stopping<br>fitting.<br>Convergence is checked against the training loss or the<br>validation loss depending on the `early_stopping` parameter.<br>Integer values must be in the range `[1, max_iter)`.<br><br>.. versionadded:: 0.20<br>    Added 'n_iter_no_change' option</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDRegressor.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to True, reuse the solution of the previous call to fit as<br>initialization, otherwise, just erase the previous solution.<br>See :term:`the Glossary <warm_start>`.<br><br>Repeatedly calling fit or partial_fit when warm_start is True can<br>result in a different solution than when calling fit a single time<br>because of the way the data is shuffled.<br>If a dynamic learning rate is used, the learning rate is adapted<br>depending on the number of samples already seen. Calling ``fit`` resets<br>this counter, while ``partial_fit``  will result in increasing the<br>existing counter.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('average',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDRegressor.html#:~:text=average,-bool%20or%20int%2C%20default%3DFalse\">\n",
       "            average\n",
       "            <span class=\"param-doc-description\">average: bool or int, default=False<br><br>When set to True, computes the averaged SGD weights across all<br>updates and stores the result in the ``coef_`` attribute. If set to<br>an int greater than 1, averaging will begin once the total number of<br>samples seen reaches `average`. So ``average=10`` will begin<br>averaging after seeing 10 samples.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>DecisionTreeRegressor</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-83\" type=\"checkbox\" ><label for=\"sk-estimator-id-83\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html\">?<span>Documentation for DecisionTreeRegressor</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"DecisionTreeRegressor__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=criterion,-%7B%22squared_error%22%2C%20%22friedman_mse%22%2C%20%22absolute_error%22%2C%20%20%20%20%20%20%20%20%20%20%20%20%20%22poisson%22%7D%2C%20default%3D%22squared_error%22\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {\"squared_error\", \"friedman_mse\", \"absolute_error\",             \"poisson\"}, default=\"squared_error\"<br><br>The function to measure the quality of a split. Supported criteria<br>are \"squared_error\" for the mean squared error, which is equal to<br>variance reduction as feature selection criterion and minimizes the L2<br>loss using the mean of each terminal node, \"friedman_mse\", which uses<br>mean squared error with Friedman's improvement score for potential<br>splits, \"absolute_error\" for the mean absolute error, which minimizes<br>the L1 loss using the median of each terminal node, and \"poisson\" which<br>uses reduction in the half mean Poisson deviance to find splits.<br><br>.. versionadded:: 0.18<br>   Mean Absolute Error (MAE) criterion.<br><br>.. versionadded:: 0.24<br>    Poisson deviance criterion.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;squared_error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('splitter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=splitter,-%7B%22best%22%2C%20%22random%22%7D%2C%20default%3D%22best%22\">\n",
       "            splitter\n",
       "            <span class=\"param-doc-description\">splitter: {\"best\", \"random\"}, default=\"best\"<br><br>The strategy used to choose the split at each node. Supported<br>strategies are \"best\" to choose the best split and \"random\" to choose<br>the best random split.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;best&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=max_depth,-int%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int, default=None<br><br>The maximum depth of the tree. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.<br><br>For an example of how ``max_depth`` influences the model, see<br>:ref:`sphx_glr_auto_examples_tree_plot_tree_regression.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, then consider `min_samples_split` as the minimum number.<br>- If float, then `min_samples_split` is a fraction and<br>  `ceil(min_samples_split * n_samples)` are the minimum<br>  number of samples for each split.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, then consider `min_samples_leaf` as the minimum number.<br>- If float, then `min_samples_leaf` is a fraction and<br>  `ceil(min_samples_leaf * n_samples)` are the minimum<br>  number of samples for each node.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=max_features,-int%2C%20float%20or%20%7B%22sqrt%22%2C%20%22log2%22%7D%2C%20default%3DNone\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: int, float or {\"sqrt\", \"log2\"}, default=None<br><br>The number of features to consider when looking for the best split:<br><br>- If int, then consider `max_features` features at each split.<br>- If float, then `max_features` is a fraction and<br>  `max(1, int(max_features * n_features_in_))` features are considered at each<br>  split.<br>- If \"sqrt\", then `max_features=sqrt(n_features)`.<br>- If \"log2\", then `max_features=log2(n_features)`.<br>- If None, then `max_features=n_features`.<br><br>Note: the search for a split does not stop until at least one<br>valid partition of the node samples is found, even if it requires to<br>effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls the randomness of the estimator. The features are always<br>randomly permuted at each split, even if ``splitter`` is set to<br>``\"best\"``. When ``max_features < n_features``, the algorithm will<br>select ``max_features`` at random at each split before finding the best<br>split among them. But the best found split may vary across different<br>runs, even if ``max_features=n_features``. That is the case, if the<br>improvement of the criterion is identical for several splits and one<br>split has to be selected at random. To obtain a deterministic behaviour<br>during fitting, ``random_state`` has to be fixed to an integer.<br>See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow a tree with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>If None then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>:ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeRegressor.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features), default=None<br><br>Indicates the monotonicity constraint to enforce on each feature.<br>  - 1: monotonic increase<br>  - 0: no constraint<br>  - -1: monotonic decrease<br><br>If monotonic_cst is None, no constraints are applied.<br><br>Monotonicity constraints are not supported for:<br>  - multioutput regressions (i.e. when `n_outputs_ > 1`),<br>  - regressions trained on data with missing values.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-19');</script></body>"
      ],
      "text/plain": [
       "VotingRegressor(estimators=[('LinearRegression', LinearRegression()),\n",
       "                            ('StochasticGradientDescent', SGDRegressor()),\n",
       "                            ('DecisionTreeRegressor', DecisionTreeRegressor())])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voteReg.fit(X_lr,y_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "0e1e7197",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_reg = voteReg.predict(X_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "cac26e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error,mean_absolute_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "6b929de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 score : 0.9922292438224448\n",
      "The mae score : 1.3616656914525802\n",
      "The rmse score : 1.6935386493622622\n",
      "The cvs score : -5.881924692371743e+17\n"
     ]
    }
   ],
   "source": [
    "print(f'The r2 score : {r2_score(y_lr,y_pred_reg)}')\n",
    "print(f'The mae score : {mean_absolute_error(y_lr,y_pred_reg)}')\n",
    "print(f'The rmse score : {root_mean_squared_error(y_lr,y_pred_reg)}')\n",
    "print(f'The cvs score : {cross_val_score(voteReg,X_lr,y_lr,cv=10).mean()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
