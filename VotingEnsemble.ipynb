{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "bf496991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the necessary imports for the programme\n",
    "from sklearn.datasets import load_iris # We are gonna use the iris dataset for this demonstration.\n",
    "from sklearn.metrics import classification_report,confusion_matrix # Evaluation metrics for classification\n",
    "from sklearn.model_selection import cross_val_score # Cross val score to predict using different combinations of the folds.\n",
    "import pandas as pd # For dataframem manipulation\n",
    "import seaborn as sns # For plotting graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "07e8c6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_iris(return_X_y=True) # load the dataset\n",
    "# Basically we already have the variables and labels stored in different values , reducing wokload(preprocessing). \n",
    "# In iris dataset we are give iris flower properties (continous numeric) and we have to predict based on this properties\n",
    "# which flower belong to which class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "e0d607c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ad9202ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-16.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-16.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-16 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-16 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-16 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-16 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-16 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-16 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-16 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-16 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-16 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-72\" type=\"checkbox\" checked><label for=\"sk-estimator-id-72\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=penalty,-%7B%27l1%27%2C%20%27l2%27%2C%20%27elasticnet%27%2C%20None%7D%2C%20default%3D%27l2%27\">\n",
       "            penalty\n",
       "            <span class=\"param-doc-description\">penalty: {'l1', 'l2', 'elasticnet', None}, default='l2'<br><br>Specify the norm of the penalty:<br><br>- `None`: no penalty is added;<br>- `'l2'`: add a L2 penalty term and it is the default choice;<br>- `'l1'`: add a L1 penalty term;<br>- `'elasticnet'`: both L1 and L2 penalty terms are added.<br><br>.. warning::<br>   Some penalties may not work with some solvers. See the parameter<br>   `solver` below, to know the compatibility between the penalty and<br>   solver.<br><br>.. versionadded:: 0.19<br>   l1 penalty with SAGA solver (allowing 'multinomial' + L1)<br><br>.. deprecated:: 1.8<br>   `penalty` was deprecated in version 1.8 and will be removed in 1.10.<br>   Use `l1_ratio` instead. `l1_ratio=0` for `penalty='l2'`, `l1_ratio=1` for<br>   `penalty='l1'` and `l1_ratio` set to any float between 0 and 1 for<br>   `'penalty='elasticnet'`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=C,-float%2C%20default%3D1.0\">\n",
       "            C\n",
       "            <span class=\"param-doc-description\">C: float, default=1.0<br><br>Inverse of regularization strength; must be a positive float.<br>Like in support vector machines, smaller values specify stronger<br>regularization. `C=np.inf` results in unpenalized logistic regression.<br>For a visual example on the effect of tuning the `C` parameter<br>with an L1 penalty, see:<br>:ref:`sphx_glr_auto_examples_linear_model_plot_logistic_path.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=l1_ratio,-float%2C%20default%3D0.0\">\n",
       "            l1_ratio\n",
       "            <span class=\"param-doc-description\">l1_ratio: float, default=0.0<br><br>The Elastic-Net mixing parameter, with `0 <= l1_ratio <= 1`. Setting<br>`l1_ratio=1` gives a pure L1-penalty, setting `l1_ratio=0` a pure L2-penalty.<br>Any value between 0 and 1 gives an Elastic-Net penalty of the form<br>`l1_ratio * L1 + (1 - l1_ratio) * L2`.<br><br>.. warning::<br>   Certain values of `l1_ratio`, i.e. some penalties, may not work with some<br>   solvers. See the parameter `solver` below, to know the compatibility between<br>   the penalty and solver.<br><br>.. versionchanged:: 1.8<br>    Default value changed from None to 0.0.<br><br>.. deprecated:: 1.8<br>    `None` is deprecated and will be removed in version 1.10. Always use<br>    `l1_ratio` to specify the penalty type.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=dual,-bool%2C%20default%3DFalse\">\n",
       "            dual\n",
       "            <span class=\"param-doc-description\">dual: bool, default=False<br><br>Dual (constrained) or primal (regularized, see also<br>:ref:`this equation <regularized-logistic-loss>`) formulation. Dual formulation<br>is only implemented for l2 penalty with liblinear solver. Prefer `dual=False`<br>when n_samples > n_features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=tol,-float%2C%20default%3D1e-4\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-4<br><br>Tolerance for stopping criteria.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Specifies if a constant (a.k.a. bias or intercept) should be<br>added to the decision function.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=intercept_scaling,-float%2C%20default%3D1\">\n",
       "            intercept_scaling\n",
       "            <span class=\"param-doc-description\">intercept_scaling: float, default=1<br><br>Useful only when the solver `liblinear` is used<br>and `self.fit_intercept` is set to `True`. In this case, `x` becomes<br>`[x, self.intercept_scaling]`,<br>i.e. a \"synthetic\" feature with constant value equal to<br>`intercept_scaling` is appended to the instance vector.<br>The intercept becomes<br>``intercept_scaling * synthetic_feature_weight``.<br><br>.. note::<br>    The synthetic feature weight is subject to L1 or L2<br>    regularization as all other features.<br>    To lessen the effect of regularization on synthetic feature weight<br>    (and therefore on the intercept) `intercept_scaling` has to be increased.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=class_weight,-dict%20or%20%27balanced%27%2C%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: dict or 'balanced', default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If not given, all classes are supposed to have weight one.<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.<br><br>.. versionadded:: 0.17<br>   *class_weight='balanced'*</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=random_state,-int%2C%20RandomState%20instance%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance, default=None<br><br>Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the<br>data. See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=solver,-%7B%27lbfgs%27%2C%20%27liblinear%27%2C%20%27newton-cg%27%2C%20%27newton-cholesky%27%2C%20%27sag%27%2C%20%27saga%27%7D%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3D%27lbfgs%27\">\n",
       "            solver\n",
       "            <span class=\"param-doc-description\">solver: {'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'},             default='lbfgs'<br><br>Algorithm to use in the optimization problem. Default is 'lbfgs'.<br>To choose a solver, you might want to consider the following aspects:<br><br>- 'lbfgs' is a good default solver because it works reasonably well for a wide<br>  class of problems.<br>- For :term:`multiclass` problems (`n_classes >= 3`), all solvers except<br>  'liblinear' minimize the full multinomial loss, 'liblinear' will raise an<br>  error.<br>- 'newton-cholesky' is a good choice for<br>  `n_samples` >> `n_features * n_classes`, especially with one-hot encoded<br>  categorical features with rare categories. Be aware that the memory usage<br>  of this solver has a quadratic dependency on `n_features * n_classes`<br>  because it explicitly computes the full Hessian matrix.<br>- For small datasets, 'liblinear' is a good choice, whereas 'sag'<br>  and 'saga' are faster for large ones;<br>- 'liblinear' can only handle binary classification by default. To apply a<br>  one-versus-rest scheme for the multiclass setting one can wrap it with the<br>  :class:`~sklearn.multiclass.OneVsRestClassifier`.<br><br>.. warning::<br>   The choice of the algorithm depends on the penalty chosen (`l1_ratio=0`<br>   for L2-penalty, `l1_ratio=1` for L1-penalty and `0 < l1_ratio < 1` for<br>   Elastic-Net) and on (multinomial) multiclass support:<br><br>   ================= ======================== ======================<br>   solver            l1_ratio                 multinomial multiclass<br>   ================= ======================== ======================<br>   'lbfgs'           l1_ratio=0               yes<br>   'liblinear'       l1_ratio=1 or l1_ratio=0 no<br>   'newton-cg'       l1_ratio=0               yes<br>   'newton-cholesky' l1_ratio=0               yes<br>   'sag'             l1_ratio=0               yes<br>   'saga'            0<=l1_ratio<=1           yes<br>   ================= ======================== ======================<br><br>.. note::<br>   'sag' and 'saga' fast convergence is only guaranteed on features<br>   with approximately the same scale. You can preprocess the data with<br>   a scaler from :mod:`sklearn.preprocessing`.<br><br>.. seealso::<br>   Refer to the :ref:`User Guide <Logistic_regression>` for more<br>   information regarding :class:`LogisticRegression` and more specifically the<br>   :ref:`Table <logistic_regression_solvers>`<br>   summarizing solver/penalty supports.<br><br>.. versionadded:: 0.17<br>   Stochastic Average Gradient (SAG) descent solver. Multinomial support in<br>   version 0.18.<br>.. versionadded:: 0.19<br>   SAGA solver.<br>.. versionchanged:: 0.22<br>   The default solver changed from 'liblinear' to 'lbfgs' in 0.22.<br>.. versionadded:: 1.2<br>   newton-cholesky solver. Multinomial support in version 1.6.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=max_iter,-int%2C%20default%3D100\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=100<br><br>Maximum number of iterations taken for the solvers to converge.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>For the liblinear and lbfgs solvers set verbose to any positive<br>number for verbosity.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to True, reuse the solution of the previous call to fit as<br>initialization, otherwise, just erase the previous solution.<br>Useless for liblinear solver. See :term:`the Glossary <warm_start>`.<br><br>.. versionadded:: 0.17<br>   *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Does not have any effect.<br><br>.. deprecated:: 1.8<br>   `n_jobs` is deprecated in version 1.8 and will be removed in 1.10.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-16');</script></body>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr.fit(X[:,:2],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "d37bb854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the models that can be used to classify the species.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "607277a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model selection for ensemble learning - Voting is upto us . \n",
    "# We can either use multiple different models or a same models with different paramaters tuned with it .\n",
    "lor1 = LogisticRegression(max_iter = 1000)\n",
    "clf1 = DecisionTreeClassifier(\n",
    "    criterion = 'gini'\n",
    ")\n",
    "clf2 = DecisionTreeClassifier(\n",
    "    criterion = 'gini',\n",
    "    max_depth = 5 ,\n",
    "    splitter = 'random'\n",
    ")\n",
    "gnb1 = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "69f416ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make a estimator list consiting of all the tuples which has the name of that model so that VotingClassifier \n",
    "# can uniquely identify it and this is followe by the object of that model instantiated earlier . \n",
    "'''\n",
    "            syntax : estimators(just a variable name) = \n",
    "            [\n",
    "                ('modelname1' , model1),\n",
    "                ('modelname2' , mode2), . . . \n",
    "                ('modelnameN' , modelN),\n",
    "]\n",
    "'''\n",
    "estimators = [\n",
    "    ('LogisticRegressor1' , lor1) , \n",
    "    ('DecisionTreeClassifier' , clf1) , \n",
    "    ('DecisionTreeClassifierUsingRandom' , clf2) ,\n",
    "    ('GaussianNaiveBayes' , gnb1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "af8476b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Voting Ensemble Classifier from the ensemble module\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "744b4e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "voteHard = VotingClassifier(\n",
    "    estimators = estimators ,  # Pass the variables in which we made the list of the modelnames and models (estimators)\n",
    "    voting = 'hard' # We are using hard voting which means only the predicted label is passed as the output for the ensembler and \n",
    "    # not the probability of all the other classes which were not predicted . \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "9968cbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-17.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-17.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-17 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-17 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-17 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-17 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-17 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-17 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-17 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-17 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-17 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;LogisticRegressor1&#x27;,\n",
       "                              LogisticRegression(max_iter=1000)),\n",
       "                             (&#x27;DecisionTreeClassifier&#x27;,\n",
       "                              DecisionTreeClassifier()),\n",
       "                             (&#x27;DecisionTreeClassifierUsingRandom&#x27;,\n",
       "                              DecisionTreeClassifier(max_depth=5,\n",
       "                                                     splitter=&#x27;random&#x27;)),\n",
       "                             (&#x27;GaussianNaiveBayes&#x27;, GaussianNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-73\" type=\"checkbox\" ><label for=\"sk-estimator-id-73\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>VotingClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html\">?<span>Documentation for VotingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html#:~:text=estimators,-list%20of%20%28str%2C%20estimator%29%20tuples\">\n",
       "            estimators\n",
       "            <span class=\"param-doc-description\">estimators: list of (str, estimator) tuples<br><br>Invoking the ``fit`` method on the ``VotingClassifier`` will fit clones<br>of those original estimators that will be stored in the class attribute<br>``self.estimators_``. An estimator can be set to ``'drop'`` using<br>:meth:`set_params`.<br><br>.. versionchanged:: 0.21<br>    ``'drop'`` is accepted. Using None was deprecated in 0.22 and<br>    support was removed in 0.24.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">[(&#x27;LogisticRegressor1&#x27;, ...), (&#x27;DecisionTreeClassifier&#x27;, ...), ...]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('voting',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html#:~:text=voting,-%7B%27hard%27%2C%20%27soft%27%7D%2C%20default%3D%27hard%27\">\n",
       "            voting\n",
       "            <span class=\"param-doc-description\">voting: {'hard', 'soft'}, default='hard'<br><br>If 'hard', uses predicted class labels for majority rule voting.<br>Else if 'soft', predicts the class label based on the argmax of<br>the sums of the predicted probabilities, which is recommended for<br>an ensemble of well-calibrated classifiers.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;hard&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html#:~:text=weights,-array-like%20of%20shape%20%28n_classifiers%2C%29%2C%20default%3DNone\">\n",
       "            weights\n",
       "            <span class=\"param-doc-description\">weights: array-like of shape (n_classifiers,), default=None<br><br>Sequence of weights (`float` or `int`) to weight the occurrences of<br>predicted class labels (`hard` voting) or class probabilities<br>before averaging (`soft` voting). Uses uniform weights if `None`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of jobs to run in parallel for ``fit``.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.<br><br>.. versionadded:: 0.18</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('flatten_transform',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html#:~:text=flatten_transform,-bool%2C%20default%3DTrue\">\n",
       "            flatten_transform\n",
       "            <span class=\"param-doc-description\">flatten_transform: bool, default=True<br><br>Affects shape of transform output only when voting='soft'<br>If voting='soft' and flatten_transform=True, transform method returns<br>matrix with shape (n_samples, n_classifiers * n_classes). If<br>flatten_transform=False, it returns<br>(n_classifiers, n_samples, n_classes).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html#:~:text=verbose,-bool%2C%20default%3DFalse\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: bool, default=False<br><br>If True, the time elapsed while fitting will be printed as it<br>is completed.<br><br>.. versionadded:: 0.23</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>LogisticRegressor1</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-74\" type=\"checkbox\" ><label for=\"sk-estimator-id-74\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"LogisticRegressor1__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=penalty,-%7B%27l1%27%2C%20%27l2%27%2C%20%27elasticnet%27%2C%20None%7D%2C%20default%3D%27l2%27\">\n",
       "            penalty\n",
       "            <span class=\"param-doc-description\">penalty: {'l1', 'l2', 'elasticnet', None}, default='l2'<br><br>Specify the norm of the penalty:<br><br>- `None`: no penalty is added;<br>- `'l2'`: add a L2 penalty term and it is the default choice;<br>- `'l1'`: add a L1 penalty term;<br>- `'elasticnet'`: both L1 and L2 penalty terms are added.<br><br>.. warning::<br>   Some penalties may not work with some solvers. See the parameter<br>   `solver` below, to know the compatibility between the penalty and<br>   solver.<br><br>.. versionadded:: 0.19<br>   l1 penalty with SAGA solver (allowing 'multinomial' + L1)<br><br>.. deprecated:: 1.8<br>   `penalty` was deprecated in version 1.8 and will be removed in 1.10.<br>   Use `l1_ratio` instead. `l1_ratio=0` for `penalty='l2'`, `l1_ratio=1` for<br>   `penalty='l1'` and `l1_ratio` set to any float between 0 and 1 for<br>   `'penalty='elasticnet'`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=C,-float%2C%20default%3D1.0\">\n",
       "            C\n",
       "            <span class=\"param-doc-description\">C: float, default=1.0<br><br>Inverse of regularization strength; must be a positive float.<br>Like in support vector machines, smaller values specify stronger<br>regularization. `C=np.inf` results in unpenalized logistic regression.<br>For a visual example on the effect of tuning the `C` parameter<br>with an L1 penalty, see:<br>:ref:`sphx_glr_auto_examples_linear_model_plot_logistic_path.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=l1_ratio,-float%2C%20default%3D0.0\">\n",
       "            l1_ratio\n",
       "            <span class=\"param-doc-description\">l1_ratio: float, default=0.0<br><br>The Elastic-Net mixing parameter, with `0 <= l1_ratio <= 1`. Setting<br>`l1_ratio=1` gives a pure L1-penalty, setting `l1_ratio=0` a pure L2-penalty.<br>Any value between 0 and 1 gives an Elastic-Net penalty of the form<br>`l1_ratio * L1 + (1 - l1_ratio) * L2`.<br><br>.. warning::<br>   Certain values of `l1_ratio`, i.e. some penalties, may not work with some<br>   solvers. See the parameter `solver` below, to know the compatibility between<br>   the penalty and solver.<br><br>.. versionchanged:: 1.8<br>    Default value changed from None to 0.0.<br><br>.. deprecated:: 1.8<br>    `None` is deprecated and will be removed in version 1.10. Always use<br>    `l1_ratio` to specify the penalty type.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=dual,-bool%2C%20default%3DFalse\">\n",
       "            dual\n",
       "            <span class=\"param-doc-description\">dual: bool, default=False<br><br>Dual (constrained) or primal (regularized, see also<br>:ref:`this equation <regularized-logistic-loss>`) formulation. Dual formulation<br>is only implemented for l2 penalty with liblinear solver. Prefer `dual=False`<br>when n_samples > n_features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=tol,-float%2C%20default%3D1e-4\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-4<br><br>Tolerance for stopping criteria.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Specifies if a constant (a.k.a. bias or intercept) should be<br>added to the decision function.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=intercept_scaling,-float%2C%20default%3D1\">\n",
       "            intercept_scaling\n",
       "            <span class=\"param-doc-description\">intercept_scaling: float, default=1<br><br>Useful only when the solver `liblinear` is used<br>and `self.fit_intercept` is set to `True`. In this case, `x` becomes<br>`[x, self.intercept_scaling]`,<br>i.e. a \"synthetic\" feature with constant value equal to<br>`intercept_scaling` is appended to the instance vector.<br>The intercept becomes<br>``intercept_scaling * synthetic_feature_weight``.<br><br>.. note::<br>    The synthetic feature weight is subject to L1 or L2<br>    regularization as all other features.<br>    To lessen the effect of regularization on synthetic feature weight<br>    (and therefore on the intercept) `intercept_scaling` has to be increased.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=class_weight,-dict%20or%20%27balanced%27%2C%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: dict or 'balanced', default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If not given, all classes are supposed to have weight one.<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.<br><br>.. versionadded:: 0.17<br>   *class_weight='balanced'*</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=random_state,-int%2C%20RandomState%20instance%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance, default=None<br><br>Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the<br>data. See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=solver,-%7B%27lbfgs%27%2C%20%27liblinear%27%2C%20%27newton-cg%27%2C%20%27newton-cholesky%27%2C%20%27sag%27%2C%20%27saga%27%7D%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3D%27lbfgs%27\">\n",
       "            solver\n",
       "            <span class=\"param-doc-description\">solver: {'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'},             default='lbfgs'<br><br>Algorithm to use in the optimization problem. Default is 'lbfgs'.<br>To choose a solver, you might want to consider the following aspects:<br><br>- 'lbfgs' is a good default solver because it works reasonably well for a wide<br>  class of problems.<br>- For :term:`multiclass` problems (`n_classes >= 3`), all solvers except<br>  'liblinear' minimize the full multinomial loss, 'liblinear' will raise an<br>  error.<br>- 'newton-cholesky' is a good choice for<br>  `n_samples` >> `n_features * n_classes`, especially with one-hot encoded<br>  categorical features with rare categories. Be aware that the memory usage<br>  of this solver has a quadratic dependency on `n_features * n_classes`<br>  because it explicitly computes the full Hessian matrix.<br>- For small datasets, 'liblinear' is a good choice, whereas 'sag'<br>  and 'saga' are faster for large ones;<br>- 'liblinear' can only handle binary classification by default. To apply a<br>  one-versus-rest scheme for the multiclass setting one can wrap it with the<br>  :class:`~sklearn.multiclass.OneVsRestClassifier`.<br><br>.. warning::<br>   The choice of the algorithm depends on the penalty chosen (`l1_ratio=0`<br>   for L2-penalty, `l1_ratio=1` for L1-penalty and `0 < l1_ratio < 1` for<br>   Elastic-Net) and on (multinomial) multiclass support:<br><br>   ================= ======================== ======================<br>   solver            l1_ratio                 multinomial multiclass<br>   ================= ======================== ======================<br>   'lbfgs'           l1_ratio=0               yes<br>   'liblinear'       l1_ratio=1 or l1_ratio=0 no<br>   'newton-cg'       l1_ratio=0               yes<br>   'newton-cholesky' l1_ratio=0               yes<br>   'sag'             l1_ratio=0               yes<br>   'saga'            0<=l1_ratio<=1           yes<br>   ================= ======================== ======================<br><br>.. note::<br>   'sag' and 'saga' fast convergence is only guaranteed on features<br>   with approximately the same scale. You can preprocess the data with<br>   a scaler from :mod:`sklearn.preprocessing`.<br><br>.. seealso::<br>   Refer to the :ref:`User Guide <Logistic_regression>` for more<br>   information regarding :class:`LogisticRegression` and more specifically the<br>   :ref:`Table <logistic_regression_solvers>`<br>   summarizing solver/penalty supports.<br><br>.. versionadded:: 0.17<br>   Stochastic Average Gradient (SAG) descent solver. Multinomial support in<br>   version 0.18.<br>.. versionadded:: 0.19<br>   SAGA solver.<br>.. versionchanged:: 0.22<br>   The default solver changed from 'liblinear' to 'lbfgs' in 0.22.<br>.. versionadded:: 1.2<br>   newton-cholesky solver. Multinomial support in version 1.6.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=max_iter,-int%2C%20default%3D100\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=100<br><br>Maximum number of iterations taken for the solvers to converge.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>For the liblinear and lbfgs solvers set verbose to any positive<br>number for verbosity.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to True, reuse the solution of the previous call to fit as<br>initialization, otherwise, just erase the previous solution.<br>Useless for liblinear solver. See :term:`the Glossary <warm_start>`.<br><br>.. versionadded:: 0.17<br>   *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Does not have any effect.<br><br>.. deprecated:: 1.8<br>   `n_jobs` is deprecated in version 1.8 and will be removed in 1.10.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>DecisionTreeClassifier</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-75\" type=\"checkbox\" ><label for=\"sk-estimator-id-75\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"DecisionTreeClassifier__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=criterion,-%7B%22gini%22%2C%20%22entropy%22%2C%20%22log_loss%22%7D%2C%20default%3D%22gini%22\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"<br><br>The function to measure the quality of a split. Supported criteria are<br>\"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the<br>Shannon information gain, see :ref:`tree_mathematical_formulation`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('splitter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=splitter,-%7B%22best%22%2C%20%22random%22%7D%2C%20default%3D%22best%22\">\n",
       "            splitter\n",
       "            <span class=\"param-doc-description\">splitter: {\"best\", \"random\"}, default=\"best\"<br><br>The strategy used to choose the split at each node. Supported<br>strategies are \"best\" to choose the best split and \"random\" to choose<br>the best random split.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;best&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_depth,-int%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int, default=None<br><br>The maximum depth of the tree. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, then consider `min_samples_split` as the minimum number.<br>- If float, then `min_samples_split` is a fraction and<br>  `ceil(min_samples_split * n_samples)` are the minimum<br>  number of samples for each split.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, then consider `min_samples_leaf` as the minimum number.<br>- If float, then `min_samples_leaf` is a fraction and<br>  `ceil(min_samples_leaf * n_samples)` are the minimum<br>  number of samples for each node.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_features,-int%2C%20float%20or%20%7B%22sqrt%22%2C%20%22log2%22%7D%2C%20default%3DNone\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: int, float or {\"sqrt\", \"log2\"}, default=None<br><br>The number of features to consider when looking for the best split:<br><br>- If int, then consider `max_features` features at each split.<br>- If float, then `max_features` is a fraction and<br>  `max(1, int(max_features * n_features_in_))` features are considered at<br>  each split.<br>- If \"sqrt\", then `max_features=sqrt(n_features)`.<br>- If \"log2\", then `max_features=log2(n_features)`.<br>- If None, then `max_features=n_features`.<br><br>.. note::<br><br>    The search for a split does not stop until at least one<br>    valid partition of the node samples is found, even if it requires to<br>    effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls the randomness of the estimator. The features are always<br>randomly permuted at each split, even if ``splitter`` is set to<br>``\"best\"``. When ``max_features < n_features``, the algorithm will<br>select ``max_features`` at random at each split before finding the best<br>split among them. But the best found split may vary across different<br>runs, even if ``max_features=n_features``. That is the case, if the<br>improvement of the criterion is identical for several splits and one<br>split has to be selected at random. To obtain a deterministic behaviour<br>during fitting, ``random_state`` has to be fixed to an integer.<br>See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow a tree with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>If None then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=class_weight,-dict%2C%20list%20of%20dict%20or%20%22balanced%22%2C%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: dict, list of dict or \"balanced\", default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If None, all classes are supposed to have weight one. For<br>multi-output problems, a list of dicts can be provided in the same<br>order as the columns of y.<br><br>Note that for multioutput (including multilabel) weights should be<br>defined for each class of every column in its own dict. For example,<br>for four-class multilabel classification weights should be<br>[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of<br>[{1:1}, {2:5}, {3:1}, {4:1}].<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``<br><br>For multi-output, the weights of each column of y will be multiplied.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>:ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features), default=None<br><br>Indicates the monotonicity constraint to enforce on each feature.<br>  - 1: monotonic increase<br>  - 0: no constraint<br>  - -1: monotonic decrease<br><br>If monotonic_cst is None, no constraints are applied.<br><br>Monotonicity constraints are not supported for:<br>  - multiclass classifications (i.e. when `n_classes > 2`),<br>  - multioutput classifications (i.e. when `n_outputs_ > 1`),<br>  - classifications trained on data with missing values.<br><br>The constraints hold over the probability of the positive class.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>DecisionTreeClassifierUsingRandom</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-76\" type=\"checkbox\" ><label for=\"sk-estimator-id-76\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"DecisionTreeClassifierUsingRandom__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=criterion,-%7B%22gini%22%2C%20%22entropy%22%2C%20%22log_loss%22%7D%2C%20default%3D%22gini%22\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"<br><br>The function to measure the quality of a split. Supported criteria are<br>\"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the<br>Shannon information gain, see :ref:`tree_mathematical_formulation`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('splitter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=splitter,-%7B%22best%22%2C%20%22random%22%7D%2C%20default%3D%22best%22\">\n",
       "            splitter\n",
       "            <span class=\"param-doc-description\">splitter: {\"best\", \"random\"}, default=\"best\"<br><br>The strategy used to choose the split at each node. Supported<br>strategies are \"best\" to choose the best split and \"random\" to choose<br>the best random split.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;random&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_depth,-int%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int, default=None<br><br>The maximum depth of the tree. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, then consider `min_samples_split` as the minimum number.<br>- If float, then `min_samples_split` is a fraction and<br>  `ceil(min_samples_split * n_samples)` are the minimum<br>  number of samples for each split.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, then consider `min_samples_leaf` as the minimum number.<br>- If float, then `min_samples_leaf` is a fraction and<br>  `ceil(min_samples_leaf * n_samples)` are the minimum<br>  number of samples for each node.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_features,-int%2C%20float%20or%20%7B%22sqrt%22%2C%20%22log2%22%7D%2C%20default%3DNone\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: int, float or {\"sqrt\", \"log2\"}, default=None<br><br>The number of features to consider when looking for the best split:<br><br>- If int, then consider `max_features` features at each split.<br>- If float, then `max_features` is a fraction and<br>  `max(1, int(max_features * n_features_in_))` features are considered at<br>  each split.<br>- If \"sqrt\", then `max_features=sqrt(n_features)`.<br>- If \"log2\", then `max_features=log2(n_features)`.<br>- If None, then `max_features=n_features`.<br><br>.. note::<br><br>    The search for a split does not stop until at least one<br>    valid partition of the node samples is found, even if it requires to<br>    effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls the randomness of the estimator. The features are always<br>randomly permuted at each split, even if ``splitter`` is set to<br>``\"best\"``. When ``max_features < n_features``, the algorithm will<br>select ``max_features`` at random at each split before finding the best<br>split among them. But the best found split may vary across different<br>runs, even if ``max_features=n_features``. That is the case, if the<br>improvement of the criterion is identical for several splits and one<br>split has to be selected at random. To obtain a deterministic behaviour<br>during fitting, ``random_state`` has to be fixed to an integer.<br>See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow a tree with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>If None then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=class_weight,-dict%2C%20list%20of%20dict%20or%20%22balanced%22%2C%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: dict, list of dict or \"balanced\", default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If None, all classes are supposed to have weight one. For<br>multi-output problems, a list of dicts can be provided in the same<br>order as the columns of y.<br><br>Note that for multioutput (including multilabel) weights should be<br>defined for each class of every column in its own dict. For example,<br>for four-class multilabel classification weights should be<br>[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of<br>[{1:1}, {2:5}, {3:1}, {4:1}].<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``<br><br>For multi-output, the weights of each column of y will be multiplied.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>:ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features), default=None<br><br>Indicates the monotonicity constraint to enforce on each feature.<br>  - 1: monotonic increase<br>  - 0: no constraint<br>  - -1: monotonic decrease<br><br>If monotonic_cst is None, no constraints are applied.<br><br>Monotonicity constraints are not supported for:<br>  - multiclass classifications (i.e. when `n_classes > 2`),<br>  - multioutput classifications (i.e. when `n_outputs_ > 1`),<br>  - classifications trained on data with missing values.<br><br>The constraints hold over the probability of the positive class.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>GaussianNaiveBayes</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-77\" type=\"checkbox\" ><label for=\"sk-estimator-id-77\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GaussianNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.naive_bayes.GaussianNB.html\">?<span>Documentation for GaussianNB</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"GaussianNaiveBayes__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('priors',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.naive_bayes.GaussianNB.html#:~:text=priors,-array-like%20of%20shape%20%28n_classes%2C%29%2C%20default%3DNone\">\n",
       "            priors\n",
       "            <span class=\"param-doc-description\">priors: array-like of shape (n_classes,), default=None<br><br>Prior probabilities of the classes. If specified, the priors are not<br>adjusted according to the data.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('var_smoothing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.naive_bayes.GaussianNB.html#:~:text=var_smoothing,-float%2C%20default%3D1e-9\">\n",
       "            var_smoothing\n",
       "            <span class=\"param-doc-description\">var_smoothing: float, default=1e-9<br><br>Portion of the largest variance of all features that is added to<br>variances for calculation stability.<br><br>.. versionadded:: 0.20</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1e-09</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-17');</script></body>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('LogisticRegressor1',\n",
       "                              LogisticRegression(max_iter=1000)),\n",
       "                             ('DecisionTreeClassifier',\n",
       "                              DecisionTreeClassifier()),\n",
       "                             ('DecisionTreeClassifierUsingRandom',\n",
       "                              DecisionTreeClassifier(max_depth=5,\n",
       "                                                     splitter='random')),\n",
       "                             ('GaussianNaiveBayes', GaussianNB())])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voteHard.fit(X,y) # Fit the X and y values \n",
    "# To be honest this should be X_train and Y_train but for simplicity we are gonna pass X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "49d2feaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = voteHard.predict(X) # Predict species based on X features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "f48eef9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.93333333, 1.        , 0.93333333, 0.93333333,\n",
       "       0.86666667, 0.93333333, 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(voteHard,X,y,cv=10,scoring='accuracy') # Calculate the cross val score to evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "b531728b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9533333333333334)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(voteHard,X,y,cv=10,scoring='accuracy').mean() # Calculate the mean of  cross val score to evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "13d334e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.98      1.00      0.99        50\n",
      "           2       1.00      0.98      0.99        50\n",
      "\n",
      "    accuracy                           0.99       150\n",
      "   macro avg       0.99      0.99      0.99       150\n",
      "weighted avg       0.99      0.99      0.99       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y,pred1)) # Examine the different classfication metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "42e48f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf1 = pd.DataFrame(confusion_matrix(y,pred1)) # Convert to dataframe for better visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "8640d62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "2",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "9f0fa176-4954-438f-a4ab-02f49ed04464",
       "rows": [
        [
         "0",
         "50",
         "0",
         "0"
        ],
        [
         "1",
         "0",
         "50",
         "0"
        ],
        [
         "2",
         "0",
         "1",
         "49"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2\n",
       "0  50   0   0\n",
       "1   0  50   0\n",
       "2   0   1  49"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "fd32e631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the confusion matrix using heatmap\n",
    "sns.heatmap(\n",
    "    data = conf1,\n",
    "    cmap = 'Reds',\n",
    "    annot = True # For values to be displayed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "1040e239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets do the same process but with soft Voting Ensemble\n",
    "voteSoft = VotingClassifier(\n",
    "    estimators = estimators ,  # Pass the variables in which we made the list of the modelnames and models (estimators)\n",
    "    voting = 'soft'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "f4e2d1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-18.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-18.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-18 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-18 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-18 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-18 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-18 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-18 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-18 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-18 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-18 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;LogisticRegressor1&#x27;,\n",
       "                              LogisticRegression(max_iter=1000)),\n",
       "                             (&#x27;DecisionTreeClassifier&#x27;,\n",
       "                              DecisionTreeClassifier()),\n",
       "                             (&#x27;DecisionTreeClassifierUsingRandom&#x27;,\n",
       "                              DecisionTreeClassifier(max_depth=5,\n",
       "                                                     splitter=&#x27;random&#x27;)),\n",
       "                             (&#x27;GaussianNaiveBayes&#x27;, GaussianNB())],\n",
       "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-78\" type=\"checkbox\" ><label for=\"sk-estimator-id-78\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>VotingClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html\">?<span>Documentation for VotingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html#:~:text=estimators,-list%20of%20%28str%2C%20estimator%29%20tuples\">\n",
       "            estimators\n",
       "            <span class=\"param-doc-description\">estimators: list of (str, estimator) tuples<br><br>Invoking the ``fit`` method on the ``VotingClassifier`` will fit clones<br>of those original estimators that will be stored in the class attribute<br>``self.estimators_``. An estimator can be set to ``'drop'`` using<br>:meth:`set_params`.<br><br>.. versionchanged:: 0.21<br>    ``'drop'`` is accepted. Using None was deprecated in 0.22 and<br>    support was removed in 0.24.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">[(&#x27;LogisticRegressor1&#x27;, ...), (&#x27;DecisionTreeClassifier&#x27;, ...), ...]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('voting',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html#:~:text=voting,-%7B%27hard%27%2C%20%27soft%27%7D%2C%20default%3D%27hard%27\">\n",
       "            voting\n",
       "            <span class=\"param-doc-description\">voting: {'hard', 'soft'}, default='hard'<br><br>If 'hard', uses predicted class labels for majority rule voting.<br>Else if 'soft', predicts the class label based on the argmax of<br>the sums of the predicted probabilities, which is recommended for<br>an ensemble of well-calibrated classifiers.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;soft&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html#:~:text=weights,-array-like%20of%20shape%20%28n_classifiers%2C%29%2C%20default%3DNone\">\n",
       "            weights\n",
       "            <span class=\"param-doc-description\">weights: array-like of shape (n_classifiers,), default=None<br><br>Sequence of weights (`float` or `int`) to weight the occurrences of<br>predicted class labels (`hard` voting) or class probabilities<br>before averaging (`soft` voting). Uses uniform weights if `None`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of jobs to run in parallel for ``fit``.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.<br><br>.. versionadded:: 0.18</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('flatten_transform',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html#:~:text=flatten_transform,-bool%2C%20default%3DTrue\">\n",
       "            flatten_transform\n",
       "            <span class=\"param-doc-description\">flatten_transform: bool, default=True<br><br>Affects shape of transform output only when voting='soft'<br>If voting='soft' and flatten_transform=True, transform method returns<br>matrix with shape (n_samples, n_classifiers * n_classes). If<br>flatten_transform=False, it returns<br>(n_classifiers, n_samples, n_classes).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.VotingClassifier.html#:~:text=verbose,-bool%2C%20default%3DFalse\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: bool, default=False<br><br>If True, the time elapsed while fitting will be printed as it<br>is completed.<br><br>.. versionadded:: 0.23</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>LogisticRegressor1</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-79\" type=\"checkbox\" ><label for=\"sk-estimator-id-79\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"LogisticRegressor1__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=penalty,-%7B%27l1%27%2C%20%27l2%27%2C%20%27elasticnet%27%2C%20None%7D%2C%20default%3D%27l2%27\">\n",
       "            penalty\n",
       "            <span class=\"param-doc-description\">penalty: {'l1', 'l2', 'elasticnet', None}, default='l2'<br><br>Specify the norm of the penalty:<br><br>- `None`: no penalty is added;<br>- `'l2'`: add a L2 penalty term and it is the default choice;<br>- `'l1'`: add a L1 penalty term;<br>- `'elasticnet'`: both L1 and L2 penalty terms are added.<br><br>.. warning::<br>   Some penalties may not work with some solvers. See the parameter<br>   `solver` below, to know the compatibility between the penalty and<br>   solver.<br><br>.. versionadded:: 0.19<br>   l1 penalty with SAGA solver (allowing 'multinomial' + L1)<br><br>.. deprecated:: 1.8<br>   `penalty` was deprecated in version 1.8 and will be removed in 1.10.<br>   Use `l1_ratio` instead. `l1_ratio=0` for `penalty='l2'`, `l1_ratio=1` for<br>   `penalty='l1'` and `l1_ratio` set to any float between 0 and 1 for<br>   `'penalty='elasticnet'`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=C,-float%2C%20default%3D1.0\">\n",
       "            C\n",
       "            <span class=\"param-doc-description\">C: float, default=1.0<br><br>Inverse of regularization strength; must be a positive float.<br>Like in support vector machines, smaller values specify stronger<br>regularization. `C=np.inf` results in unpenalized logistic regression.<br>For a visual example on the effect of tuning the `C` parameter<br>with an L1 penalty, see:<br>:ref:`sphx_glr_auto_examples_linear_model_plot_logistic_path.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=l1_ratio,-float%2C%20default%3D0.0\">\n",
       "            l1_ratio\n",
       "            <span class=\"param-doc-description\">l1_ratio: float, default=0.0<br><br>The Elastic-Net mixing parameter, with `0 <= l1_ratio <= 1`. Setting<br>`l1_ratio=1` gives a pure L1-penalty, setting `l1_ratio=0` a pure L2-penalty.<br>Any value between 0 and 1 gives an Elastic-Net penalty of the form<br>`l1_ratio * L1 + (1 - l1_ratio) * L2`.<br><br>.. warning::<br>   Certain values of `l1_ratio`, i.e. some penalties, may not work with some<br>   solvers. See the parameter `solver` below, to know the compatibility between<br>   the penalty and solver.<br><br>.. versionchanged:: 1.8<br>    Default value changed from None to 0.0.<br><br>.. deprecated:: 1.8<br>    `None` is deprecated and will be removed in version 1.10. Always use<br>    `l1_ratio` to specify the penalty type.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=dual,-bool%2C%20default%3DFalse\">\n",
       "            dual\n",
       "            <span class=\"param-doc-description\">dual: bool, default=False<br><br>Dual (constrained) or primal (regularized, see also<br>:ref:`this equation <regularized-logistic-loss>`) formulation. Dual formulation<br>is only implemented for l2 penalty with liblinear solver. Prefer `dual=False`<br>when n_samples > n_features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=tol,-float%2C%20default%3D1e-4\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-4<br><br>Tolerance for stopping criteria.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Specifies if a constant (a.k.a. bias or intercept) should be<br>added to the decision function.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=intercept_scaling,-float%2C%20default%3D1\">\n",
       "            intercept_scaling\n",
       "            <span class=\"param-doc-description\">intercept_scaling: float, default=1<br><br>Useful only when the solver `liblinear` is used<br>and `self.fit_intercept` is set to `True`. In this case, `x` becomes<br>`[x, self.intercept_scaling]`,<br>i.e. a \"synthetic\" feature with constant value equal to<br>`intercept_scaling` is appended to the instance vector.<br>The intercept becomes<br>``intercept_scaling * synthetic_feature_weight``.<br><br>.. note::<br>    The synthetic feature weight is subject to L1 or L2<br>    regularization as all other features.<br>    To lessen the effect of regularization on synthetic feature weight<br>    (and therefore on the intercept) `intercept_scaling` has to be increased.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=class_weight,-dict%20or%20%27balanced%27%2C%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: dict or 'balanced', default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If not given, all classes are supposed to have weight one.<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.<br><br>.. versionadded:: 0.17<br>   *class_weight='balanced'*</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=random_state,-int%2C%20RandomState%20instance%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance, default=None<br><br>Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the<br>data. See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=solver,-%7B%27lbfgs%27%2C%20%27liblinear%27%2C%20%27newton-cg%27%2C%20%27newton-cholesky%27%2C%20%27sag%27%2C%20%27saga%27%7D%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3D%27lbfgs%27\">\n",
       "            solver\n",
       "            <span class=\"param-doc-description\">solver: {'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'},             default='lbfgs'<br><br>Algorithm to use in the optimization problem. Default is 'lbfgs'.<br>To choose a solver, you might want to consider the following aspects:<br><br>- 'lbfgs' is a good default solver because it works reasonably well for a wide<br>  class of problems.<br>- For :term:`multiclass` problems (`n_classes >= 3`), all solvers except<br>  'liblinear' minimize the full multinomial loss, 'liblinear' will raise an<br>  error.<br>- 'newton-cholesky' is a good choice for<br>  `n_samples` >> `n_features * n_classes`, especially with one-hot encoded<br>  categorical features with rare categories. Be aware that the memory usage<br>  of this solver has a quadratic dependency on `n_features * n_classes`<br>  because it explicitly computes the full Hessian matrix.<br>- For small datasets, 'liblinear' is a good choice, whereas 'sag'<br>  and 'saga' are faster for large ones;<br>- 'liblinear' can only handle binary classification by default. To apply a<br>  one-versus-rest scheme for the multiclass setting one can wrap it with the<br>  :class:`~sklearn.multiclass.OneVsRestClassifier`.<br><br>.. warning::<br>   The choice of the algorithm depends on the penalty chosen (`l1_ratio=0`<br>   for L2-penalty, `l1_ratio=1` for L1-penalty and `0 < l1_ratio < 1` for<br>   Elastic-Net) and on (multinomial) multiclass support:<br><br>   ================= ======================== ======================<br>   solver            l1_ratio                 multinomial multiclass<br>   ================= ======================== ======================<br>   'lbfgs'           l1_ratio=0               yes<br>   'liblinear'       l1_ratio=1 or l1_ratio=0 no<br>   'newton-cg'       l1_ratio=0               yes<br>   'newton-cholesky' l1_ratio=0               yes<br>   'sag'             l1_ratio=0               yes<br>   'saga'            0<=l1_ratio<=1           yes<br>   ================= ======================== ======================<br><br>.. note::<br>   'sag' and 'saga' fast convergence is only guaranteed on features<br>   with approximately the same scale. You can preprocess the data with<br>   a scaler from :mod:`sklearn.preprocessing`.<br><br>.. seealso::<br>   Refer to the :ref:`User Guide <Logistic_regression>` for more<br>   information regarding :class:`LogisticRegression` and more specifically the<br>   :ref:`Table <logistic_regression_solvers>`<br>   summarizing solver/penalty supports.<br><br>.. versionadded:: 0.17<br>   Stochastic Average Gradient (SAG) descent solver. Multinomial support in<br>   version 0.18.<br>.. versionadded:: 0.19<br>   SAGA solver.<br>.. versionchanged:: 0.22<br>   The default solver changed from 'liblinear' to 'lbfgs' in 0.22.<br>.. versionadded:: 1.2<br>   newton-cholesky solver. Multinomial support in version 1.6.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=max_iter,-int%2C%20default%3D100\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=100<br><br>Maximum number of iterations taken for the solvers to converge.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>For the liblinear and lbfgs solvers set verbose to any positive<br>number for verbosity.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to True, reuse the solution of the previous call to fit as<br>initialization, otherwise, just erase the previous solution.<br>Useless for liblinear solver. See :term:`the Glossary <warm_start>`.<br><br>.. versionadded:: 0.17<br>   *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Does not have any effect.<br><br>.. deprecated:: 1.8<br>   `n_jobs` is deprecated in version 1.8 and will be removed in 1.10.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>DecisionTreeClassifier</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-80\" type=\"checkbox\" ><label for=\"sk-estimator-id-80\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"DecisionTreeClassifier__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=criterion,-%7B%22gini%22%2C%20%22entropy%22%2C%20%22log_loss%22%7D%2C%20default%3D%22gini%22\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"<br><br>The function to measure the quality of a split. Supported criteria are<br>\"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the<br>Shannon information gain, see :ref:`tree_mathematical_formulation`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('splitter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=splitter,-%7B%22best%22%2C%20%22random%22%7D%2C%20default%3D%22best%22\">\n",
       "            splitter\n",
       "            <span class=\"param-doc-description\">splitter: {\"best\", \"random\"}, default=\"best\"<br><br>The strategy used to choose the split at each node. Supported<br>strategies are \"best\" to choose the best split and \"random\" to choose<br>the best random split.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;best&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_depth,-int%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int, default=None<br><br>The maximum depth of the tree. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, then consider `min_samples_split` as the minimum number.<br>- If float, then `min_samples_split` is a fraction and<br>  `ceil(min_samples_split * n_samples)` are the minimum<br>  number of samples for each split.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, then consider `min_samples_leaf` as the minimum number.<br>- If float, then `min_samples_leaf` is a fraction and<br>  `ceil(min_samples_leaf * n_samples)` are the minimum<br>  number of samples for each node.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_features,-int%2C%20float%20or%20%7B%22sqrt%22%2C%20%22log2%22%7D%2C%20default%3DNone\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: int, float or {\"sqrt\", \"log2\"}, default=None<br><br>The number of features to consider when looking for the best split:<br><br>- If int, then consider `max_features` features at each split.<br>- If float, then `max_features` is a fraction and<br>  `max(1, int(max_features * n_features_in_))` features are considered at<br>  each split.<br>- If \"sqrt\", then `max_features=sqrt(n_features)`.<br>- If \"log2\", then `max_features=log2(n_features)`.<br>- If None, then `max_features=n_features`.<br><br>.. note::<br><br>    The search for a split does not stop until at least one<br>    valid partition of the node samples is found, even if it requires to<br>    effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls the randomness of the estimator. The features are always<br>randomly permuted at each split, even if ``splitter`` is set to<br>``\"best\"``. When ``max_features < n_features``, the algorithm will<br>select ``max_features`` at random at each split before finding the best<br>split among them. But the best found split may vary across different<br>runs, even if ``max_features=n_features``. That is the case, if the<br>improvement of the criterion is identical for several splits and one<br>split has to be selected at random. To obtain a deterministic behaviour<br>during fitting, ``random_state`` has to be fixed to an integer.<br>See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow a tree with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>If None then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=class_weight,-dict%2C%20list%20of%20dict%20or%20%22balanced%22%2C%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: dict, list of dict or \"balanced\", default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If None, all classes are supposed to have weight one. For<br>multi-output problems, a list of dicts can be provided in the same<br>order as the columns of y.<br><br>Note that for multioutput (including multilabel) weights should be<br>defined for each class of every column in its own dict. For example,<br>for four-class multilabel classification weights should be<br>[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of<br>[{1:1}, {2:5}, {3:1}, {4:1}].<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``<br><br>For multi-output, the weights of each column of y will be multiplied.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>:ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features), default=None<br><br>Indicates the monotonicity constraint to enforce on each feature.<br>  - 1: monotonic increase<br>  - 0: no constraint<br>  - -1: monotonic decrease<br><br>If monotonic_cst is None, no constraints are applied.<br><br>Monotonicity constraints are not supported for:<br>  - multiclass classifications (i.e. when `n_classes > 2`),<br>  - multioutput classifications (i.e. when `n_outputs_ > 1`),<br>  - classifications trained on data with missing values.<br><br>The constraints hold over the probability of the positive class.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>DecisionTreeClassifierUsingRandom</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-81\" type=\"checkbox\" ><label for=\"sk-estimator-id-81\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"DecisionTreeClassifierUsingRandom__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=criterion,-%7B%22gini%22%2C%20%22entropy%22%2C%20%22log_loss%22%7D%2C%20default%3D%22gini%22\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"<br><br>The function to measure the quality of a split. Supported criteria are<br>\"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the<br>Shannon information gain, see :ref:`tree_mathematical_formulation`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('splitter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=splitter,-%7B%22best%22%2C%20%22random%22%7D%2C%20default%3D%22best%22\">\n",
       "            splitter\n",
       "            <span class=\"param-doc-description\">splitter: {\"best\", \"random\"}, default=\"best\"<br><br>The strategy used to choose the split at each node. Supported<br>strategies are \"best\" to choose the best split and \"random\" to choose<br>the best random split.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;random&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_depth,-int%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int, default=None<br><br>The maximum depth of the tree. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, then consider `min_samples_split` as the minimum number.<br>- If float, then `min_samples_split` is a fraction and<br>  `ceil(min_samples_split * n_samples)` are the minimum<br>  number of samples for each split.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, then consider `min_samples_leaf` as the minimum number.<br>- If float, then `min_samples_leaf` is a fraction and<br>  `ceil(min_samples_leaf * n_samples)` are the minimum<br>  number of samples for each node.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_features,-int%2C%20float%20or%20%7B%22sqrt%22%2C%20%22log2%22%7D%2C%20default%3DNone\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: int, float or {\"sqrt\", \"log2\"}, default=None<br><br>The number of features to consider when looking for the best split:<br><br>- If int, then consider `max_features` features at each split.<br>- If float, then `max_features` is a fraction and<br>  `max(1, int(max_features * n_features_in_))` features are considered at<br>  each split.<br>- If \"sqrt\", then `max_features=sqrt(n_features)`.<br>- If \"log2\", then `max_features=log2(n_features)`.<br>- If None, then `max_features=n_features`.<br><br>.. note::<br><br>    The search for a split does not stop until at least one<br>    valid partition of the node samples is found, even if it requires to<br>    effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls the randomness of the estimator. The features are always<br>randomly permuted at each split, even if ``splitter`` is set to<br>``\"best\"``. When ``max_features < n_features``, the algorithm will<br>select ``max_features`` at random at each split before finding the best<br>split among them. But the best found split may vary across different<br>runs, even if ``max_features=n_features``. That is the case, if the<br>improvement of the criterion is identical for several splits and one<br>split has to be selected at random. To obtain a deterministic behaviour<br>during fitting, ``random_state`` has to be fixed to an integer.<br>See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow a tree with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>If None then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=class_weight,-dict%2C%20list%20of%20dict%20or%20%22balanced%22%2C%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: dict, list of dict or \"balanced\", default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If None, all classes are supposed to have weight one. For<br>multi-output problems, a list of dicts can be provided in the same<br>order as the columns of y.<br><br>Note that for multioutput (including multilabel) weights should be<br>defined for each class of every column in its own dict. For example,<br>for four-class multilabel classification weights should be<br>[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of<br>[{1:1}, {2:5}, {3:1}, {4:1}].<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``<br><br>For multi-output, the weights of each column of y will be multiplied.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>:ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features), default=None<br><br>Indicates the monotonicity constraint to enforce on each feature.<br>  - 1: monotonic increase<br>  - 0: no constraint<br>  - -1: monotonic decrease<br><br>If monotonic_cst is None, no constraints are applied.<br><br>Monotonicity constraints are not supported for:<br>  - multiclass classifications (i.e. when `n_classes > 2`),<br>  - multioutput classifications (i.e. when `n_outputs_ > 1`),<br>  - classifications trained on data with missing values.<br><br>The constraints hold over the probability of the positive class.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>GaussianNaiveBayes</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-82\" type=\"checkbox\" ><label for=\"sk-estimator-id-82\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GaussianNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.naive_bayes.GaussianNB.html\">?<span>Documentation for GaussianNB</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"GaussianNaiveBayes__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('priors',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.naive_bayes.GaussianNB.html#:~:text=priors,-array-like%20of%20shape%20%28n_classes%2C%29%2C%20default%3DNone\">\n",
       "            priors\n",
       "            <span class=\"param-doc-description\">priors: array-like of shape (n_classes,), default=None<br><br>Prior probabilities of the classes. If specified, the priors are not<br>adjusted according to the data.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('var_smoothing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.naive_bayes.GaussianNB.html#:~:text=var_smoothing,-float%2C%20default%3D1e-9\">\n",
       "            var_smoothing\n",
       "            <span class=\"param-doc-description\">var_smoothing: float, default=1e-9<br><br>Portion of the largest variance of all features that is added to<br>variances for calculation stability.<br><br>.. versionadded:: 0.20</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1e-09</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-18');</script></body>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('LogisticRegressor1',\n",
       "                              LogisticRegression(max_iter=1000)),\n",
       "                             ('DecisionTreeClassifier',\n",
       "                              DecisionTreeClassifier()),\n",
       "                             ('DecisionTreeClassifierUsingRandom',\n",
       "                              DecisionTreeClassifier(max_depth=5,\n",
       "                                                     splitter='random')),\n",
       "                             ('GaussianNaiveBayes', GaussianNB())],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voteSoft.fit(X,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "2fdd0bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = voteSoft.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "7f6d5e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now compare the Hard and Soft evaluation metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "74c22068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.93333333, 1.        , 0.93333333, 0.93333333,\n",
       "       0.93333333, 0.86666667, 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(voteSoft,X,y,cv=10,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "a764625d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.96)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(voteSoft,X,y,cv=10,scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "3ebc2e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.94      0.98      0.96        50\n",
      "           2       0.98      0.94      0.96        50\n",
      "\n",
      "    accuracy                           0.97       150\n",
      "   macro avg       0.97      0.97      0.97       150\n",
      "weighted avg       0.97      0.97      0.97       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y,pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "e61607f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf2 = pd.DataFrame(confusion_matrix(y,pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "ea197695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "2",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "724bbac6-fbe7-4fc6-8850-9f2d26ba3407",
       "rows": [
        [
         "0",
         "50",
         "0",
         "0"
        ],
        [
         "1",
         "0",
         "49",
         "1"
        ],
        [
         "2",
         "0",
         "3",
         "47"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2\n",
       "0  50   0   0\n",
       "1   0  49   1\n",
       "2   0   3  47"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "3368286f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(\n",
    "    data = conf2,\n",
    "    cmap = 'Blues',\n",
    "    annot = True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "4e48e339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results are almost the same for soft and hard Voting so we will try some changes ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "ac3ac3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Voting(X,y,method):\n",
    "\n",
    "    lor = LogisticRegression(max_iter = 1000)\n",
    "    clf = DecisionTreeClassifier(\n",
    "        criterion = 'gini'\n",
    "    )\n",
    "    clf1 = DecisionTreeClassifier(\n",
    "        criterion = 'gini',\n",
    "        max_depth = 5 ,\n",
    "        splitter = 'random'\n",
    "    )\n",
    "    gnb = GaussianNB()\n",
    "\n",
    "\n",
    "    estimators = [\n",
    "        ('LogisticRegressor1' , lor) , \n",
    "        ('DecisionTreeClassifier' , clf) , \n",
    "        ('DecisionTreeClassifierUsingRandom' , clf1) ,\n",
    "        ('GaussianNaiveBayes' , gnb)\n",
    "    ]\n",
    "\n",
    "\n",
    "    voteX = VotingClassifier(\n",
    "    estimators = estimators ,  # Pass the variables in which we made the list of the modelnames and models (estimators)\n",
    "    voting = method\n",
    "    )\n",
    "\n",
    "    voteX.fit(X,y)\n",
    "\n",
    "    predX = voteX.predict(X)\n",
    "\n",
    "    print(f'Cross Val Score Mean for Voting : {method} : \\n {cross_val_score(voteX,X,y,cv=10,scoring='accuracy').mean()}')\n",
    "    print(f'Classification report for Voting : {method} : \\n {classification_report(y,predX)}')\n",
    "\n",
    "    confX = pd.DataFrame(confusion_matrix(y,predX))\n",
    "    print(f'Confusion Matrix for Voting : {method} : ')\n",
    "    sns.heatmap(\n",
    "        data = confX,\n",
    "        cmap = 'Blues',\n",
    "        annot = True \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "a2d20f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Score Mean for Voting : hard : \n",
      " 0.7933333333333333\n",
      "Classification report for Voting : hard : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.73      0.76      0.75        50\n",
      "           2       0.75      0.72      0.73        50\n",
      "\n",
      "    accuracy                           0.83       150\n",
      "   macro avg       0.83      0.83      0.83       150\n",
      "weighted avg       0.83      0.83      0.83       150\n",
      "\n",
      "Confusion Matrix for Voting : hard : \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Voting( \n",
    "        X[:,:2] , # Doing this cause I wanted to introduce some hurdles and find how well can ensembling work on\n",
    "        # models using Soft and Hard Votings.\n",
    "        y , \n",
    "        'hard'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "efb5e1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Score Mean for Voting : soft : \n",
      " 0.7533333333333333\n",
      "Classification report for Voting : soft : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.82      0.84      0.83        50\n",
      "           2       0.84      0.82      0.83        50\n",
      "\n",
      "    accuracy                           0.89       150\n",
      "   macro avg       0.89      0.89      0.89       150\n",
      "weighted avg       0.89      0.89      0.89       150\n",
      "\n",
      "Confusion Matrix for Voting : soft : \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Voting( \n",
    "        X[:,:2] , \n",
    "        y , \n",
    "        'soft'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "7a98d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As you can see now that we take only two columns we can clearly see that hard voting is better ensembling technique for it ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "c4dd27b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I will take the last two columns and check again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "e208ac58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Score Mean for Voting : hard : \n",
      " 0.96\n",
      "Classification report for Voting : hard : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.94      0.98      0.96        50\n",
      "           2       0.98      0.94      0.96        50\n",
      "\n",
      "    accuracy                           0.97       150\n",
      "   macro avg       0.97      0.97      0.97       150\n",
      "weighted avg       0.97      0.97      0.97       150\n",
      "\n",
      "Confusion Matrix for Voting : hard : \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Voting( \n",
    "        X[:,2:] , # Doing this cause I wanted to introduce some hurdles and find how well can ensembling work on\n",
    "        # models using Soft and Hard Votings.\n",
    "        y , \n",
    "        'hard'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "65966410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Score Mean for Voting : soft : \n",
      " 0.9666666666666666\n",
      "Classification report for Voting : soft : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.98      0.98      0.98        50\n",
      "           2       0.98      0.98      0.98        50\n",
      "\n",
      "    accuracy                           0.99       150\n",
      "   macro avg       0.99      0.99      0.99       150\n",
      "weighted avg       0.99      0.99      0.99       150\n",
      "\n",
      "Confusion Matrix for Voting : soft : \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Voting( \n",
    "        X[:,2:] , # Doing this cause I wanted to introduce some hurdles and find how well can ensembling work on\n",
    "        # models using Soft and Hard Votings.\n",
    "        y , \n",
    "        'soft'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "38ca9ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now soft method is performing good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e325786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now what does this mean ? \n",
    "#           Basically these are hyperparameters we use to tune and get better results. \n",
    "#           Not just this but also the parameters passed to each model can also be hypertuned . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963db1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
